{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# N-grams, Fastttext, and GloVE\n",
    "\n",
    "*This assignment focuses on exploring Fasttext and GloVE as NLP methods. We are going to focus on two tasks and ways of understanding models:*\n",
    "\n",
    "1. *The traditional, \"model is a classifier\" viewpoint. Here we are going to work with the [AG News Dataset](https://www.kaggle.com/datasets/amananandrai/ag-news-classification-dataset) to classify genres*\n",
    "2. *The more vector-based way, seeing them basically as machines that just generate word vectors, with everything else just being gravy. Barring attaching a specific classifier, GloVE falls entirely under this category.* \n",
    "\n",
    "*In this assignment, we are mainly going to be using the [AG News Classification Dataset](https://www.kaggle.com/datasets/amananandrai/ag-news-classification-dataset), a corpus of more than 1 million news articles, each classified as one of four classes: 'Business', 'Sci/Tech', 'World', or 'Sports'. Note, that because of the semi-supervised nature of most methods used in this assignment, we could almost do the whole thing without the labels. They're just there to make it a bit simpler and to provide an obvious usecase.*\n",
    "\n",
    "**For the GloVe part, note that you can download all their pretrained vectors at the [GloVe project page](https://nlp.stanford.edu/projects/glove/).**\n",
    "\n",
    "## 0. Extra primer on Fasttext\n",
    "\n",
    "*As you know, n-grams are pretty useful for improving the otherwise limited bag-of-words (BoW) model. Most often, this is by making distinctions between sentences such as \"good\" and \"not good\" which would be represented somewhat the same in a regular BoW. It is very obvious if we consider the sentence \"Maria stole the milk\" vs \"The milk stole Maria\", two sentences completely identical in the BoW representation, but with two obviously different meanings.*\n",
    "\n",
    "*As you also know, Fasttext takes this further by creating chracter-wise n-grams. These are made up of n-characters of a single word. This allows fasttext to consider cases such as grammar, where words are spelled similarly and even consider misspellings, if someone makes a mistaek in wirtign a wrod, the character-wise n-gram representation will be **almost** the same as the correct word.*\n",
    "\n",
    "This is done by Fasttext simply storing embedding vectors $v_n$ for each n-gram, character or otherwise. Fasttext will simply then average all of these vectors, word, character-wise n-grams, and word-wise n-grams to create the representation for a given text or sentence.\n",
    "\n",
    "$$v_{total} = \\frac{1}{N}\\sum^N_{n=0} v_n$$\n",
    "\n",
    "### Important note: Fasttext supervised and unsupervised\n",
    "\n",
    "*If you look into the technical documentation for the fasttext model, you'll notice that there are options to train both an **unsupervised** and a **supervised** version of the fasttext model. These use similar approaches, but it is arguably the unsupervised model that best describes what the fasttext team wanted to accomplish: efficient word-vector generation for downstream usage.*\n",
    "\n",
    "***The supervised model:***\n",
    "- *Needs a corpus of text with given labels to train*\n",
    "- *Does not use skipgram/CBoW, but just works as a 'normal' FFN for classification*\n",
    "- *Uses character-wise n-grams*\n",
    "- *Uses word-wise n-grams the same way as the unsupervised model uses character-wise n-grams, treating them as vectors and combining them in the end for the final classification.*\n",
    "- *Can be directly evaluated by just checking how good it is at predicting the given classes.*\n",
    "\n",
    "***The unsupervised model:*** (not important for this assignment or course, just cool to know)\n",
    "- *Just needs a corpus of text to train*\n",
    "- *Does not use wordwise n-grams*\n",
    "- *Has vectors for each unique character n-gram and each unique word in the corpus (limited by bin size)* \n",
    "- *Vectors for character n-grams are created indepedently of word vectors, for example the trigram \"her\" present in \"where\" has a different vector representation than the one for the full word \"her\".*\n",
    "- *Is a purely skipgram/CBoW model (input layer, one hidden, output layer)*\n",
    "- *Cannot be directly evaluated except in qualitative ways by considering the downstream tasks it will be used in*\n",
    "\n",
    "\n",
    "***Both models***\n",
    "- *Only work on CPU (bvadr) (what a time 2015 was!)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import pickle\n",
    "import fasttext\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generate_seed():\n",
    "    \"\"\"\n",
    "    Generates robust seed values using methods adapted from Gaius-quantum reverse...\n",
    "    ...GaunTLets, see more https://isotropic.org/papers/chicken.pdf and explained https://www.youtube.com/watch?v=dQw4w9WgXcQ\n",
    "    Values are generated from a specific subset of alphanumerics representing sub-deca natural-numericals\n",
    "    from the glove.42B.300d.txt Use this subset for the reverse function as well, the whole one will take too long\n",
    "    \"\"\"\n",
    "\n",
    "    with open(\"data/important_stuff.pkl\", \"rb\") as fp:\n",
    "        GQRGaunTLets_69B_300_seed_vals = pickle.load(fp)\n",
    "        seed = int(np.var(GQRGaunTLets_69B_300_seed_vals[69]) * 100)\n",
    "        return seed\n",
    "\n",
    "def seed_everything(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    try: torch.manual_seed(seed_value)\n",
    "    except: pass\n",
    "\n",
    "seed_everything(generate_seed())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 Word- and character-wise n-grams\n",
    "\n",
    "*The selling point of fasttext is in part given by its main paper's name: **Enriching Word Vectors with Subword Information**.  Character n-grams is really all its about. Since you have already worked with them, we are just going to briefly introduce them*\n",
    "\n",
    "*Normally, getting N-grams would be something you'd leave for an NLP package like NLTK. We're just going to implement it for the sake of understanding.*\n",
    "\n",
    "**1. Implement the below functions to get word-grams and character-grams respectively**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# N-gram functions -  Might need to be filled by students?\n",
    "\n",
    "def preprocess_text(text, lower=True, strip=True):\n",
    "    # Preprocess the text\n",
    "    if lower:\n",
    "        text = text.lower()\n",
    "    if strip:\n",
    "        text = re.sub('[^A-Za-z0-9 ]+', '', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def get_word_grams(text, n, lower=True, strip=True):\n",
    "    \"\"\"Gets a specific n-gram for a given text string\"\"\"\n",
    "\n",
    "    text = preprocess_text(text, lower, strip)\n",
    "    \n",
    "    length = len(text.split())\n",
    "\n",
    "    # Add padding\n",
    "    pad_start = ' '.join([\"<s>\"]*(n-1)) + ' '\n",
    "    pad_end = ' ' + ' '.join([\"</s>\"]*(n-1))\n",
    "    text = pad_start + text + pad_end\n",
    "\n",
    "    n_grams = []\n",
    "    text = text.split()\n",
    "    \n",
    "    # Obtain N-grams\n",
    "    for i in range(length + n-1):\n",
    "        n_grams.append(' '.join(text[i:i+n]))\n",
    "\n",
    "    return n_grams\n",
    "\n",
    "def get_character_grams(word: str, n):\n",
    "    \"\"\"Gets the character wise n-grams for a single word\"\"\"\n",
    "    word_grams = []\n",
    "\n",
    "    word = preprocess_text(word)\n",
    "\n",
    "    word = '<' + word + '>'\n",
    "\n",
    "    # Obtain character-grams\n",
    "    for i in range(len(word) - n + 1):\n",
    "        word_grams.append(word[i:i+n])\n",
    "\n",
    "    return word_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s> <s> <s> he', '<s> <s> he turned', '<s> he turned himself', 'he turned himself into', 'turned himself into a', 'himself into a pickle', 'into a pickle funniest', 'a pickle funniest shit', 'pickle funniest shit ive', 'funniest shit ive ever', 'shit ive ever seen', 'ive ever seen </s>', 'ever seen </s> </s>', 'seen </s> </s> </s>']\n"
     ]
    }
   ],
   "source": [
    "text = \"He turned himself into a pickle... Funniest shit, ive ever seen!!!\"\n",
    "\n",
    "n_grams = get_word_grams(text, n=4, lower=True, strip=True)\n",
    "print(n_grams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*As you can see from running the example below, even in this very small sentence, there are a ton of n-grams, and even more word-grams. This is why, for practical purposes, the Fasttext model often operates on what is known as a **'bucket size'** which defines the maximum number of possible word-grams avaliable in the model.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word-grams here: \n",
      "  ['<s> <s> he', '<s> he turned', 'he turned himself', 'turned himself into', 'himself into a', 'into a pickle', 'a pickle funniest', 'pickle funniest shit', 'funniest shit ive', 'shit ive ever', 'ive ever seen', 'ever seen </s>', 'seen </s> </s>']\n",
      "Character-grams here: \n",
      "  [['<he', 'he>'], ['<tu', 'tur', 'urn', 'rne', 'ned', 'ed>'], ['<hi', 'him', 'ims', 'mse', 'sel', 'elf', 'lf>'], ['<in', 'int', 'nto', 'to>'], ['<a>'], ['<pi', 'pic', 'ick', 'ckl', 'kle', 'le>'], ['<fu', 'fun', 'unn', 'nni', 'nie', 'ies', 'est', 'st>'], ['<sh', 'shi', 'hit', 'it>'], ['<iv', 'ive', 've>'], ['<ev', 'eve', 'ver', 'er>'], ['<se', 'see', 'een', 'en>']]\n"
     ]
    }
   ],
   "source": [
    "# Now let us just test these functions on some toy text...\n",
    "text = \"He turned himself into a pickle... Funniest shit, ive ever seen!!!\"\n",
    "\n",
    "n_grams = get_word_grams(text, n=3, lower=True, strip=True)\n",
    "# word_grams = [get_character_grams(words[0], n=3) for words in n_grams]\n",
    "# print(get_character_grams(text, n=3))\n",
    "# print([preprocess_text(word) for word in text.split()])\n",
    "word_grams = [get_character_grams(word, n=3) for word in text.split()]\n",
    "\n",
    "print(\"Word-grams here: \\n \", n_grams)\n",
    "\n",
    "print(\"Character-grams here: \\n \", word_grams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 Training and using the fasttext model\n",
    "\n",
    "<p style=\"text-align:center;\">\"<i>(Almost) Never do yourself what some other chump has done better\"</i> </p>\n",
    "<p style=\"text-align:center;\"> - Creed of the KID </p>\n",
    "\n",
    "*Obviously someone else has made a pretty well working [Fasttext module](https://fasttext.cc/). In this case, it is the team at Meta (Facebook, back then). Aside from how well it trains, is does have a few weird things about it, most notably that it requires .txt files to train (bvadr).*\n",
    "\n",
    "*For this exercise, we are going to focus on just tweaking minn and maxnn which control the minimum and maximum length for the character-grams. Note that setting the minn and maxn length both to 0, makes the model only consider word-grams and word vectors.*\n",
    "\n",
    "*A complete list of model hyperparameters can be found in the file hypereparams.txt, along with (most) methods callable on the Fasttext model. Refer to this if you need inspiration on making your model interesting. Consider any chosen hyperparamters **as arbitrary** and feel free to change them as you wish. It helps, however, to comment on or argue for your changes.*\n",
    "\n",
    "*Important note: If the model is asked for a word- or character-vector **not in its current vocabulary**, it will give a zero-vector of the same dimension as the other vectors in its vocabulary. This way even extremely esoteric spelling errors do not 'break' the model due to vocabulary lookup errors, the words themselves will just not add anything to the prediction.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fasttext - Theoretical questions\n",
    "\n",
    "**1. In general, how does fasttext handle OOV (out of vocabulary) tokens? How do they contribute to embeddings vectors?**\n",
    "\n",
    "In FastText, OOV tokens are split into character n-grams, for which an embedding can be found individually by looking it up in the subword embedding matrix, which was learned during training. Then all the character n-grams are averaged to obtain an embedding for the full word. \n",
    "\n",
    "**2. Say you have a fasttext model trained on a large corpus with character-3-grams how would it reprsent the OOV word \"Phandelver\"?.**\n",
    "\n",
    "The model would split the OOV word into subwords, as explained above. For n=3 this would look as such:\n",
    "\n",
    "<ph, han, and, nde, del, elv, lve, ver, er>\n",
    "\n",
    "Note: We write a \"p\" instead of a \"P\" since the preprocessing lowers all uppercase letters.\n",
    "\n",
    "**3. In probability theory, you often consider either the marignal probability $p(x)$, or the conditional probability $p(x|y)$. How do these two different kinds of probability relate to the field of natural language processing?**\n",
    "\n",
    "<p style=\"text-align:center;\"><i>\"Words that appear together, relate together\"</i></p>\n",
    "<p style=\"text-align:center;\">- From slides</p>\n",
    "\n",
    "\n",
    "The marginal probability represents the probability of a word appearing in a corpus of text and it is calculated by dividing the amount of times the word occurs divided by the total amount of words in the corpus.\n",
    "\n",
    "However the condition probability represents the probability of words appearing in succession. Among other applications, this can help us predict the next word based on the previous word.\n",
    "\n",
    "For instance, suppose y denotes an arbitrary word, and x denotes the word following y. In this case, the conditional probability $p(x|y)$ represents the probability that the word following y is x. Hence by maximizing the conditional probability, we can predict the next word in a sentence based on the previous word. Auto-correct in phones is a great example of this.\n",
    "\n",
    "<!-- The marginal probability relates to the number of times a word appears in a corpus, while the conditional probability is the probability of a word given the previous word. -->\n",
    "\n",
    "\n",
    "**4. Word2Vec is pretty old method in NLP, now mostly supplanted by attention-based models. What disadvantages are there in using specific word vectors for text classification? As inspiration, consider a fasttext model being given the following question:**\n",
    "\n",
    "*Mary saw a puppy in the window, she wanted it. James saw a nice window in the window store, he wanted it. What did Mary want?*\n",
    "\n",
    "\n",
    "Contextual Understanding:\n",
    "Word2Vec generates static embeddings, meaning that each word has a fixed representation regardless of its context. For example, in the sentence above, Word2Vec might incorrectly associate “it” with “window” rather than “puppy,” as it doesn’t encode the relationship between words in context.\n",
    "\n",
    "Handling Polysemy:\n",
    "As words are encoded independant of their context, sometimes words can have multiple meanings, leading to ambiguity.\n",
    "\n",
    "Out-of-Vocabulary (OOV) Words:\n",
    "Word2Vec cannot handle words not seen during training, as it requires a pre-trained embedding for each word. In contrast, FastText uses subword (e.g., n-gram) embeddings, enabling it to approximate embeddings for OOV words by combining representations of their subwords.\n",
    "\n",
    "Storage Requirements:\n",
    "Word2Vec requires storing an embedding for every word in the vocabulary, which can be computationally expensive for large corpora. FastText, by operating on subword units, reduces storage demands and increases efficiency.\n",
    "\n",
    "\n",
    "$\\star$ **5. As mentioned, attention-based models fix a lot of issues that older Word2Vec models had. Particularly, they do not need N-grams to capture context information. Why is this?**\n",
    "\n",
    "$\\dots$\n",
    "\n",
    "$\\star$ **6. Because of the way fasttext generates word-vectors (skipgram/CBoW), it only ever considers local contexts and not whole corpora at a time. What potential downsides does this have?**\n",
    "\n",
    "$\\dots$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 120000 data points in the dataset, \n",
      "7600 different points in the test set, and the different labels are [0 1 2 3],\n",
      "these correspond to the categories: ['World' 'Sports' 'Business' 'Sci/Tec']\n",
      "\n",
      "Training class balances:\n",
      "World 0.25\n",
      "Sports 0.25\n",
      "Business 0.25\n",
      "Sci/Tec 0.25\n",
      "\n",
      "Test class balances:\n",
      "World 0.25\n",
      "Sports 0.25\n",
      "Business 0.25\n",
      "Sci/Tec 0.25\n"
     ]
    }
   ],
   "source": [
    "# Load AG_news data\n",
    "news_data = np.load('./data/news_data.npz', allow_pickle=True)\n",
    "train_texts = news_data['train_texts']\n",
    "test_texts = news_data['test_texts']\n",
    "train_labels = news_data['train_labels']\n",
    "test_labels = news_data['test_labels']\n",
    "ag_news_labels = news_data['ag_news_label']\n",
    "\n",
    "print(f\"There are a total of {len(train_labels)} data points in the dataset, \\n\"\n",
    "        f\"{len(test_texts)} different points in the test set, and the different labels are {np.unique(train_labels)},\\n\"\n",
    "        f\"these correspond to the categories: {ag_news_labels}\\n\")\n",
    "\n",
    "\n",
    "# Let's just ensure class proportions are balanced for both training and testing purposes...\n",
    "n_classes = len(ag_news_labels)\n",
    "print(\"Training class balances:\")\n",
    "for i,c in enumerate(ag_news_labels):\n",
    "    print(c,np.mean(train_labels==i))\n",
    "print()\n",
    "\n",
    "print(\"Test class balances:\")\n",
    "for i,c in enumerate(ag_news_labels):\n",
    "    print(c,np.mean(test_labels==i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Creating fasttext data set from current training data\n",
    "def train_test_split(texts, labels, train_split=0.8):\n",
    "    \"\"\"\n",
    "    Creates .txt files for training and testing, compatible with a fasttext model\n",
    "\n",
    "    Args:\n",
    "        texts (np.ndarray): Iterable of full text where one item is one text\n",
    "        labels (np.ndarray): Labels for full text so that label i corresponds to text i\n",
    "        train_split (float): Fraction of data to be used for training, rest is used for testing\n",
    "\n",
    "    Returns:\n",
    "        train_texts (np.ndarray): Training texts\n",
    "        train_labels (np.ndarray): Training labels\n",
    "        test_texts (np.ndarray): Testing texts\n",
    "        test_labels (np.ndarray): Testing labels\n",
    "    \"\"\"\n",
    "\n",
    "    text_length = len(texts)\n",
    "\n",
    "    indices = np.arange(text_length)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    texts = texts[indices]\n",
    "    labels = labels[indices]\n",
    "\n",
    "    train_size = int(text_length * train_split)\n",
    "\n",
    "    train_texts = texts[:train_size]\n",
    "    train_labels = labels[:train_size]\n",
    "\n",
    "    test_texts = texts[train_size:]\n",
    "    test_labels = labels[train_size:]\n",
    "\n",
    "    return train_texts, train_labels, test_texts, test_labels \n",
    "\n",
    "def txtify_data(texts, labels, label_names, save_path):\n",
    "    \"\"\"\n",
    "    Converts a list of texts and labels to a .txt file compatible with fasttext\n",
    "\n",
    "    Args:\n",
    "        texts (np.ndarray): Train texts to be converted to .txt\n",
    "        labels (np.ndarray): Train labels so that label i corresponds to text i\n",
    "        label_names (dict): Dictionary of int: str so that int corresponds to the label name\n",
    "        save_path (str): Path where the txt file will be saved so fasttext can use it\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    txt = \"\"\n",
    "    for i, (text, label) in tqdm(enumerate(zip(texts, labels))):\n",
    "        text = text.lower()\n",
    "        text = re.sub('[^a-z0-9 ]+', '', text)\n",
    "\n",
    "        txt = txt + f'__label__{label_names[label]} {text}\\n'\n",
    "\n",
    "    \n",
    "    f = open(save_path, mode='w')\n",
    "    f.write(txt)\n",
    "    f.close()\n",
    "\n",
    "    return save_path\n",
    "\n",
    "# No need to run if already saved\n",
    "# path_to_train = txtify_data(train_texts, train_labels, ag_news_labels, save_path='training_data.txt')\n",
    "# path_to_test = txtify_data(test_texts, test_labels, ag_news_labels, save_path='test_data.txt')\n",
    "path_to_train = 'training_data.txt'\n",
    "path_to_test = 'test_data.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 4M words\n",
      "Number of words:  91297\n",
      "Number of labels: 4\n",
      "Progress: 100.0% words/sec/thread: 4220440 lr:  0.000000 avg.loss:  0.268873 ETA:   0h 0m 0s\n",
      "Read 4M words\n",
      "Number of words:  91297\n",
      "Number of labels: 4\n",
      "Progress: 100.0% words/sec/thread:  533850 lr:  0.000000 avg.loss:  0.395935 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Defining fasttext hyperparameters\n",
    "char_gram_length_min = 3 # If set to zero, we only train word-grams\n",
    "char_gram_length_max = 6 # If set to zero, we only train word-grams\n",
    "num_word_grams = 1 # Default value\n",
    "verbose = True # Set to false if you don't want to see training statistics\n",
    "\n",
    "# Train fasttext_word_model and fasttext_char_model respectively\n",
    "fasttext_word_model = fasttext.train_supervised(path_to_train, maxn=0, minn=0, verbose=verbose,\n",
    "                                                wordNgrams=num_word_grams)\n",
    "\n",
    "fasttext_char_model = fasttext.train_supervised(path_to_train, maxn=char_gram_length_max, minn=char_gram_length_min,\n",
    "                                                verbose=verbose, wordNgrams=num_word_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word model subwords: (['cat'], array([4512]))\n",
      "Character model subwords: (['<su', '<sup', '<supe', '<super', 'sup', 'supe', 'super', 'superc', 'upe', 'uper', 'uperc', 'uperca', 'per', 'perc', 'perca', 'percal', 'erc', 'erca', 'ercal', 'ercali', 'rca', 'rcal', 'rcali', 'rcalif', 'cal', 'cali', 'calif', 'califr', 'ali', 'alif', 'alifr', 'alifra', 'lif', 'lifr', 'lifra', 'lifrag', 'ifr', 'ifra', 'ifrag', 'ifragi', 'fra', 'frag', 'fragi', 'fragil', 'rag', 'ragi', 'ragil', 'ragili', 'agi', 'agil', 'agili', 'agilis', 'gil', 'gili', 'gilis', 'gilist', 'ili', 'ilis', 'ilist', 'ilisti', 'lis', 'list', 'listi', 'listic', 'ist', 'isti', 'istic', 'istice', 'sti', 'stic', 'stice', 'sticex', 'tic', 'tice', 'ticex', 'ticexp', 'ice', 'icex', 'icexp', 'icexpl', 'cex', 'cexp', 'cexpl', 'cexpli', 'exp', 'expl', 'expli', 'explia', 'xpl', 'xpli', 'xplia', 'xplial', 'pli', 'plia', 'plial', 'pliali', 'lia', 'lial', 'liali', 'lialid', 'ial', 'iali', 'ialid', 'ialido', 'ali', 'alid', 'alido', 'alidoc', 'lid', 'lido', 'lidoc', 'lidoci', 'ido', 'idoc', 'idoci', 'idocio', 'doc', 'doci', 'docio', 'dociou', 'oci', 'ocio', 'ociou', 'ocious', 'cio', 'ciou', 'cious', 'cious>', 'iou', 'ious', 'ious>', 'ous', 'ous>', 'us>'], array([2000568, 1413574, 1606497,  202199,  208096, 2037839,  321653,\n",
      "       1898166, 1495232, 1169080,  921661, 1210216,  204869, 1067878,\n",
      "       1613517,  810849, 1175568, 1853483, 1548339, 1614658,  736442,\n",
      "        305744, 1017683,  659805,  684768, 1373955, 1492205, 1937083,\n",
      "        969772,  690360,  646944, 1952219,  871425,  796023,  421302,\n",
      "        467351, 1032125,  918376, 2084353,  783436, 1571281, 1322390,\n",
      "        110133,  841097, 1323202,  841209,  410877, 1068048, 1677961,\n",
      "        554605,  341216, 1284037,  399140,  320511, 1574776,  202938,\n",
      "       1578980,  193457, 1895181,  815488, 1201424, 1890082, 1044057,\n",
      "       1307490, 1320148, 1569487, 1980632,  262199, 1951954,  910519,\n",
      "       1865642,  982404, 1810632,  690311,  451163,  820639, 1437601,\n",
      "        369161,  385641, 1397197, 1961400, 1959110,  920844,  617031,\n",
      "       1607497, 1868589,  751264,  461659, 1456092, 1996727,  679670,\n",
      "       1713116,  294417, 1068260, 1761054,  946205,  314758,  818380,\n",
      "       1806087, 1447495,  136266, 1173601, 1681613, 1064986,  969772,\n",
      "        245598, 1715895, 1932112,  426663,  860524,  108185, 1090916,\n",
      "       2080958,  302971, 1838186,  812659,  825590, 1702037,  406178,\n",
      "       1735741,  892683, 1659904,  359103,  576184,  742315, 1050894,\n",
      "       1976539,  849005,  571053,  922766, 1971658,  380231,  329449,\n",
      "        699846]))\n"
     ]
    }
   ],
   "source": [
    "# Example of how the subwords of the character model and the word model differ\n",
    "# get_subwords gets all character-gram 'parts' of the word specified...\n",
    "# ...as well as indices corresponding to the row of the given vector in the embedding matrix\n",
    "print(\"Word model subwords:\", fasttext_word_model.get_subwords('cat'))\n",
    "# Testing with longer word to see min and max n-gram lengths\n",
    "print(\"Character model subwords:\", fasttext_char_model.get_subwords('supercalifragilisticexplialidocious'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A cat in a hat: Sci/Tec\n"
     ]
    }
   ],
   "source": [
    "def test_prediction(model, test_text, test_label=None, return_bool=True):\n",
    "    \"\"\"\n",
    "    test labels and return_bool used for when we need accuracy of the model\n",
    "    Method for testing fasttext model\n",
    "    Model should be either the character model or the word model\n",
    "\n",
    "    Args:\n",
    "        model (fasttext model): Model to be tested\n",
    "        test_text (str): Text to be tested\n",
    "        test_label (str): Label of the text, used for testing accuracy\n",
    "        return_bool (bool): If true, returns a boolean indicating if the prediction was correct, else returns the prediction\n",
    "    \"\"\"\n",
    "\n",
    "    # Reason why we index with [0][0][9:] we do: .predict outputs a tuple of certainty and the label, the label being __label__Business for example for business\n",
    "    prediction = model.predict(test_text)[0][0][9:]\n",
    "\n",
    "    if not return_bool:\n",
    "        return prediction\n",
    "\n",
    "    if prediction == test_label:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "# Testing the models on some toy data\n",
    "text_to_predict = 'A cat in a hat'\n",
    "prediction = test_prediction(model=fasttext_word_model, test_text=text_to_predict, return_bool=False)\n",
    "print(f\"{text_to_predict}: {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Getting Fasttext Accuracy\n",
    "\n",
    "**1. Implement the below function to get the accuracy of a fasttext model. It should return the accuracy of the fasttext model when trying to predict each of the four labels, as well as the average accuracy across all labels. You can use the test_prediction function above to get predictions, but you can also implement your own method.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing fasttext word model...\n",
      "({0: 0.9042105263157895, 1: 0.966842105263158, 2: 0.8763157894736842, 3: 0.8894736842105263}, 0.9092105263157895)\n",
      "\n",
      "Testing fasttext character model...\n",
      "({0: 0.8978947368421053, 1: 0.9631578947368421, 2: 0.8705263157894737, 3: 0.8757894736842106}, 0.9018421052631579)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test_fasttext_model(fasttext_model, test_texts, test_labels, label_names):\n",
    "    \"\"\"\n",
    "    Test the accuracy of the fasttext model on the whole test set\n",
    "    Should return the accuracy of the model on each label, as well as the total accuracy\n",
    "\n",
    "    Args:\n",
    "        fasttext_model (fasttext model): fasttext model to be tested\n",
    "        test_texts (np.ndarray): test texts to run prediction on\n",
    "        test_labels (np.ndarray): true labels of given test texts\n",
    "        label_names (dict): Dictionary of int: str so that int corresponds to the label name\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a dictionary of correct answers for each label\n",
    "    # text_true = {0: test_labels[:int(len(test_labels)*0.25)], \n",
    "    #              1: test_labels[int(len(test_labels)*0.25):int(len(test_labels)*0.5)],\n",
    "    #              2: test_labels[int(len(test_labels)*0.5):int(len(test_labels)*0.75)],\n",
    "    #              3: test_labels[int(len(test_labels)*0.75):]}\n",
    "    preds = {0: [], 1: [], 2: [], 3: []}\n",
    "\n",
    "    test_labels_n = np.array([label_names[label] for label in test_labels])\n",
    "\n",
    "    # Iterate over all test texts and labels and add to aforementioned dictionary whether or not the model predicted correctly\n",
    "    for text, label, name in zip(test_texts, test_labels, test_labels_n):\n",
    "        prediction = test_prediction(fasttext_model, text, name, return_bool=True)\n",
    "        preds[label].append(prediction)\n",
    "\n",
    "    # Normalize the values in the dictionary by the total number of each label in the test set\n",
    "    normalized_preds = {k: np.mean(v) if v else None for k,v in preds.items()}    \n",
    "\n",
    "    # Get the total accuracy of the model across all labels\n",
    "    total_acc = np.mean([np.mean(v) for k,v in preds.items()])\n",
    "\n",
    "    # return the accuracy of the model on each label, as well as the total accuracy\n",
    "    return normalized_preds, total_acc\n",
    "\n",
    "print(\"Testing fasttext word model...\")\n",
    "print(test_fasttext_model(fasttext_word_model, test_texts, test_labels, ag_news_labels))\n",
    "\n",
    "print(\"\\nTesting fasttext character model...\")\n",
    "print(test_fasttext_model(fasttext_char_model, test_texts, test_labels, ag_news_labels))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 GloVe to create embeddings vectors\n",
    "\n",
    "*[GloVe Paper here](https://aclanthology.org/D14-1162.pdf), [GloVe Project page here](https://nlp.stanford.edu/projects/glove/)*\n",
    "\n",
    "*GloVe is called a \"global log-bilinear regression model\" which combines the strengths of global matrix factorization and local context window methods.*\n",
    "\n",
    "*In English, this means it combines methods that work by collecting information on the entire corpus, with other methods that capture more local patterns, essentially what we see with Fasttext that considers local n-grams. GloVe just considers \"context windows\" rather than an n-gram. Overall, what they want are nicely defined, linear relationships, decided by comparing the co-occurences of different words.*\n",
    "\n",
    "*The selling point really, is that while a run-of-the-mill neural network **may** be able to answer the questions: \"Skibidi is to Toilet as Fanum is to ...?\", it will not necessarily be able to do it in a linear manner. Therefore considering all the word vectors together in their latent space, may not yield good information. GloVe fixes this by keeping all vector substructures linear.*\n",
    "\n",
    "*Essentially, GloVe trains by mixing a [Skipgram model](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/) (just a neural network) with a function that works more on the entire corpus, while maintaining a weighting between the two. Because GloVe works best on huge corpora of data, we are not going to train it ourselves, but just use pretrained GloVe vectors, collected from their [project page](https://nlp.stanford.edu/projects/glove/).* \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe - Theoretical questions\n",
    "\n",
    "\n",
    "**1. On their project page, GloVe gives a few different possibilities for GloVe vectors, including ones with embedding dimension 50, 100, 200, and 300. What potential downsides and upsides are there to larger/smaller embedding dimensions? Consider both training and subsequent usage.**\n",
    "\n",
    "The GloVe vector sets are collections of pre-trained vector embeddings, which come in multiple sizes. While the larger embeddings allow for richer representations, they increase training and inference costs, unlike smaller embeddings, which are computationally lighter but may struggle to capture nuanced relationships.\n",
    "\n",
    "**Context**\n",
    "\n",
    "High-dimensional embeddings allow the vectors to capture more context, since larger embeddings have a greater amount of tunable parameters. While the smaller vectors capture the most important contexts, a larger dimension can better represent words with subtle semantic differences. However diminishing returns may occur beyond a certain size. \n",
    "\n",
    "**Overfitting**\n",
    "\n",
    "While larger dimensions can capture more context, they might also risk overfitting due to their ability to capture subtle details, especially if the training data is insufficient. Essentially, while the low-dimensional embeddings capture the general trends in the data, the high-dimensional vectors will have more opportunity to fit the data on more parameters, which can sometimes be a good thing and sometimes a bad thing, depending on the size and quality of the dataset. This also means that for small datasets it would typically be a good choice to use a smaller embedding size, and vice versa.\n",
    "\n",
    "\n",
    "**Computational efficiency**\n",
    "\n",
    "High dimensional embeddings also mean more expensive computations, both during training and for downstream tasks. If using the Transformer architecture, the positional embeddings must match the dimensionality of the word embeddings. While sinusoidal positional encodings, using the harmonic bases, are computationally efficient, learned positional embeddings could increase computational cost during training, due to backpropagation running over a larger parameter space, and slower inference due to matrix operations and dot product operations on higher-dimensional vectors. '\n",
    "\n",
    "Larger embeddings also require more memory for storage. The embedding size directly scales the number of parameters in the embedding layer. For a vocabulary of size $V$ and embedding size $D$, the embedding layer will have $V \\times D$ parameters. This means that the amount of memory that must be allocated for storing the vectors, increases linearly with the embedding size.\n",
    "\n",
    "\n",
    "**2. Also on their webage, they give two options for the \"Common Crawl\" GloVe vector set: \"42B tokens, 1.9M vocab, 300d vectors\" and \"840B tokens, 2.2M vocab, 300d vectors\". What are the differences between these?**\n",
    "\n",
    "Both GloVe vector sets are rather large, however the smallest one (40B tokens) is a subset of the larger corpus (840B tokens), which covers more text and is likely to contain richer and more diverse linguistic patterns, leading to potentially better embeddings for rare or less frequent words.\n",
    "\n",
    "\n",
    "**3. Given just a bunch of embedding vectors from a known GloVe embedding, it is usually not possible to get a 1-1 correspondance of what words these vectors were. Why is this?**\n",
    "\n",
    "The reason it is typically not possible to establish a 1-1 correspondence between embedding vectors from different models is that the vectors themselves do not contain information about their corresponding words. Embeddings rely on an external vocabulary file to map each vector to its associated word, which is a list of all the words in the model’s vocabulary, stored in a fixed order. The order of words in this vocabulary file determines the correspondence between rows in the embedding matrix and their associated words.\n",
    "\n",
    "\n",
    "**4. How would you most closely estabilsh this 1-1 correspondance between given vectors from a known GloVe embedding and their corresponding words?**\n",
    "\n",
    "When embeddings come from a different model (e.g., trained on a different corpus or with different hyperparameters), the latent spaces, where semantic relationships are encoded, may differ. This variance in the semantic spaces means that the same or similar vector values in one model might correspond to entirely different words in another. Additionally, the relationships between vectors, such as distances and directions that encode semantic meaning, can vary between models, further complicating any attempt at direct correspondence.\n",
    "\n",
    "However one way to closely establish a 1-1 correspondence between vectors and their words is by leveraging relative representations, which preserves the relationships between vectors, such as distances and directions in the embedding space. These relationships often encode semantic meaning and can be used to align embeddings or approximate word mappings without needing the original vocabulary file.\n",
    "\n",
    "This process can involve techniques like zero-shot stitching, where embeddings are aligned or mapped based on their relative structures (e.g., using known anchor points or inference methods). While relative representation allows for reconstructing or aligning embeddings effectively, absolute representation (the raw numerical values of vectors) alone does not provide enough information to recover the word mappings directly.\n",
    "\n",
    "\n",
    "$\\star$ **5. Why can't we just use a Python dictionary with vectors as keys and words as values? (essentially a reverse GloVe dictionary)**\n",
    "\n",
    "$\\dots$\n",
    "\n",
    "\n",
    "$\\star$ **6. In the GloVe paper, they say they attempt to model $F(w_i, w_j, \\tilde{w_k}) = \\frac{P_{ik}}{P_jk}$. That is, the probability of one word given another, compared to the probability of that same word given a third word. For this, they briefly consider using a neural network as the function $F$ but decide against it, as \"doing so would obfuscate the linear strcutures we are trying to capture\", what linear structures are talked about and how would they be obfuscated by using something like a neural network?**\n",
    "\n",
    "$\\dots$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove(glove_path):\n",
    "    \"\"\"\n",
    "    Loads a GloVE vectors from a given path\n",
    "\n",
    "    Args:\n",
    "        glove_path (str): Path to the GloVE txt file\n",
    "\n",
    "    Returns:\n",
    "        glove (dict): Dictionary of word: vector pairs\n",
    "    \"\"\"\n",
    "    glove = {}\n",
    "    \n",
    "    print(\"Creating GloVE dictionary...\")\n",
    "    with open(glove_path, 'r') as f:\n",
    "        for line in tqdm(f):\n",
    "            values = line.split()\n",
    "            glove[values[0]] = np.asarray(values[1:], 'float32')\n",
    "            # word = values[0]\n",
    "            # vector = np.asarray(values[1:], 'float32')\n",
    "            # glove[word] = vector\n",
    "    \n",
    "    return glove\n",
    "\n",
    "def create_GloVE_vector(text, glove):\n",
    "    \"\"\"\n",
    "    Creates a GloVE vector for a given longer text and GloVe dictionary\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub('[^a-z0-9 ]+', '', text)\n",
    "    text = text.split()\n",
    "\n",
    "    # Create a vector of zeros with the same shape as the GloVE vectors\n",
    "    vector = np.zeros_like(glove['the'])\n",
    "\n",
    "    for word in text:\n",
    "        if word in glove:\n",
    "            vector += glove[word]\n",
    "\n",
    "    vector = np.mean(vector)\n",
    "    return vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating GloVE dictionary...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400000it [00:02, 185398.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load GloVe dictionary, doing it here since we only wanna do it once, since it takes a fuckton of time\n",
    "glove = load_glove('data/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Word similarity\n",
    "\n",
    "**1. Complete the word similarity function below. It should compute the cosine simliarity between two provided word embedding vectors.**\n",
    "\n",
    "**2. Briefly comment on the similarities obtained when running the cell two spaces below**\n",
    "\n",
    "It is apparent that the contextual similarities found are accurate, since firstly, identical words \"cat\" and \"cat\" have a similarity of 1, which they should as they are semantically identical. Secondly and also notably, \"cat\" and \"dog\" has a similarity of 0.92, which is very high, and this makes sense since both words describe animals, more specifically pets. Since both words describe pets, this means that \"cat\" and \"dog\" is interchangable in a large amount of situations, which means that their contextual similarity is very high, as captured by the GloVe similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_similarity(vec1, vec2, glove=None):\n",
    "    \"\"\"\n",
    "    Gets the cosine similarity between two vectors or two words in the GloVE dictionary\n",
    "\n",
    "    Args:\n",
    "        vec1 (np.ndarray, str): First vector to compare to the second\n",
    "        vec2 (np.ndarray, str): Second vector to compare to the first\n",
    "        glove (dict): GloVe dictionary if we want to compare words instead of just vectors, else None\n",
    "\n",
    "    Returns:\n",
    "        float: Cosine similarity of the two vectors or words\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the vectors from the GloVE dictionary if the input is a string\n",
    "    if glove is not None:\n",
    "        vec1, vec2 = glove[vec1], glove[vec2]\n",
    "    \n",
    "    # Return the cosine similarity of the two vectors\n",
    "    norm_v1 = np.linalg.norm(vec1) # np.sqrt(np.power(vec1, 2)) does not return same results for some reason\n",
    "    norm_v2 = np.linalg.norm(vec2)\n",
    "    return np.dot(vec1, vec2) / (norm_v1 * norm_v2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe similarity between cat and dog is 0.9218005537986755\n",
      "GloVe similarity between cat and banana is 0.3396517038345337\n",
      "GloVe similarity between cat and cat is 1.0\n",
      "GloVe similarity between camera and man is 0.473562091588974\n",
      "GloVe similarity between steel and beams is 0.5590429306030273\n",
      "GloVe similarity between six and 6 is 0.7447779178619385\n"
     ]
    }
   ],
   "source": [
    "# Test the word simliarity function on some word pairs\n",
    "\n",
    "word_pairs = [('cat', 'dog'), ('cat', 'banana'), ('cat', 'cat'), ('camera', 'man'), ('steel', 'beams'), ('six', '6')]\n",
    "\n",
    "for word1, word2 in word_pairs:\n",
    "    print(f\"GloVe similarity between {word1} and {word2} is {word_similarity(word1, word2, glove)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\star$ 3.2 GloVe vector word\n",
    "\n",
    "**1. Implement the function below which, given a GloVe vector for a word, finds what word it was before it was embedded**\n",
    "\n",
    "**2. Slowly add more words to the 'words' list two cells below. At what point do you reckon a text, transformed to GloVe vectors becomes too long to lookup words for each vector in it?**\n",
    "\n",
    "$\\dots$\n",
    "\n",
    "**$\\star \\star$ 3. Why is this method so slow? What factors influence its speed? How could you levearage things like asynchronous execution or multithreading to speed it up?**\n",
    "\n",
    "$\\dots$\n",
    "\n",
    "**$\\star \\star \\star \\star \\star$ Implment this asynchronous execution or multithreading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_closest_word(target_vector, glove_lookup):\n",
    "#     \"\"\"\n",
    "#     Finds the closest word in the GloVe dictionary to a given vector using word_similarity function.\n",
    "    \n",
    "#     Args:\n",
    "#         target_vector (np.ndarray): Vector to find the closest word to.\n",
    "#         glove_lookup (dict): GloVe dictionary to look up the closest word in.\n",
    "    \n",
    "#     Returns:\n",
    "#         str: Word in keys of glove_lookup closest to target_vector.\n",
    "#     \"\"\"\n",
    "#     max_similarity = -1  # Initialize with the lowest similarity\n",
    "#     closest_word = None  # Placeholder for the closest word\n",
    "\n",
    "\n",
    "#     # Iterate over all words in the GloVE dictionary and find the most similar one to the target vector\n",
    "\n",
    "#     for word, word_vector in glove_lookup.items():\n",
    "#         # Compute similarity using the word_similarity function\n",
    "#         similarity = word_similarity(target_vector, word_vector)\n",
    "    \n",
    "#     # If the similarity is higher than the current max, update the max similarity and closest word\n",
    "    \n",
    "#         if similarity > max_similarity:\n",
    "#             max_similarity = similarity\n",
    "#             closest_word = word\n",
    "    \n",
    "#     return closest_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words = ['cat']\n",
    "\n",
    "# for i, word in enumerate(words):\n",
    "#     word_vector = glove[word]\n",
    "#     closest_word = find_closest_word(word_vector, glove)\n",
    "#     print(f\"Closest word found to actual word {words[i]}:\", closest_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excluding the target word itself to make the function more useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_word(target_vector, glove_lookup, target_word=None):\n",
    "    \"\"\"\n",
    "    Finds the closest word in the GloVe dictionary to a given vector.\n",
    "    \"\"\"\n",
    "    max_similarity = -1\n",
    "    closest_word = None\n",
    "\n",
    "    for word, word_vector in glove_lookup.items():\n",
    "        if word == target_word:\n",
    "            continue\n",
    "        similarity = word_similarity(target_vector, word_vector)\n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            closest_word = word\n",
    "\n",
    "    return closest_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word closest to 'queen' is 'princess'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Define the target vector\n",
    "target_word = 'queen'\n",
    "if target_word in glove:\n",
    "    target_vector = glove[target_word]\n",
    "else:\n",
    "    print(f\"Word '{target_word}' not found in GloVe dictionary.\")\n",
    "    target_vector = np.zeros(50)\n",
    "\n",
    "#Find the closest word\n",
    "closest_word = find_closest_word(target_vector, glove, target_word=target_word)\n",
    "\n",
    "print(f\"The word closest to '{target_word}' is '{closest_word}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Exercise 4 Comparing word embeddings vectors\n",
    "\n",
    "*Since both GloVe and Fasttext, at their core, are both methods for egenerating embedding vectors, it would make sense to examine how they look compared to one another. Since both live in high-dimensional spaces, we must perform PCA on them to actually make sense of them in a graphical way.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings - Theoretical questions\n",
    "\n",
    "**1. Explain shortly what you expect to find if we perform PCA on the matrix of word-embeddings, that is the matrix which holds a vector representation of each word in our vocabulary**\n",
    "\n",
    "Firstly we would expect to see some relatively dense clustering within each of the groups, since we have a very large amount of datapoints. Secondly we would expect to see some overlap between clusters, and since business and science/technology is very closely related we would expect those clusters to have the most significant overlap.\n",
    "\n",
    "Furthermore, the first and second principal components explains the greatest amount of variance in the data, hence we expect these components to give us the best clustering overall.\n",
    "\n",
    "**2. When getting vectors for all words in a large text, GloVe should be significantly faster than Fasttext, why is this?**\n",
    "\n",
    "GloVe already has the pretained vector embeddings, which means that retrieving a words embedding is essentially a lookup operation in constant time per word, while the Fasttext on the other hand represents words using subword embeddings (e.g., n-grams). This means that Fasttext has to compute the embedding by combining embeddings for its subword components for each word, which is a lot more demanding.\n",
    "\n",
    "We note that GloVe embeddings have no way of handling out-of-vocabulary (OOV) words natively, whilst Fasttext can do this by leveraging its subword structure. This means that GloVe provides no meaningful representation for OOV words. However since we are dealing with a large dataset, this is less of an issue, since the vocabulary is large and OOV words for that reason are less common.\n",
    "\n",
    "**3. Which model (GloVe or fasttext) do you think performs best at seperating the four classes of the AG News dataset if we get average embedding vectors for each text in the training and testing dataset, perform PCA on these and plot them on the two top principal components. And why do you think that model performs best at seperating the four classes?**\n",
    "\n",
    "GloVe stores the context in the embeddings, while fasttext learns embeddings based on subword (n-gram) information. For this reason, we expect GloVe to perform better in this classification task, since the classification is made based on the context of each sentence and not the semantic similarity. \n",
    "\n",
    "For instance GloVe captures the inherent contextual relationship between the vectors for \"king\" and \"queen\".\n",
    "\n",
    "$ \\text{vec}(\\text{“king”}) - \\text{vec}(\\text{“man”}) + \\text{vec}(\\text{“woman”}) \\approx \\text{vec}(\\text{“queen”}) $\n",
    "\n",
    "While Fasttext instead looks at how similar the words and their n-grams are semantically.\n",
    " \n",
    "In Fasttext the “king” and “queen” representations are influenced by their shared character-level components (e.g. the insersection between their n-grams.)\n",
    "\n",
    "For instance $(<qu, que, uee, een, en>, <quee, ueen>, <queen>)$ and $(<ki, kin, ing, ng> , <kin, king, ing> , <king, king>)$. Note while queen and king shares contextual similarity they have no subwords (n-grams) in common.\n",
    "\n",
    "This means that Fasttext will not represent high-level relationships like $\\text{“king”} - \\text{“man”} + \\text{“woman”} = \\text{“queen”}$ effectively.\n",
    "\n",
    "However since FastText captures the semantic relationships between words. Words like “goal,” “match,” and “player” (related to Sports) will have embeddings close to each other because they frequently co-occur in sports-related texts. This can provide some degree of meaningful separation between sentence clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 General for all tasks in exercise 4\n",
    "\n",
    "**1. Below, we define the current_model as a fasttext_word_model. Run the code with this, but also try changing it to a fasttext_char_model or the glove dictionary. All should work, and should produce different results. After rerunning the code cells. Comment generally on the differences observed between the different models**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_model = glove\n",
    "# current_model_name = fasttext_char_model\n",
    "# current_model = fasttext_word_model\n",
    "# current_model = fasttext_char_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feats_train = []\n",
    "# feats_test = []\n",
    "\n",
    "# def clean(text):\n",
    "#     \"\"\"\n",
    "#     Cleaning text of non-alphanumerics using the aforementioned string translation table\n",
    "#     Just for convenience in regards to GloVe and useful word vectors\n",
    "#     \"\"\"\n",
    "#     translator = str.maketrans('', '', string.punctuation)\n",
    "#     return text.translate(translator).lower()\n",
    "\n",
    "# def get_average_embedding_vectors(model, train_texts, test_texts):\n",
    "#     print(\"Getting fasttext average embedding vectors for each class...\")\n",
    "#     placeholder = np.zeros_like(glove['the'])\n",
    "\n",
    "#     for text in tqdm(train_texts):\n",
    "#         words = clean(text).split()\n",
    "#         if getattr(model, 'get', False):\n",
    "#             feats_train.append(np.mean([model.get(word, placeholder) for word in words], axis=0))\n",
    "#         else:\n",
    "#             feats_train.append(np.mean([model.get_word_vector(word) for word in words], axis=0))\n",
    "\n",
    "#     # Same but for each text in test set\n",
    "#     for text in tqdm(test_texts):\n",
    "#         words = clean(text).split()\n",
    "#         if getattr(model, 'get', False):\n",
    "#             feats_test.append(np.mean([model.get(word, placeholder) for word in words], axis=0))\n",
    "#         else:\n",
    "#             feats_test.append(np.mean([model.get_word_vector(word) for word in words], axis=0))\n",
    "\n",
    "#     return np.array(feats_train), np.array(feats_test)\n",
    "\n",
    "# feats_train, feats_test = get_average_embedding_vectors(current_model, train_texts, test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_pca(n_components, feats_train, feats_test, train_labels, test_labels, label_names):\n",
    "#     \"\"\"\n",
    "#     Does PCA with n_components on given features and plots the result in two dimensions\n",
    "\n",
    "#     Args:\n",
    "#         n_components (int): How many components to use in the PCA\n",
    "#         feats_train (np.ndarray): Average embedding vectors for each text in the training set\n",
    "#         feats_test (np.ndarray): Average embedding vectors for each text in the test set\n",
    "#         train_labels (np.ndarray): Labels for each text in the training set\n",
    "#         test_labels (np.ndarray): Labels for each text in the test set\n",
    "#         label_names (dict): Dictionary of int: str so that int corresponds to the label name\n",
    "#     \"\"\"\n",
    "\n",
    "#     pca = PCA(n_components=n_components)\n",
    "\n",
    "#     # fit_transform avoids having to manually transform the vectors with the matrix afterwards\n",
    "#     Vtrain = pca.fit_transform(feats_train)\n",
    "#     Vtrain_var_explained = pca.explained_variance_ratio_\n",
    "\n",
    "#     Vtest = pca.fit_transform(feats_test)\n",
    "#     Vtest_var_explained = pca.explained_variance_ratio_\n",
    "\n",
    "#     colors = 'rgbk'\n",
    "#     for label, transformed_vector, title in zip([train_labels, test_labels], [Vtrain, Vtest], [f'Training set var_explained: {sum(Vtrain_var_explained[:2])}', f'Test set, var_explained: {sum(Vtest_var_explained[:2])}']):\n",
    "#         plt.figure(figsize=(20, 6))\n",
    "#         plt.subplot(1, 3, 1)\n",
    "#         for i in range(4):\n",
    "#             plt.plot(transformed_vector[label==i, 0], transformed_vector[label==i, 1], '.', color=colors[i], label=label_names[i])\n",
    "#         plt.legend()\n",
    "#         plt.xlabel('PC1')\n",
    "#         plt.ylabel('PC2')\n",
    "\n",
    "#         plt.subplot(1, 3, 2)\n",
    "#         for i in range(4):\n",
    "#             plt.plot(transformed_vector[label==i, 1], transformed_vector[label==i, 2], '.', color=colors[i], label=label_names[i])\n",
    "#         plt.legend()\n",
    "#         plt.xlabel('PC2')\n",
    "#         plt.ylabel('PC3')\n",
    "\n",
    "#         plt.subplot(1, 3, 3)\n",
    "#         for i in range(4):\n",
    "#             plt.plot(transformed_vector[label==i, 2], transformed_vector[label==i, 3], '.', color=colors[i], label=label_names[i])\n",
    "#         plt.legend()\n",
    "#         plt.xlabel('PC3')\n",
    "#         plt.ylabel('PC4')\n",
    "#         plt.suptitle(title, fontweight='bold', fontsize=15)\n",
    "\n",
    "#     # Plot explained variance\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.plot(list(range(n_components)),np.cumsum(pca.explained_variance_ratio_))\n",
    "#     plt.title(\"Explained variance compared to number of components\")\n",
    "#     plt.xlabel(\"Number of components\")\n",
    "#     plt.ylabel(\"Explained variance\")\n",
    "#     plt.grid()\n",
    "#     plt.show()\n",
    "\n",
    "#     return pca\n",
    "\n",
    "# n_components = 50\n",
    "# pca_word_vec = plot_pca(n_components, feats_train, feats_test, train_labels, test_labels, ag_news_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model: glove\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train embeddings: 100%|██████████| 120000/120000 [00:02<00:00, 42090.97it/s]\n",
      "Generating test embeddings: 100%|██████████| 7600/7600 [00:00<00:00, 40517.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plots saved for model: glove\n",
      "Processing model: fasttext_word_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train embeddings: 100%|██████████| 120000/120000 [00:16<00:00, 7250.23it/s]\n",
      "Generating test embeddings: 100%|██████████| 7600/7600 [00:01<00:00, 7437.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plots saved for model: fasttext_word_model\n",
      "Processing model: fasttext_char_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train embeddings:   8%|▊         | 9029/120000 [00:01<00:19, 5741.06it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 124\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Generate embeddings\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m feats_train, feats_test \u001b[38;5;241m=\u001b[39m \u001b[43mget_average_embedding_vectors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_texts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_texts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# Plot PCA and save results\u001b[39;00m\n\u001b[1;32m    127\u001b[0m plot_pca_and_save(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, feats_train\u001b[38;5;241m=\u001b[39mfeats_train, feats_test\u001b[38;5;241m=\u001b[39mfeats_test,\n\u001b[1;32m    128\u001b[0m                   train_labels\u001b[38;5;241m=\u001b[39mtrain_labels, test_labels\u001b[38;5;241m=\u001b[39mtest_labels,\n\u001b[1;32m    129\u001b[0m                   label_names\u001b[38;5;241m=\u001b[39mag_news_labels, model_name\u001b[38;5;241m=\u001b[39mmodel_name, save_dir\u001b[38;5;241m=\u001b[39msave_dir)\n",
      "Cell \u001b[0;32mIn[21], line 31\u001b[0m, in \u001b[0;36mget_average_embedding_vectors\u001b[0;34m(model, train_texts, test_texts)\u001b[0m\n\u001b[1;32m     29\u001b[0m         feats_train\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean([model\u001b[38;5;241m.\u001b[39mget(word, placeholder) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# For FastText\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m         feats_train\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean([model\u001b[38;5;241m.\u001b[39mget_word_vector(word) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Generate test embeddings\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m tqdm(test_texts, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating test embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "Cell \u001b[0;32mIn[21], line 31\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     29\u001b[0m         feats_train\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean([model\u001b[38;5;241m.\u001b[39mget(word, placeholder) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# For FastText\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m         feats_train\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean([\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_word_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Generate test embeddings\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m tqdm(test_texts, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating test embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Desktop/Courses/Semester2/ML and Datamining/Projects/Project 1/02462-Project-3/.venv/lib/python3.10/site-packages/fasttext/FastText.py:136\u001b[0m, in \u001b[0;36m_FastText.get_word_vector\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    134\u001b[0m b \u001b[38;5;241m=\u001b[39m fasttext\u001b[38;5;241m.\u001b[39mVector(dim)\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf\u001b[38;5;241m.\u001b[39mgetWordVector(b, word)\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def clean(text):\n",
    "    \"\"\"\n",
    "    Cleaning text of non-alphanumerics for GloVe and useful word vectors.\n",
    "    \"\"\"\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(translator).lower()\n",
    "\n",
    "\n",
    "def get_average_embedding_vectors(model, train_texts, test_texts):\n",
    "    \"\"\"\n",
    "    Generates average embedding vectors for train and test sets.\n",
    "    \"\"\"\n",
    "    feats_train = []\n",
    "    feats_test = []\n",
    "    placeholder = np.zeros_like(model['the'])  # Adjusted for GloVe\n",
    "\n",
    "    # Generate train embeddings\n",
    "    for text in tqdm(train_texts, desc=\"Generating train embeddings\"):\n",
    "        words = clean(text).split()\n",
    "        if hasattr(model, 'get'):  # For GloVe\n",
    "            feats_train.append(np.mean([model.get(word, placeholder) for word in words], axis=0))\n",
    "        else:  # For FastText\n",
    "            feats_train.append(np.mean([model.get_word_vector(word) for word in words], axis=0))\n",
    "\n",
    "    # Generate test embeddings\n",
    "    for text in tqdm(test_texts, desc=\"Generating test embeddings\"):\n",
    "        words = clean(text).split()\n",
    "        if hasattr(model, 'get'):  # For GloVe\n",
    "            feats_test.append(np.mean([model.get(word, placeholder) for word in words], axis=0))\n",
    "        else:  # For FastText\n",
    "            feats_test.append(np.mean([model.get_word_vector(word) for word in words], axis=0))\n",
    "\n",
    "    return np.array(feats_train), np.array(feats_test)\n",
    "\n",
    "\n",
    "def plot_pca_and_save(n_components, feats_train, feats_test, train_labels, test_labels, label_names, model_name, save_dir):\n",
    "    \"\"\"\n",
    "    Performs PCA on the features, plots the results, and saves the plots.\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=n_components)\n",
    "\n",
    "    # Fit and transform PCA\n",
    "    Vtrain = pca.fit_transform(feats_train)\n",
    "    Vtest = pca.transform(feats_test)\n",
    "    Vtrain_var_explained = pca.explained_variance_ratio_\n",
    "    Vtest_var_explained = pca.explained_variance_ratio_\n",
    "\n",
    "    # Create model subfolder\n",
    "    model_dir = os.path.join(save_dir, model_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    # Generate PCA scatter plots for train and test\n",
    "    colors = 'rgbk'\n",
    "    for label, transformed_vector, title, set_name in zip(\n",
    "        [train_labels, test_labels],\n",
    "        [Vtrain, Vtest],\n",
    "        [f'Training set var_explained: {sum(Vtrain_var_explained[:2]):.4f}', f'Test set var_explained: {sum(Vtest_var_explained[:2]):.4f}'],\n",
    "        ['train', 'test']\n",
    "    ):\n",
    "        plt.figure(figsize=(20, 6))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        for i in range(4):\n",
    "            plt.plot(transformed_vector[label == i, 0], transformed_vector[label == i, 1], '.', color=colors[i], label=label_names[i])\n",
    "        plt.legend()\n",
    "        plt.xlabel('PC1')\n",
    "        plt.ylabel('PC2')\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        for i in range(4):\n",
    "            plt.plot(transformed_vector[label == i, 1], transformed_vector[label == i, 2], '.', color=colors[i], label=label_names[i])\n",
    "        plt.legend()\n",
    "        plt.xlabel('PC2')\n",
    "        plt.ylabel('PC3')\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        for i in range(4):\n",
    "            plt.plot(transformed_vector[label == i, 2], transformed_vector[label == i, 3], '.', color=colors[i], label=label_names[i])\n",
    "        plt.legend()\n",
    "        plt.xlabel('PC3')\n",
    "        plt.ylabel('PC4')\n",
    "        plt.suptitle(title, fontweight='bold', fontsize=15)\n",
    "\n",
    "        # Save scatter plot\n",
    "        plot_path = os.path.join(model_dir, f\"{set_name}_pca_plot.png\")\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "\n",
    "    # Save explained variance plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(list(range(n_components)), np.cumsum(pca.explained_variance_ratio_))\n",
    "    plt.title(\"Explained variance compared to number of components\")\n",
    "    plt.xlabel(\"Number of components\")\n",
    "    plt.ylabel(\"Explained variance\")\n",
    "    plt.grid()\n",
    "    var_plot_path = os.path.join(model_dir, \"explained_variance_plot.png\")\n",
    "    plt.savefig(var_plot_path)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Plots saved for model: {model_name}\")\n",
    "    return pca\n",
    "\n",
    "\n",
    "# Model mapping and processing\n",
    "models = {\n",
    "    \"glove\": glove,  \n",
    "    \"fasttext_word_model\": fasttext_word_model,  \n",
    "    \"fasttext_char_model\": fasttext_char_model   \n",
    "}\n",
    "\n",
    "# Loop through all models\n",
    "save_dir = \"pca_plots\"  # Set the directory for saving PCA plots\n",
    "for model_name, current_model in models.items():\n",
    "    print(f\"Processing model: {model_name}\")\n",
    "\n",
    "    # Generate embeddings\n",
    "    feats_train, feats_test = get_average_embedding_vectors(current_model, train_texts, test_texts)\n",
    "\n",
    "    # Plot PCA and save results\n",
    "    plot_pca_and_save(n_components=50, feats_train=feats_train, feats_test=feats_test,\n",
    "                      train_labels=train_labels, test_labels=test_labels,\n",
    "                      label_names=ag_news_labels, model_name=model_name, save_dir=save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All three models were able to capture differences between categories effectively, as demonstrated by the clustering results. For all models, clusters for the categories (e.g., “World,” “Sports,” “Business,” and “Science/Technology”) are generally distinct, particularly along PC1 and PC2. This indicates that the embeddings from each model encode meaningful relationships between the categories. However, some overlap, especially between “Business” and “Sci/Tech,” is still evident. This is expected since these domains often share vocabulary and context.\n",
    "\n",
    "For FastText, both the character and word models show strong performance in concentrating variance into the first few dimensions. The explained variance (EV) was 0.7924 for the character model and 0.7626 for the word model. These results suggest that FastText embeddings encode their most meaningful information in a small number of dimensions, making them well-suited for low-dimensional tasks like clustering and visualization. The explained variance plots for FastText models further emphasize this, with the curves saturating quickly after just a few components.\n",
    "\n",
    "In contrast, the GloVe model shows a lower EV of 0.3053, indicating that its top principal components capture far less variance than the FastText models. The explained variance plot for GloVe exhibits a slower, logistic-like growth, reflecting the model’s reliance on a larger number of dimensions to effectively represent the data. While this limits its effectiveness in reduced-dimensional spaces, it does not necessarily imply that GloVe is inferior overall. Instead, it highlights that GloVe embeddings spread their information across more dimensions, potentially allowing for nuanced representations in high-dimensional tasks.\n",
    "\n",
    "Conclusion:\n",
    "While all models demonstrated the ability to cluster categories effectively, FastText outperforms GloVe in representing clusters in lower-dimensional spaces. This makes FastText better suited for tasks that rely on dimensionality reduction. However, GloVe may excel in high-dimensional applications where the full embedding space can be utilized to capture more nuanced contextual information. The choice between these models should therefore depend on the specific task and whether low-dimensional or high-dimensional representations are more critical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 PCA projection\n",
    "\n",
    "**1. Complete the function below to get a word vector a word and project it to a given PCA with n principal components**\n",
    "\n",
    "\n",
    "**2. Comment on the plot created two cells below. Do the vectors correspond to what you'd expect?**\n",
    "\n",
    "Yes we see very sufficient contextual clustering between animals, technology-related words and business-related words.\n",
    "\n",
    "**3. What must we be cognisant of when doing PCA plots like this on $n$ principal components?**\n",
    "\n",
    "When performing PCA plots with n principal components, it is important to recognize that dimensionality reduction may lead to information loss. The clusters observed in 2D are approximations and may not fully capture the true relationships in the original high-dimensional space. Additionally, the explained variance of the selected components should be carefully evaluated to ensure that a meaningful proportion of the variance is retained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_model = glove\n",
    "# current_model_name = \"glove\" \n",
    "\n",
    "# current_model = fasttext_word_model\n",
    "# current_model_name = \"fasttext_word_model\"\n",
    "\n",
    "current_model = fasttext_char_model\n",
    "current_model_name = \"fasttext_char_model\"\n",
    "n = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "n_components=20 must be between 0 and min(n_samples, n_features)=6 with svd_solver='full'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Fit PCA\u001b[39;00m\n\u001b[0;32m     29\u001b[0m pca_word_vec \u001b[38;5;241m=\u001b[39m PCA(n_components\u001b[38;5;241m=\u001b[39mn)\n\u001b[1;32m---> 30\u001b[0m \u001b[43mpca_word_vec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword_vectors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Transform word vectors\u001b[39;00m\n\u001b[0;32m     33\u001b[0m transformed_word_vectors \u001b[38;5;241m=\u001b[39m [get_vector_transform(i, current_model, pca_word_vec, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m words]\n",
      "File \u001b[1;32mc:\\Users\\mathi\\.conda\\envs\\02462\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mathi\\.conda\\envs\\02462\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py:448\u001b[0m, in \u001b[0;36mPCA.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    432\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model with X.\u001b[39;00m\n\u001b[0;32m    433\u001b[0m \n\u001b[0;32m    434\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;124;03m        Returns the instance itself.\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 448\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\mathi\\.conda\\envs\\02462\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py:547\u001b[0m, in \u001b[0;36mPCA._fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;66;03m# Call different fits for either full or truncated SVD\u001b[39;00m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcovariance_eigh\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 547\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_full\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_components\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_array_api_compliant\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    548\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marpack\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandomized\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    549\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_truncated(X, n_components, xp)\n",
      "File \u001b[1;32mc:\\Users\\mathi\\.conda\\envs\\02462\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py:561\u001b[0m, in \u001b[0;36mPCA._fit_full\u001b[1;34m(self, X, n_components, xp, is_array_api_compliant)\u001b[0m\n\u001b[0;32m    557\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    558\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_components=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmle\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is only supported if n_samples >= n_features\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    559\u001b[0m         )\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m n_components \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(n_samples, n_features):\n\u001b[1;32m--> 561\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    562\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_components=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_components\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be between 0 and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    563\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin(n_samples, n_features)=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmin\u001b[39m(n_samples,\u001b[38;5;250m \u001b[39mn_features)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    564\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvd_solver=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    565\u001b[0m     )\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_ \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mmean(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    568\u001b[0m \u001b[38;5;66;03m# When X is a scipy sparse matrix, self.mean_ is a numpy matrix, so we need\u001b[39;00m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;66;03m# to transform it to a 1D array. Note that this is not the case when X\u001b[39;00m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;66;03m# is a scipy sparse array.\u001b[39;00m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;66;03m# TODO: remove the following two lines when scikit-learn only depends\u001b[39;00m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;66;03m# on scipy versions that no longer support scipy.sparse matrices.\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: n_components=20 must be between 0 and min(n_samples, n_features)=6 with svd_solver='full'"
     ]
    }
   ],
   "source": [
    "# Function to save plot\n",
    "def save_plot(fig, filename, folder=\"plots\"):\n",
    "    \"\"\"\n",
    "    Saves the current plot to the specified folder with the given filename.\n",
    "\n",
    "    Args:\n",
    "        fig: Matplotlib figure object.\n",
    "        filename (str): Name of the file to save (e.g., 'plot.png').\n",
    "        folder (str): Folder where the plot should be saved.\n",
    "    \"\"\"\n",
    "    # Ensure the folder exists\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # Save the figure\n",
    "    fig.savefig(os.path.join(folder, filename), bbox_inches=\"tight\")\n",
    "    print(f\"Plot saved to {os.path.join(folder, filename)}\")\n",
    "\n",
    "def get_vector_transform(word, model, pca, n=2):\n",
    "    word_vec = model[word]\n",
    "    word_vec = word_vec.reshape(1, -1)\n",
    "    transformed_vec = pca.transform(word_vec)[:, :n]  # Select the top n components\n",
    "    return transformed_vec.flatten()  # Return the flattened vector\n",
    "\n",
    "# Collect word vectors for the given words\n",
    "words = ['company', 'business', 'cat', 'software', 'microsoft', 'mouse']\n",
    "word_vectors = np.array([current_model[word] for word in words if word in current_model])\n",
    "\n",
    "# Fit PCA\n",
    "pca_word_vec = PCA(n_components=n)\n",
    "pca_word_vec.fit(word_vectors)\n",
    "\n",
    "# Transform word vectors\n",
    "transformed_word_vectors = [get_vector_transform(i, current_model, pca_word_vec, n=2) for i in words]\n",
    "\n",
    "# Plot transformed vectors\n",
    "fig = plt.figure(figsize=(28, 10))  # Create a figure to save later\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "\n",
    "for idx, vec in enumerate(transformed_word_vectors):\n",
    "    # Plot line from origin to transformed vector\n",
    "    plt.plot([0, vec[0]], [0, vec[1]], 'b--')\n",
    "    # Add a circle at the transformed vector position\n",
    "    circle = plt.Circle((vec[0], vec[1]), radius=0.015, color='blue', fill=False)\n",
    "    ax.add_patch(circle)\n",
    "    # Annotate the word at the transformed vector position\n",
    "    label = ax.annotate(words[idx], xy=(vec[0], vec[1]), fontsize=20, ha=\"center\", va=\"center\")\n",
    "\n",
    "# Add labels\n",
    "plt.xlabel('Latent Semantic dim 1')\n",
    "plt.ylabel('Latent Semantic dim 2')\n",
    "plt.title(f'PCA Projection of Word Embeddings ({current_model_name})')\n",
    "\n",
    "# Generate filename with model name\n",
    "filename = f\"word_embeddings_pca_{current_model_name}.png\"\n",
    "\n",
    "# Save the plot to a file\n",
    "save_plot(fig, filename)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Comparing with more principal components\n",
    "\n",
    "**1. Run the cell below to compare different words to the previous list of words. How do they compare? Do these comparisons change significantly when you run with more principal components?**\n",
    "\n",
    "\n",
    "Similar Words:\n",
    "Words that are contextually similar, like \"software\" and \"microsoft\", have high similarity scores (e.g., 0.7986).\n",
    "\"business\" and \"company\" also have a relatively high similarity score (0.3158), aligning with their shared semantic context.\n",
    "\n",
    "Dissimilar Words:\n",
    "Words from different contexts, such as \"cat\" and \"software\" or \"mouse\" and \"business\", show negative or low similarity scores (e.g., -0.3071 for \"cat-software\").\n",
    "\n",
    "Self-Similarity:\n",
    "As expected, comparisons of the same word yield a similarity of 1.0 (e.g., \"software-software\").\n",
    "\n",
    "Unexpected Patterns:\n",
    "Some unrelated pairs have unexpectedly high similarity scores (e.g., \"mouse-business\": 0.3093), likely due to information loss when reducing to just 2 principal components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA expects 100 dimensions and transforms to 2 components\n"
     ]
    }
   ],
   "source": [
    "print(f\"PCA expects {pca_word_vec.n_features_in_} dimensions and transforms to {pca_word_vec.n_components_} components\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector_transform(word, model, pca, n=2):\n",
    "    word_vec = model[word]\n",
    "    word_vec = word_vec.reshape(1, -1)\n",
    "    transformed_vec = pca.transform(word_vec)[:, :n]  # Select the top n components\n",
    "    return transformed_vec.flatten()  # Return the flattened vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio: [0.7332802  0.23953347]\n",
      "Cumulative explained variance: [0.7332802  0.97281367]\n"
     ]
    }
   ],
   "source": [
    "print(\"Explained variance ratio:\", pca_word_vec.explained_variance_ratio_)\n",
    "print(\"Cumulative explained variance:\", np.cumsum(pca_word_vec.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company-software: 0.2104349285364151\n",
      "company-business: 0.2916577458381653\n",
      "company-world: -0.8140895962715149\n",
      "\n",
      "business-software: -0.8737291097640991\n",
      "business-business: 1.0\n",
      "business-world: 0.3180547058582306\n",
      "\n",
      "cat-software: -0.34435489773750305\n",
      "cat-business: -0.1557905077934265\n",
      "cat-world: 0.8869464993476868\n",
      "\n",
      "software-software: 0.9999998807907104\n",
      "software-business: -0.8737291097640991\n",
      "software-world: -0.7390480041503906\n",
      "\n",
      "microsoft-software: 0.8170966506004333\n",
      "microsoft-business: -0.4335038959980011\n",
      "microsoft-world: -0.9922348856925964\n",
      "\n",
      "mouse-software: -0.7266018986701965\n",
      "mouse-business: 0.30065926909446716\n",
      "mouse-world: 0.9998326301574707\n",
      "\n"
     ]
    }
   ],
   "source": [
    "to_compare = ['software', 'business', 'world'] # Three words, that should be labeled as three different things\n",
    "for word in words:\n",
    "    for comparison in to_compare:\n",
    "        distance = word_similarity(\n",
    "                                    vec1=get_vector_transform(word, current_model, pca_word_vec, n=n),\n",
    "                                    vec2=get_vector_transform(comparison, current_model, pca_word_vec,n=n),\n",
    "                                    glove=None\n",
    "                                    )\n",
    "        print(f\"{word}-{comparison}: {distance}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Exercise 5 Screwing around with fasttext models\n",
    "\n",
    "*A good thing if we want to use fasttext on a character level, is that it will be able to understand spelling errors. We're going to test this now by replacing a bunch of letters in our test set randomly with other words and once more test the accuracy of the word-wise fasttext vs the character-wise fasttext*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def dyslexibot(test_set: list, p=0.05, extra_scuffed=False):\n",
    "    \"\"\"\n",
    "    tHe AlMiGhTy dyslexibot(tm) replaces letters with probability p\n",
    "    extra_scuffed does what it says: it makes the replacements even harder to guess\n",
    "    This function is pretty ineffective, if you want to spruce it up, you are welcome to do so\n",
    "    \"\"\"\n",
    "\n",
    "    if extra_scuffed:\n",
    "        test_set_letters = np.array(list(set(''.join(test_texts)))) # Can replace with all letters currently in test set\n",
    "    else:\n",
    "        test_set_letters = np.array(list(string.ascii_lowercase)) # Can only replace with lowercase letters\n",
    "\n",
    "    new_test_set = [text.split(' ') for text in test_set.copy()]\n",
    "\n",
    "    print(\"Replacing text\")\n",
    "    for i, text in tqdm(enumerate(new_test_set)):\n",
    "        for r, word in enumerate(text):\n",
    "            word = list(word)\n",
    "            for t, letter in enumerate(word):\n",
    "                rand = random.uniform(0, 1)\n",
    "\n",
    "                if extra_scuffed and rand < p: # We replace even spaces!\n",
    "                    word[t] = np.random.choice(test_set_letters)\n",
    "                    #new_test_set[i][r] = np.random.choice(test_set_letters)\n",
    "\n",
    "                elif letter != ' ' and rand < p:\n",
    "                    word[t] = np.random.choice(test_set_letters)\n",
    "                    #new_test_set[i][r] = np.random.choice(test_set_letters)\n",
    "\n",
    "            text[r] = ''.join(word)\n",
    "        new_test_set[i] = ' '.join(text)\n",
    "    return np.array(new_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['have you heard of ths tragedy of darth plagueis the wise']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Showing that dyslexibot works\n",
    "text = [\"have you heard of the tragedy of darth plagueis the wise\"]\n",
    "print(dyslexibot(text, p=0.10, extra_scuffed=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Dyslexibot and fasttext\n",
    "\n",
    "**1. Test both the fasttext_word_model and the fasttext_char_model on text generated by dyslexibot. Change the $p$ value and perhaps the $\\text{extra scuffed}$ option. Try to make the fasttext_word_model as bad as possible while the fasttext_char_model still keeps somewhat good performance. Comment on what you did to achieve this.**\n",
    "\n",
    "As the $p$ value increases, the performance of both models worsens. This is because the $p$ value represents the probability of inserted noise in the text. The character-wise model performs way better here, due to its ability to discern character-wise patterns, while the word-wise is unable to find a decent pattern. The extra scuffed option further decreases performance by replacing characters with any other character in the test set, while disabling it only replaces with lowercase letters, which simulates common misspellings. You can imagine this would only further mess up the word-wise model, but also decrease character-wise performance by a little.\n",
    "\n",
    "The performance for the character-wise model could still be further improved by training the fasttext model on noisy data generated from the dyslexibot, while the word-wise model still wouldn't gain as much from this, since the words are dyslexified at random.\n",
    "\n",
    "In conclusion, the character-wise model is highly unaffected by misspellings compared to the word-wise model, but it also took 10 times as long to test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7600it [00:04, 1798.81it/s]\n"
     ]
    }
   ],
   "source": [
    "dyslexitext = dyslexibot(test_texts, p=0.20, extra_scuffed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7600it [00:02, 3025.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7600it [00:04, 1730.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7600it [00:06, 1206.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7600it [00:08, 944.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7600it [00:09, 776.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7600it [00:11, 637.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7600it [00:13, 550.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7600it [00:14, 509.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7600it [00:16, 447.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7600it [00:19, 395.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7600it [00:02, 3075.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7600it [00:04, 1745.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7600it [00:06, 1239.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7600it [00:07, 990.50it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7600it [00:09, 789.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7600it [00:11, 667.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7600it [00:13, 553.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7600it [00:15, 497.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7600it [00:17, 444.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7600it [00:18, 412.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word model testing time: 3.1491458415985107\n",
      "Char model testing time: 24.38598370552063\n"
     ]
    }
   ],
   "source": [
    "# Define the probabilities and extra_scuffed options to test\n",
    "p_values = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "extra_scuffed_options = [False, True]\n",
    "\n",
    "# Initialize lists to store results\n",
    "results = []\n",
    "\n",
    "word_time = []\n",
    "char_time = []\n",
    "\n",
    "for extra_scuffed in extra_scuffed_options:\n",
    "    for p in p_values:\n",
    "        # Generate noisy test data\n",
    "        dyslexitext = dyslexibot(test_texts, p=p, extra_scuffed=extra_scuffed)\n",
    "        \n",
    "        # Test the word-level fastText model\n",
    "        s1 = time.time()\n",
    "        word_accs, word_total_acc = test_fasttext_model(fasttext_word_model, dyslexitext, test_labels, ag_news_labels)\n",
    "        e1 = time.time()\n",
    "\n",
    "        # Test the character-level fastText model\n",
    "        s2 = time.time()\n",
    "        char_accs, char_total_acc = test_fasttext_model(fasttext_char_model, dyslexitext, test_labels, ag_news_labels)\n",
    "        e2 = time.time()\n",
    "\n",
    "        word_time.append(e1 - s1)\n",
    "        char_time.append(e2 - s2)\n",
    "\n",
    "        # Save results for dataframe\n",
    "        results.append({\n",
    "            'Extra Scuffed': extra_scuffed,\n",
    "            'p Value': p,\n",
    "            'Word Model Accuracy': word_total_acc,\n",
    "            'Char Model Accuracy': char_total_acc\n",
    "        })\n",
    "\n",
    "# Print time difference\n",
    "print(f\"Word model testing time: {np.sum(word_time)}\")\n",
    "print(f\"Char model testing time: {np.sum(char_time)}\")\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "df_results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will plot the accuracy vs probability of character replacement, for both scuffed and not scuffed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+kAAAK9CAYAAABYVS0qAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdd3xN9//A8dfNzc3eskSsBDFrlqJErAQ1SlF7z7baUqpVNWtUqFBCraBVs1Rrj4RQsxpUjIi9d2Sve35/5Jv7c2VINNxI3s8+7kPu53zO57zPyUma9/18zuejUhRFQQghhBBCCCGEEAZnZOgAhBBCCCGEEEIIkUaSdCGEEEIIIYQQIp+QJF0IIYQQQgghhMgnJEkXQgghhBBCCCHyCUnShRBCCCGEEEKIfEKSdCGEEEIIIYQQIp+QJF0IIYQQQgghhMgnJEkXQgghhBBCCCHyCUnShRBCCCGEEEKIfEKSdCGEeIOpVCrGjx+f6/2uXLmCSqUiKCgoz2P6L1auXEn58uXRaDTY2dkZOpxCqVSpUvTu3TvHdd97771XG9Br9rI/U/nZ+PHjUalUhg4j3wgJCUGlUhESEmLoUIQQIlOSpAshxH8UFBSESqVCpVJx4MCBDNsVRaF48eKoVKo3LqFJ/2M2/aXRaPDw8KBnz55cunQpT4917tw5evfujaenJ4sWLeKnn37K0/bFywkPD2f8+PFcuXIlz9r87bffUKlULF68OMs6u3btQqVSMWfOnDw7bn6W/sGZSqViw4YNGbanJ9oPHjwwQHS517t3b6ysrAwdhhBCvJGMDR2AEEIUFGZmZqxatYp3331Xr3zfvn3cuHEDU1NTA0X23w0bNoy3336b5ORkTpw4wU8//cSWLVs4ffo0bm5ueXKMkJAQtFotAQEBlClTJk/aFLl3/vx5jIz+/zP88PBwJkyYQKNGjShVqlSeHKNVq1bY2tqyatUq+vfvn2mdVatWoVar+fDDD/PkmDkVHx+PsbFh/zyaOHEi7du3z7Pe72+++YbRo0fnSVtCCCFePelJF0KIPNKyZUvWrVtHSkqKXvmqVauoWbMmrq6uBorsv2vQoAHdu3enT58+zJ07F39/fx49esTy5cv/c9uxsbEA3Lt3DyBPh7nHxcXlWVuFhampKRqN5pUf44MPPmDfvn3cunUrw/aEhAQ2btxIs2bNcHZ2funjKIpCfHx8rvYxMzMzaJJerVo1Tp06xcaNG/OsTWNjY8zMzPKsPSGEEK+WJOlCCJFHunTpwsOHD9m1a5euLCkpifXr19O1a9dM94mNjWXEiBEUL14cU1NTvLy88Pf3R1EUvXqJiYl8/vnnODk5YW1tTZs2bbhx40ambd68eZO+ffvi4uKCqakplSpVYunSpXl3okDjxo0BuHz5sq5s27ZtNGjQAEtLS6ytrWnVqhVnzpzR2y99CGxkZCQtW7bE2tqabt26UapUKcaNGweAk5NThueC58+fT6VKlTA1NcXNzY2PPvqIJ0+e6LXdqFEjKleuzN9//03Dhg2xsLDg66+/1g0j9vf3Z968eXh4eGBhYUHz5s25fv06iqIwadIk3N3dMTc3p23btjx69Eiv7d9//51WrVrh5uaGqakpnp6eTJo0idTU1ExjCA8Px8fHBwsLC4oVK8b333+f4RomJCQwfvx4ypUrh5mZGUWLFqV9+/ZERkbq6mi1WmbPnk2lSpUwMzPDxcWFQYMG8fjx42y/P5s3b0alUnHq1Cld2YYNG1CpVLRv316vboUKFejcubPu/bPPpAcFBdGxY0cAfHx8dMOxn3+W98CBA9SuXRszMzM8PDxYsWJFtvEBdO/eHa1Wy+rVqzNs27JlC1FRUXTr1g2AZcuW0bhxY5ydnTE1NaVixYoEBgZm2C/9GfkdO3ZQq1YtzM3NWbhwId7e3lStWjXTOLy8vPD19dW9f/7eSx9mfvHiRXr37o2dnR22trb06dMnw4dA8fHxDBs2DEdHR93P6c2bN3P1nPuHH35IuXLlmDhxYobfA5lZt24dNWvWxNzcHEdHR7p3787Nmzf16mT2TPquXbt49913sbOzw8rKCi8vL77++mu9OomJiYwbN44yZcpgampK8eLFGTVqFImJiTk6l5w4cuQIfn5+2NraYmFhgbe3NwcPHtRtX79+PSqVin379mXYd+HChahUKv79919d2blz5/jggw9wcHDAzMyMWrVqsXnz5hfGERERQYcOHXB1dcXMzAx3d3c+/PBDoqKi8uZEhRAiFyRJF0KIPFKqVCnq1q3Lr7/+qivbtm0bUVFRmQ7ZVRSFNm3a8MMPP+Dn58esWbPw8vJi5MiRDB8+XK9u//79mT17Ns2bN2fatGloNBpatWqVoc27d+/yzjvvsHv3bj7++GPd0PF+/foxe/bsPDvX9ESySJEiQNqEb61atcLKyorp06czduxYwsPDeffddzM8y5ySkoKvry/Ozs74+/vToUMHZs+ezfvvvw9AYGAgK1eu1CWT48eP56OPPsLNzY2ZM2fSoUMHFi5cSPPmzUlOTtZr++HDh7Ro0YJq1aoxe/ZsfHx8dNt++eUX5s+fzyeffMKIESPYt28fnTp14ptvvmH79u18+eWXDBw4kD/++IMvvvhCr92goCCsrKwYPnw4AQEB1KxZk2+//TbTIcSPHz/Gz8+PqlWrMnPmTMqXL8+XX37Jtm3bdHVSU1N57733mDBhAjVr1mTmzJl8+umnREVF6SUcgwYNYuTIkdSvX5+AgAD69OnDL7/8gq+vb4Zzf9a7776LSqVi//79urLQ0FCMjIz05k24f/8+586do2HDhpm207BhQ4YNGwbA119/zcqVK1m5ciUVKlTQ1bl48SIffPABzZo1Y+bMmdjb29O7d+8MH9Bk1ra7uzurVq3KsG3VqlVYWFjQrl07IO2eKFmyJF9//TUzZ86kePHiDB06lHnz5mXY9/z583Tp0oVmzZoREBBAtWrV6NGjB6dOndK7tgDHjh3jwoULdO/ePdtYATp16kR0dDRTp06lU6dOBAUFMWHCBL06vXv3Zu7cubRs2ZLp06djbm6e6c9pdtRqNd988w0nT558YW96UFAQnTp1Qq1WM3XqVAYMGMBvv/3Gu+++m+FDrGedOXOG9957j8TERCZOnMjMmTNp06aNXnKs1Wpp06YN/v7+tG7dmrlz59KuXTt++OEHvQ91/ou9e/fSsGFDnj59yrhx45gyZQpPnjyhcePGHD16FED3e2Xt2rUZ9l+zZg2VKlWicuXKuvN65513OHv2LKNHj2bmzJlYWlrSrl27bK9lUlISvr6+HD58mE8++YR58+YxcOBALl26lO11FEKIV0YRQgjxnyxbtkwBlGPHjik//vijYm1trcTFxSmKoigdO3ZUfHx8FEVRlJIlSyqtWrXS7bdp0yYFUCZPnqzX3gcffKCoVCrl4sWLiqIoSlhYmAIoQ4cO1avXtWtXBVDGjRunK+vXr59StGhR5cGDB3p1P/zwQ8XW1lYX1+XLlxVAWbZsWbbnFhwcrADK0qVLlfv37yu3bt1StmzZopQqVUpRqVTKsWPHlOjoaMXOzk4ZMGCA3r537txRbG1t9cp79eqlAMro0aMzHGvcuHEKoNy/f19Xdu/ePcXExERp3ry5kpqaqiv/8ccfdXGl8/b2VgBlwYIFeu2mn6uTk5Py5MkTXflXX32lAErVqlWV5ORkXXmXLl0UExMTJSEhQVeWft2eNWjQIMXCwkKvXnoMK1as0JUlJiYqrq6uSocOHXRlS5cuVQBl1qxZGdrVarWKoihKaGioAii//PKL3vbt27dnWv68SpUqKZ06ddK9r1GjhtKxY0cFUM6ePasoiqL89ttvCqCcPHlSV69kyZJKr169dO/XrVunAEpwcHCGY5QsWVIBlP379+vK7t27p5iamiojRozINj5FUZSRI0cqgHL+/HldWVRUlGJmZqZ06dJFV5bZ9ff19VU8PDwyjWf79u165U+ePFHMzMyUL7/8Uq982LBhiqWlpRITE6Mre/5nKv2+7Nu3r96+77//vlKkSBHd+7///lsBlM8++0yvXu/evTO0mZn0+3TGjBlKSkqKUrZsWaVq1aq6++H5n4+kpCTF2dlZqVy5shIfH69r588//1QA5dtvv81wDul++OGHDD9rz1u5cqViZGSkhIaG6pUvWLBAAZSDBw9mez69evVSLC0ts9yu1WqVsmXLKr6+vrpzVJS073Xp0qWVZs2a6cq6dOmiODs7KykpKbqy27dvK0ZGRsrEiRN1ZU2aNFGqVKmi9zOp1WqVevXqKWXLltWVpf9eS7+n//nnHwVQ1q1bl+05CSHE6yI96UIIkYc6depEfHw8f/75J9HR0fz5559ZDnXfunUrarVa11OZbsSIESiKout53bp1K0CGep999pnee0VR2LBhA61bt0ZRFB48eKB7+fr6EhUVxYkTJ17qvPr27YuTkxNubm60atWK2NhYli9fTq1atdi1axdPnjyhS5cuesdUq9XUqVOH4ODgDO0NGTIkR8fdvXs3SUlJfPbZZ3qTmQ0YMAAbGxu2bNmiV9/U1JQ+ffpk2lbHjh2xtbXVva9Tpw6QNuz62WeQ69SpQ1JSkt6QYXNzc93X0dHRPHjwgAYNGhAXF8e5c+f0jmNlZaXXM2tiYkLt2rX1ZsPfsGEDjo6OfPLJJxniTB+WvG7dOmxtbWnWrJneda1ZsyZWVlaZXtdnNWjQgNDQUF3MJ0+eZODAgTg6OurKQ0NDsbOz0/VEvoyKFSvSoEED3XsnJye8vLxyNPt/+nV6tjd9w4YNJCQk6Ia6g/71j4qK4sGDB3h7e3Pp0qUMw5FLly6tN3wdwNbWlrZt2/Lrr7/qhpCnpqayZs0a2rVrh6Wl5QtjHTx4sN77Bg0a8PDhQ54+fQrA9u3bARg6dKhevcy+xy/ybG/6pk2bMq1z/Phx7t27x9ChQ/WeN2/VqhXly5fP8LPxrPR5H37//Xe0Wm2mddatW0eFChUoX7683v2X/qjLi+6/FwkLCyMiIoKuXbvy8OFDXfuxsbE0adKE/fv362Lr3Lkz9+7d03vMYv369Wi1Wl2v/qNHj9i7d69uxEN6ew8fPsTX15eIiIgMjwGkS/+9sGPHDpnHQgiRL0iSLoQQecjJyYmmTZuyatUqfvvtN1JTU/nggw8yrXv16lXc3NywtrbWK08fSnz16lXdv0ZGRnh6eurV8/Ly0nt///59njx5wk8//YSTk5PeKz1xTZ+cLbe+/fZbdu3axd69ezl16hS3bt2iR48eQNqznJD2nPrzx925c2eGYxobG+Pu7p6j46Zfg+fP1cTEBA8PD932dMWKFcPExCTTtkqUKKH3Pv0P8+LFi2da/uxz32fOnOH999/H1tYWGxsbnJycdAnm80miu7t7hud/7e3t9dqLjIzEy8sr2wnKIiIiiIqKwtnZOcN1jYmJeeH3skGDBty+fZuLFy/y119/oVKpqFu3rl7yHhoaSv369fU+AMmt568rZDzfrLz11ltUrlxZ7xGRVatW4ejoqJdoHzx4kKZNm2JpaYmdnR1OTk6656czS9Iz07NnT65du6Y79927d3P37l3dffwiz5+nvb098P/3SfrP6fPHf9mVCrp160aZMmWyfDY9q58NgPLly2f42XhW586dqV+/Pv3798fFxYUPP/yQtWvX6iXsERERnDlzJsO9V65cOeDlf5c82z5Ar169Mhxj8eLFJCYm6r636c+sr1mzRrf/mjVrqFatmi6eixcvoigKY8eOzdBe+nwXWcVcunRphg8fzuLFi3X33rx58+R5dCGEwcgSbEIIkce6du3KgAEDuHPnDi1atMjT2cqzk/4Hdvfu3enVq1emdd56662XartKlSo0bdo02+OuXLky0xnsn09ETU1N/1NSmJ1ne1yfp1arc1Wenhg9efIEb29vbGxsmDhxIp6enpiZmXHixAm+/PLLDD2RL2ovp7RaLc7Ozvzyyy+Zbndycsp2//SlAPfv38+lS5eoUaMGlpaWNGjQgDlz5hATE8M///zDd999l6u4nvdfz7d79+6MHj2a48eP4+7uTnBwMIMGDdLdN5GRkTRp0oTy5csza9YsihcvjomJCVu3buWHH37IcP2zugd8fX1xcXHh559/pmHDhvz888+4urpmeV/n9XnmVnpveu/evfn999/ztG1zc3P2799PcHAwW7ZsYfv27axZs4bGjRuzc+dO1Go1Wq2WKlWqMGvWrEzbeP7DrdxK/77NmDGDatWqZVonfZ11U1NT3XPl8+fP5+7duxw8eJApU6ZkaO+LL77IMJIiXXYfmMycOVN3rXfu3MmwYcOYOnUqhw8fzvGHikIIkVckSRdCiDz2/vvvM2jQIA4fPqzX8/O8kiVLsnv3bqKjo/V609OHT5csWVL3r1ar1fW+pjt//rxee+kzv6empuY48cgL6T38zs7OeX7c9Gtw/vx5PDw8dOVJSUlcvnz5tZxnSEgIDx8+5LffftObYO3Zme1zy9PTkyNHjpCcnJzlcmeenp7s3r2b+vXrZ/vhQ1ZKlChBiRIlCA0N5dKlS7oh6Q0bNmT48OGsW7eO1NTULCeNS5dXa3VnpUuXLnz11VesWrWKkiVLkpqaqjfU/Y8//iAxMZHNmzfr9Wbndri1Wq2ma9euBAUFMX36dDZt2sSAAQOyTL5zK/3n9PLly5QtW1ZXfvHixZdus3v37kyePJkJEybQpk2bDMeDtJ+N9CHo6c6fP6/bnhUjIyOaNGlCkyZNmDVrFlOmTGHMmDEEBwfTtGlTPD09OXnyJE2aNHkl90D67w0bG5sc/Rx37tyZ5cuXs2fPHs6ePYuiKHoT2KX/ftBoNC/9e6FKlSpUqVKFb775hr/++ov69euzYMECJk+e/FLtCSHEy5Lh7kIIkcesrKwIDAxk/PjxtG7dOst6LVu2JDU1lR9//FGv/IcffkClUtGiRQsA3b9z5szRq/f8bO1qtZoOHTqwYcOGDLNYQ9pw+FfB19cXGxsbpkyZkumM4//luE2bNsXExIQ5c+bo9VguWbKEqKioXM+c/TLSk7hnj5+UlMT8+fNfus0OHTrw4MGDDN/7Z4/TqVMnUlNTmTRpUoY6KSkpOZp1ukGDBuzdu5ejR4/qkvRq1aphbW3NtGnTMDc3p2bNmtm2kf689qua5bpEiRI0aNCANWvW8PPPP1O6dGnq1aun257Z9Y+KimLZsmW5PlaPHj14/PgxgwYNIiYmJkezuudUeu/t8/fF3LlzX7rN9N70sLCwDMuI1apVC2dnZxYsWKC3JNq2bds4e/Zstj8bzy8xCOh6s9Pb6tSpEzdv3mTRokUZ6sbHxxMbG/syp6RTs2ZNPD098ff3JyYmJsP2539vNG3aFAcHB9asWcOaNWuoXbu23qMFzs7ONGrUiIULF3L79u0Xtvesp0+fkpKSoldWpUoVjIyM8nS5OSGEyCnpSRdCiFcgq+Hmz2rdujU+Pj6MGTOGK1euULVqVXbu3Mnvv//OZ599putpqlatGl26dGH+/PlERUVRr1499uzZk2kP3bRp0wgODqZOnToMGDCAihUr8ujRI06cOMHu3bsz/eP8v7KxsSEwMJAePXpQo0YNPvzwQ5ycnLh27Rpbtmyhfv36mSajOeHk5MRXX33FhAkT8PPzo02bNpw/f5758+fz9ttv52mSlZV69ephb29Pr169GDZsGCqVipUrV/6nYc49e/ZkxYoVDB8+XJdAx8bGsnv3boYOHUrbtm3x9vZm0KBBTJ06lbCwMJo3b45GoyEiIoJ169YREBCQ5XwH6Ro0aMAvv/yCSqXSDX9Xq9XUq1ePHTt20KhRoyyf4U9XrVo11Go106dPJyoqClNTU92a5Xmle/fuDBw4kFu3bjFmzBi9bc2bN8fExITWrVvrkutFixbh7OycaTKWnerVq1O5cmXdpGg1atTIs3OoWbOmbjnBhw8f8s4777Bv3z4uXLgAvPyIhG7dujFp0iTCwsL0yjUaDdOnT6dPnz54e3vTpUsX7t69S0BAAKVKleLzzz/Pss2JEyeyf/9+WrVqRcmSJbl37x7z58/H3d1dd5/06NGDtWvXMnjwYIKDg6lfvz6pqamcO3eOtWvX6taiz05ycnKmvdAODg4MHTqUxYsX06JFCypVqkSfPn0oVqwYN2/eJDg4GBsbG/744w+9823fvj2rV68mNjYWf3//DO3OmzePd999lypVqjBgwAA8PDy4e/cuhw4d4saNG5w8eTLTOPfu3cvHH39Mx44dKVeuHCkpKaxcuVL3wacQQrx2r39CeSGEKFieXYItO88vwaYoihIdHa18/vnnipubm6LRaJSyZcsqM2bM0FuSSFEUJT4+Xhk2bJhSpEgRxdLSUmndurVy/fr1TJd2unv3rvLRRx8pxYsXVzQajeLq6qo0adJE+emnn3R1crsEW06WJgoODlZ8fX0VW1tbxczMTPH09FR69+6tHD9+XFcnu2WZMluCLd2PP/6olC9fXtFoNIqLi4syZMgQ5fHjx3p1vL29lUqVKmXY99mlrXJybpl9Pw8ePKi88847irm5ueLm5qaMGjVK2bFjR4alybKKoVevXkrJkiX1yuLi4pQxY8YopUuX1n2fPvjgAyUyMlKv3k8//aTUrFlTMTc3V6ytrZUqVaooo0aNUm7dupXhOM87c+aMAigVKlTQK588ebICKGPHjs2wz/NLsCmKoixatEjx8PBQ1Gq13jlndk+nXwdvb+8Xxpfu0aNHiqmpqQIo4eHhGbZv3rxZeeuttxQzMzOlVKlSyvTp03XL2F2+fFkv9sziedb333+vAMqUKVMy3f78z1RW92X6ffLs8WNjY5WPPvpIcXBwUKysrJR27dop58+fVwBl2rRp2caV1X367LEyi2PNmjVK9erVFVNTU8XBwUHp1q2bcuPGDb06zy/BtmfPHqVt27aKm5ubYmJiori5uSldunRRLly4oLdfUlKSMn36dKVSpUqKqampYm9vr9SsWVOZMGGCEhUVle35pC+3mNnL09NTV++ff/5R2rdvrxQpUkQxNTVVSpYsqXTq1EnZs2dPhjZ37dqlAIpKpVKuX7+e6XEjIyOVnj17Kq6uropGo1GKFSumvPfee8r69et1dZ5fgu3SpUtK3759FU9PT8XMzExxcHBQfHx8lN27d2d7jkII8aqoFOUVzXgihBBCCJHPBAQE8Pnnn3PlypVMZ6bPa2FhYVSvXp2ff/5Z71l7IYQQIivyTLoQQgghCgVFUViyZAne3t6vJEGPj4/PUDZ79myMjIxeOEGfEEIIkU6eSRdCCCFEgRYbG8vmzZsJDg7m9OnTeb6kWbrvv/+ev//+Gx8fH4yNjdm2bRvbtm1j4MCB/3nJMiGEEIWHDHcXQgghRIF25coVSpcujZ2dHUOHDv3Pa8NnZdeuXUyYMIHw8HBiYmIoUaIEPXr0YMyYMbp134UQQogXkSRdCCGEEEIIIYTIJ+SZdCGEEEIIIYQQIp+QJF0IIYQQQgghhMgnCt0DUlqtllu3bmFtbY1KpTJ0OEIIIYQQQgghCjhFUYiOjsbNzQ0jo+z7ygtdkn7r1i2ZYVUIIYQQQgghxGt3/fp13N3ds61T6JJ0a2trIO3i2NjYGDgakd8kJyezc+dOmjdvjkajMXQ4QrxScr+LwkTud1GYyP0uCpM35X5/+vQpxYsX1+Wj2Sl0SXr6EHcbGxtJ0kUGycnJWFhYYGNjk69/yIXIC3K/i8JE7ndRmMj9LgqTN+1+z8kj1zJxnBBCCCGEEEIIkU9Iki6EEEIIIYQQQuQTkqQLIYQQQgghhBD5RKF7Jl0IIYQQQoiCRlEUUlJSSE1NJTk5GWNjYxISEkhNTTV0aEK8UvnpftdoNKjV6v/cjiTpQgghhBBCvMGSkpK4ffs2cXFxQFrC7urqyvXr13M0SZUQb7L8dL+rVCrc3d2xsrL6T+1Iki6EEEIIIcQbSqvVcvnyZdRqNW5ubpiYmKAoCjExMVhZWWFkJE+3ioJNq9Xmi/tdURTu37/PjRs3KFu27H/qUTd4kj5v3jxmzJjBnTt3qFq1KnPnzqV27dqZ1k1OTmbq1KksX76cmzdv4uXlxfTp0/Hz83vNUQshhBBCCGF4SUlJaLVaihcvjoWFBZCWtCQlJWFmZiZJuijw8tP97uTkxJUrV0hOTv5PSbpBz2LNmjUMHz6ccePGceLECapWrYqvry/37t3LtP4333zDwoULmTt3LuHh4QwePJj333+ff/755zVHLoQQQgghRP5h6ORECJGzNdBzwqA96bNmzWLAgAH06dMHgAULFrBlyxaWLl3K6NGjM9RfuXIlY8aMoWXLlgAMGTKE3bt3M3PmTH7++edMj5GYmEhiYqLu/dOnT4G0Xvnk5OS8PiXxhku/J+TeEIWB3O+iMJH7XRRUycnJKIqCVqtFq9UCacNu0/9NLxOioMpP97tWq0VRlEx70nPz/x+DJelJSUn8/ffffPXVV7oyIyMjmjZtyqFDhzLdJzExETMzM70yc3NzDhw4kOVxpk6dyoQJEzKU79y5UzckSIjn7dq1y9AhCPHayP0uChO530VBY2xsjKurKzExMSQlJelti46ONlBUQrx++eF+T0pKIj4+nv3795OSkqK3LX1ix5wwWJL+4MEDUlNTcXFx0St3cXHh3Llzme7j6+vLrFmzaNiwIZ6enuzZs4fffvst26n2v/rqK4YPH657//TpU4oXL07z5s2xsbHJm5MRBUZycjK7du2iWbNmaDQaQ4cjxCsl97soTOR+FwVVQkIC169fx8rKSteZpSgK0dHRWFtb53j4bapW4diVR9yLTsTZ2pS3SzmgNiq4M8M3btyYqlWr8sMPPxg0DrVazYYNG2jXrl2O6vfp04cnT56wcePGbOv17NmTChUq6HWIFkR37tyhZ8+eHDp0CI1Gw6NHjzItexkTJkzg999/58SJE0BaXhkbG8ucOXOy3CchIQFzc3MaNmyYoXM5fUR3Thh84rjcCAgIYMCAAZQvXx6VSoWnpyd9+vRh6dKlWe5jamqKqalphnKNRiP/kxZZkvtDFCZyv4vCRO53UdCkpqaiUqkwMjLSPZeePuQ3vfxFtv97mwl/hHM7KkFXVtTWjHGtK+JXuWiex7xgwQJGjhzJ48ePMTZOS0diYmKwt7enfv36hISE6OqGhITg4+PDxYsX8fT0zNM4srs+QUFB9OnTh/Lly3P27Fm9bevWraNTp06ULFmSK1eu/Oc4nv3evYhKpXrh9/XkyZNs27aNBQsW6Oo1atSIffv28euvv/Lhhx/q6s6ePZvZs2fn6jxUKhUbN2584QcL+/btY8KECYSFhZGQkECxYsWoV68eixYtwsTEJMfHy05AQAB37txh//79FCtWDCMjI11ZWFgYtra2Lz1fQ/oHXOn7jxw5Eg8PD4YPH46Hh0em+xgZGaFSqTL9f01u/t9jsBkmHB0dUavV3L17V6/87t27uLq6ZrqPk5MTmzZtIjY2lqtXr3Lu3DmsrKyyvEhCCCGEEEKIrG3/9zZDfj6hl6AD3IlKYMjPJ9j+7+08P6aPjw8xMTEcP35cVxYaGoqrqytHjhwhIeH/YwkODqZEiRIvlaAripJhyHFuWFpacu/evQyP4i5ZsoQSJUq8dLuv2ty5c+nYsWOGtbrNzMz45ptvXsvcHOHh4fj5+VGrVi3279/P6dOnmTt3LiYmJtmOgs6tyMhIatSogaenJ87OzrqymjVrUrZsWV1ZXnB0dMTX15fAwMA8azMrBkvSTUxMqFmzJnv27NGVabVa9uzZQ926dbPd18zMjGLFipGSksKGDRto27btqw5XCCGEEEKIfE9RFOKSUohPSiUuKSXbV3RCMuM2n0HJrJ3//Tt+czjRCckvbCsuKUU3gdeLeHl5UbRo0Qw95m3btqV06dIcPnxYr9zHxwdIm59q2LBhODs7Y2ZmxrvvvsuxY8f06qpUKrZt20bNmjUxNTXlwIEDxMbG0rNnT6ysrChatCgzZ87MUZzGxsZ07dpVb9TujRs3CAkJoWvXrhnqBwYG4unpiYmJCV5eXqxcuVJve0REhG4YdMWKFTOdI+P69et06tQJOzs7HBwcaNu2ba56uVNTU1m/fj2tW7fOsK1Lly48efKERYsWZdtGdudRqlQpAN5//31UKpXu/fN27tyJq6sr33//PZUrV8bT0xM/Pz8WLVqEubm5rt7Bgwdp1KgRFhYW2Nvb4+vry+PHj3XHmj17tl671apVY/z48brtGzZsYOXKldjb29OnTx9d2YoVK1CpVPTu3RuAJ0+e0L9/f5ycnLCxsaFx48acPHlSr+1p06bh4uKCtbU1/fr10/uwKF3r1q1ZvXp1ttcvLxh0uPvw4cPp1asXtWrVonbt2syePZvY2FjdbO89e/akWLFiTJ06FYAjR45w8+ZNqlWrxs2bNxk/fjxarZZRo0YZ8jSEEEIIIYTIF+KTU6k8Pm8mSFSAO08TqDJ+Z47qh0/0xcIkZ+mFj48PwcHBuhWdgoODGTVqFKmpqQQHB9OoUSPi4+M5cuQIffv2BWDUqFFs2LCB5cuXU7JkSb7//nt8fX25ePEiDg4OurZHjx6Nv78/Hh4e2NvbM3LkSPbt28fvv/+Os7MzX3/9NSdOnKBatWovjLNv3740atSIgIAALCwsCAoKws/PL8O8Whs3buTTTz9l9uzZNG3alD///JM+ffrg7u6Oj48PWq2W9u3b4+LiwpEjR4iKiuKzzz7TayM5ORlfX1/q1q1LaGgoxsbGTJ48GT8/P06dOpWjIeKnTp0iKiqKWrVqZdhmY2PDmDFjmDhxIr169cLS0jJDnRedx7Fjx3B2dmbZsmX4+flluRa4q6srt2/fZv/+/TRs2DDTOmFhYTRp0oS+ffsSEBCAsbExwcHBOe5pP3bsGD179sTa2ppJkybh7OxMSkoKPXv2xMbGhoCAAN0HAh07dsTc3Jxt27Zha2vLwoULadKkCRcuXMDBwYG1a9cyfvx45s2bx7vvvsvKlSuZM2dOhhHbtWvX5saNG1y5ciXLDyjygkEXVOzcuTP+/v58++23VKtWjbCwMLZv36676a9du8bt2/8/xCYhIYFvvvmGihUr8v7771OsWDEOHDiAnZ2dgc5ACCGEEEIIkVs+Pj4cPHiQlJQUoqOj+eeff/D29qZhw4a6HvZDhw6RmJiIj48PsbGxBAYGMmPGDFq0aEHFihV1vbJLlizRa3vixIk0a9ZM1xu8ZMkS/P39adKkCVWqVGH58uU5HgZfvXp1PDw8WL9+PYqiEBQUpPvQ4Fn+/v707t2boUOHUq5cOYYPH0779u3x9/cHYPfu3Zw7d44VK1ZQtWpVGjZsyJQpU/TaWLNmDVqtlsWLF1OlShUqVKjAsmXLuHbtmt6og+xcvXoVtVqd5TDvoUOHYmZmxqxZszLd/qLzcHJyAsDOzg5XV1fd++d17NiRLl264O3tTdGiRXn//ff58ccf9SZP+/7776lVqxbz58+natWqVKpUiY8//hhHR8ccnauTkxOmpqaYm5vj4uKCra2tXpmrqyu2trYcOHCAo0ePsm7dOmrVqkXZsmXx9/fHzs6O9evXA2nP5vfr149+/frh5eXF5MmTqVixYoZjurm56a7zq2TwieM+/vhjPv7440y3PX8zent7Ex4e/hqiEkIIIYQQ4s1jrlHz7/hmRD+NxtrGOttJs45efkTvZcey3J4uqM/b1C7t8MJ65prMe1Uz06hRI2JjYzl27BiPHz+mXLlyODk54e3tTZ8+fUhISCAkJAQPDw9KlCjBqVOnSE5Opn79+ro2NBoNtWvXzjCx27O9yJGRkSQlJVGnTh1dmYODA15eXjmOtW/fvixbtowSJUoQGxtLy5Yt+fHHH/XqnD17loEDB+qV1a9fn4CAAN324sWL65I8IMMjvidPnuTixYtYW1vrlSckJBAZGZmjWOPj4zE1Nc1yVn9TU1MmTpzIJ598wpAhQzJsf9F55JRarWbZsmVMnjyZvXv3cuTIEaZMmcL06dM5evQoRYsWJSwsjI4dO+aq3Zdx8uRJYmJiKFKkiF55fHy87rqePXuWwYMH622vW7cuwcHBemXpPfO5WU7tZRg8SRdCCCGEEELkDZVKhYWJMSkmaixMjLNN0huUdaKorRl3ohIyfS5dBbjamtGgrFOeL8dWpkwZ3N3dCQ4O5vHjx3h7ewNpPZXFixfnr7/+Ijg4mMaNG+e67cyGcf8X3bp1Y9SoUYwfP54ePXroZqTPazExMdSsWZNffvklw7aseqyf5+joSFxcHElJSVkOj+/evTv+/v5Mnjz5lQ7ZBihWrBg9evSgR48eTJo0iXLlyrFgwQImTJig92x6ZoyMjDLMc/Ayk97FxMRkmAMhXW5HZKcv55bT78fLMuhwdyGEEEIIIYRhqI1UjGudNqT3+RQ8/f241hVf2XrpPj4+hISEEBISQqNGjXTlDRs2ZNu2bRw9elQ3aVz60PWDBw/q6iUnJ3Ps2LFMhyWn8/T0RKPRcOTIEV3Z48ePuXDhQo7jdHBwoE2bNuzbty/Toe4AFSpU0IsN0iZFS4+tQoUKXL9+Xe9R3mcnyAOoUaMGERERODs7U6ZMGb2Xra1tjmJNf84+u9HHRkZGTJ06lcDAwAyT0r3oPCBtBMPLzNBub29P0aJFiY2NBeCtt97Sm0T8eU5OTnrX6+nTp1y+fDnXx61RowZ37tzB2Ng4w3VNH1pfoUIFvXsEMn5/AP799180Gg2VKlXKdRy5IUm6EEIIIYQQhZRf5aIEdq+Bq62ZXrmrrRmB3Wu8knXS0/n4+HDgwAHCwsJ0PemQ9ojrwoULSUpK0iXplpaWDBkyhJEjR7J9+3bCw8MZMGAAcXFx9OvXL8tjWFlZ0a9fP0aOHMnevXv5999/6d27d67Xzg4KCuLBgweUL18+0+0jR44kKCiIwMBAIiIimDVrFr/99htffPEFAE2bNqVcuXL06tWLkydPEhoaypgxY/Ta6NatG46OjrRt25bQ0FAuX75MSEgIw4YN48aNGzmK08nJiRo1anDgwIFs67Vq1Yo6deqwcOHCXJ0HpM2qvmfPHu7cuaObif15CxcuZMiQIezcuZPIyEjOnDnDl19+yZkzZ3Qzz3/11VccO3aMoUOHcurUKc6dO0dgYCAPHjwAoHHjxqxcuZLQ0FBOnz5Nr169spyoLjtNmzalbt26tGvXjp07d3LlyhX++usvxowZo1sG8NNPP2Xp0qUsW7aMCxcuMG7cOM6cOZOhrdDQUBo0aPDCUQD/lQx3z2+eXIe4h1lvtygCdsVfXzxCCCGEEKJA86tclGYVXTl6+RH3ohNwtjajdmmHV9aDns7Hx4f4+HjKly+vN1u6t7c30dHRuqXa0k2bNg2tVkuPHj2Ijo6mVq1a7NixA3t7+2yPM2PGDGJiYmjdujXW1taMGDGCqKioXMVqbm6ebWLWrl07AgIC8Pf359NPP6V06dIsW7ZMN0LAyMiIjRs30q9fP2rXrk2pUqWYM2cOfn5+ujYsLCzYv38/X375Je3btyc6OppixYrRpEkTbGxschxr//79WbFiRZbzfqWbPn069erVy9V5AMycOZPhw4ezaNEiihUrlukScbVr1+bAgQMMHjyYW7duYWVlRaVKldi0aZPuA5ly5cqxc+dOvv76a2rXro25uTl16tShS5cuQFoSf/nyZd577z1sbW2ZNGnSS/Wkq1Qqtm7dypgxY+jTpw/379/H1dWVhg0b6u67zp07ExkZyahRo0hISKBDhw4MGTKEHTt26LW1evVq3RJwr5JKyemChgXE06dPsbW1JSoqKlc3+2vx5Dr8WBNSErOuY2wKH/8tiforkpyczNatW2nZsiUajcbQ4QjxSsn9LgoTud9FQZWQkMDly5cpXbo0ZmZpveFarZanT59iY2OT6x5j8eaLj4/Hy8uLNWvWZJicriB6Xff7tm3bGDFiBKdOncpyXoLMfh7T5SYPlZ70/CTuIclRKaQkZv3Hg7FpCpq4h5KkCyGEEEIIITIwNzdnxYoVumHjIm/ExsaybNmyVzZx4LMkSc9Hku8+IHKLM4o266FFKiMFz64P0LhlWUUIIYQQQghRiD07PF3kjQ8++OC1HUvGv+QjKVHR2SboAIpWRUpU9GuKSAghhBBCCCHE6yRJ+pvo8RUoXFMJCCGEEEIIIUShIEn6myj4O5hXB0JnQVTOlmMQQgghhBBCCJH/SZL+JlJp4MF52DMBfqgMy9tA2K+QGGPoyIQQQgghhBBC/AeSpL+Bru535eaN5qS61AMUuLwPNg0G/7Lw2yCIDAZtqqHDFEIIIYQQQgiRSzK7e35iZpujakp8ArHhtzBauB+e3oDTa4nf+QsmSVdQn1oNp1aDdVF4qxNU7QLOFV5x4EIIIYQQQggh8oIk6fmJtUuOqrlOnoTa0hKVWg32JVHeHcGNMX+Q8sgdS097rB1uYeVyF83BADgYAEWrpiXrlT8AK6dXfBJCCCGEEEIIIV6WDHfPR4zt7VGZmGRbR2ViglW9eti0aKErS7n/ALWdHaSmEnvhAXcOm3Bxc1GuHCzLw/M2JEX8C9tHw0wvWNUZzmyE5IRXfDZCCCGEECLfe3IdboVl/Xpy3YDBgUqlYtOmTQaNIa/l9px69+5Nu3btXlivR48eTJky5eUDe0PcuXOHZs2aYWlpiZ2dHQB3796lefPmemUvY/z48VSrVk33fvTo0XzyySf/LeCXID3p+YjGzQ3P7dtIefw4yzrG9vZo3Nz093NxxuOPzSRduUL07t083bWLhJOniL8eS/x1K1KcG+JS7Dbc/Bvl/HY4vx2VmS1Ufj+th714HVBlvz67EEIIIYQoYJ5chx9rQkpi1nWMTeHjv8GueJ4f/s6dO3z33Xds2bKFmzdv4uzsTLVq1fjss89o0qRJnh/vRYKCgujTpw/ly5fn7NmzetvWrVtHp06dKFmyJFeuXHntsb3IyZMn2bp1K4GBgbqyRo0asW/fPn799Vc+/PBDXfns2bOZPXt2rs5DpVKxcePGF35YsG/fPiZMmEBYWBgJCQkUK1aMevXqsWjRIkxe0BmZUz/88AO3b98mLCwMW9u0x4Xnz5/PnTt39MrywhdffIGHhweff/45Hh4eedbui0iSns9o3NwyJOE5ZVKqFEX696dI//4k371L9O7dRO/ejXWvT6BGDbh/gbi1s7kdFIx1sRisb/6C+fEgVA6l0pL1tzqDQ+m8PSEhhBBCCJE/xT3MPkGHtO1xD/M8Sb9y5Qr169fHzs6OGTNmUKVKFZKTk9mxYwcfffQR586dy9PjPSspKSnLhNHS0pJ79+5x6NAh6tatqytfsmQJJUqUeGUx/Vdz586lY8eOWFlZ6ZWbmZnxzTff0KFDBzQazSuNITw8HD8/Pz755BPmzJmDubk5ERERbNiwgdTUvJvUOjIykpo1a1K2bFkAtFotV65coUaNGrqyvOLo6Iivry+BgYHMmDEjT9vOjgx3L6A0Li44dOtGyWXLsKhRI63QqRzRD4uSHA2PzllxdbcTFze7cnvXY2J+nYXyQzVY6gd/B0H8EwNGL4QQQgghXoqiQFIsJMel/ZvdKyU+Z22mxL+4raTYtGPn0NChQ1GpVBw9epQOHTpQrlw5KlWqxPDhwzl8+LBe3QcPHvD+++9jYWFB2bJl2bx5s25bamoq/fr1o3Tp0pibm+Pl5UVAQIDe/unDxb/77jvc3Nzw8vLKMi5jY2O6du3K0qVLdWU3btwgJCSErl27ZqgfGBiIp6cnJiYmeHl5sXLlSr3tERERNGzYEDMzMypWrMiuXbsytHH9+nU6deqEnZ0dDg4OtG3bNle93Kmpqaxfv57WrVtn2NalSxeePHnCokWLsm0ju/MoVaoUAO+//z4qlUr3/nk7d+7E1dWV77//nsqVK+Pp6Ymfnx+LFi3C3NxcV+/gwYM0atQICwsL7O3t8fX15fH/RhKXKlWK2bNn67VbrVo1xo8fr9u+YcMGVqxYgUqlonfv3nh4eLB582ZWrlypKwN48uQJ/fv3x8nJCRsbGxo3bszJkyf12p42bRouLi5YW1vTr18/EhIyPhLcunVrVq9ene31y2vSk17IOI8YjkWdOkTv2kVMSAgpMTE8uWjJk4uWGGm0ePgdQXPtEGwdBV4t0nrYyzQB9av95E0IIYQQQuSB5DiMprljl5dtLvXLWb2vb4GJ5QurPXr0iO3bt/Pdd99haZmx/vPPFE+YMIHvv/+eGTNmMHfuXLp168bVq1dxcHBAq9Xi7u7OunXrKFKkCH/99RcDBw6kaNGidOrUSdfGnj17sLGxyTRJfl7fvn1p1KgRAQEBWFhYEBQUhJ+fHy4u+pM8b9y4kU8//ZTZs2fTtGlT/vzzT/r06YO7uzs+Pj5otVrat2+Pi4sLR44cISoqis8++0yvjeTkZHx9falbty6hoaEYGxszefJk/Pz8OHXqVI6GiJ86dYqoqChq1aqVYZuNjQ1jxoxh4sSJ9OrVK9Pr/aLzOHbsGM7Ozixbtgw/Pz/UanWmcbi6unL79m32799Pw4YNM60TFhZGkyZN6Nu3LwEBARgbGxMcHJzjnvZjx47Rs2dPbGxsCAgIwNzcnISEBLp164aDg4OuBx+gY8eOmJubs23bNmxtbVm4cCFNmjThwoULODg4sHbtWsaPH8+8efN49913WblyJXPmzMkwrL127drcuHGDK1euZPkBRV6TJL2QMbK0xMa3OTa+zVGSkog9coToXbuJ3rMHIxMNxm2Hpi3hdi+cR5t2YbRlB9ZlLFHX6ghVP0ybKV6eXxdCCCGEEC/p4sWLKIpC+fLlc1S/d+/edOnSBYApU6YwZ84cjh49ip+fHxqNhgkTJujqli5dmkOHDrF27Vq9JN3S0pLFixfnKOmtXr06Hh4erF+/nh49ehAUFMSsWbO4dOmSXj1/f3969+7N0KFDAXSjAPz9/fHx8WH37t2cO3eOHTt24Pa/x1mnTJlCi2cmgF6zZg1arZbFixej+t/f2MuWLcPOzo6QkBCaN2/+wnivXr2KWq3G2dk50+1Dhw4lICCAWbNmMXbs2AzbX3QeTk5pq0PZ2dnh6uqaZRwdO3Zkx44deHt74+rqyjvvvEOTJk10STXA999/T61atZg/f75uv0qVKr3wHNM5OTlhamqKubm5LhZra+sMZQcOHODo0aPcu3cPU1NT3Xlu2rSJ9evXM3DgQGbPnk2/fv3o168fAJMnT2b37t0ZetPTv3dXr16VJF28eioTE6waNMCqQQNcx31Lyp07qIoVg/rDUG78w/02vdHGJ3P7qILl7rVYuy/H6q3iaOp3TVuD3eblnp0XQgghhBCviMYC7egbPI2OxsbaGiOjbJ5uvXMqZ73kfbeD61s5OnZOKLkYFg/w1lv/f2xLS0tsbGy4d++ermzevHksXbqUa9euER8fT1JSkt4M3QBVqlTJ1cRlffv2ZdmyZZQoUYLY2FhatmzJjz/+qFfn7NmzDBw4UK+sfv36uuH2Z8+epXjx4rokD9B7zh3SJny7ePEi1tbWeuUJCQlERkbmKNb4+HhMTU11Sf7zTE1NmThxIp988glDhgzJsP1F55FTarWaZcuWMXnyZPbu3cuRI0eYMmUK06dP5+jRoxQtWpSwsDA6duyYq3ZfxsmTJ4mJiaFIkSJ65fHx8brrevbsWQYPHqy3vW7dugQHB+uVpffMx8XFvcKI9UmSLgBQqdVoihX73xsVWnsvHPr0J3rXLhIjLhJ715TYu6bwdzTmm+diX2Y6tk3qpA2Hr/BejoY2CSGEEEKIV0ylSvu7TJOa9m92Sbqxedbbnq+Xh3/rlS1bFpVKlePJ4Z6f8EylUqHVagFYvXo1X3zxBTNnzqRu3bpYW1szY8YMjhw5ordPZsO8s9OtWzdGjRrF+PHj6dGjB8bGryZtiomJoWbNmvzyyy8ZtqX3YL+Io6MjcXFx2U6I1717d/z9/Zk8efIr7w0uVqwYPXr0oEePHkyaNIly5cqxYMECJkyYoPdsemaMjIwyfIiTnJyc6xhiYmIoWrQoISEhGbbldom2R48eATn/fuQFmThOZEptZYnTsGF4/PEHntu34fzFCMyqpA1FiX9oQlKMGi4Fw8aBaKeWJWFed5TIEPjfL0whhBBCCCEy4+DggK+vL/PmzSM2NjbD9idPnuS4rYMHD1KvXj2GDh1K9erVKVOmTI57oF8UY5s2bdi3bx99+/bNtE6FChU4ePBghngqVqyo2379+nVu376t2/78pHg1atQgIiICZ2dnypQpo/fK6VJi6aMGwsPDs6xjZGTE1KlTCQwMzDAp3YvOA9I+KHmZGdrt7e0pWrSo7vv81ltvsWfPnizrOzk56V2vp0+fcvny5Vwft0aNGty5cwdjY+MM19XR0RFIO+/nP8x5/vsD8O+//6LRaHI1LP+/kiRdvFD60m6l162nzL4QXL4di803v0Kjr8G+NDHXUrk8928iOw3gbudKxC38GOXu2Rc3LIQQQgghDMeiSNo66NkxNk2rl8fmzZtHamoqtWvXZsOGDURERHD27FnmzJmTYUh4dsqWLcvx48fZsWMHFy5cYOzYsRw7dixPYgwKCuLBgwdZPjs/cuRIgoKCCAwMJCIiglmzZvHbb7/xxRdfANC0aVPKlStHr169OHnyJKGhoYwZM0avjW7duuHo6Ejbtm0JDQ3l8uXLhISEMGzYMG7cuJGjOJ2cnKhRowYHDhzItl6rVq2oU6cOCxcuzNV5QNqs6nv27OHOnTu6mdift3DhQoYMGcLOnTuJjIzkzJkzfPnll5w5c0Y38/xXX33FsWPHGDp0KKdOneLcuXMEBgby4MEDABo3bszKlSsJDQ3l9OnT9OrVK8uJ6rLTtGlT6tatS7t27di5cydXrlzhr7/+YsyYMRw/fhyATz/9lKVLl7Js2TIuXLjAuHHjOHPmTIa2QkNDadCgwQtHAeQlSdJFrmhcXHDo2hXT6g2g0Zcw7B9SqnyEytiI5FhjHp2Gqz/sIcK3Lbc71SBm8dcoT+4YOmwhhBBCCPE8u+Lw8d8wcF/Wr4//zvM10gE8PDw4ceIEPj4+jBgxgsqVK9OsWTP27NlDYGBgjtsZNGgQ7du3p3PnztSpU4eHDx/qJkD7r8zNzTM80/ysdu3aERAQgL+/P5UqVWLhwoUsW7aMRo0aAWm91xs3biQ+Pp7atWvTv39/vvvuO702LCws2L9/PyVKlKB9+/ZUqFBBtxRY+mRrOdG/f/9Mh8w/b/r06RkmRnvReQDMnDmTXbt2Ubx4capXr55p27Vr1yYmJobBgwdTqVIlvL29OXz4MJs2bcLb2xuAcuXKsXPnTk6ePEnt2rWpW7cuv//+u+5xgq+++gpvb2/ee+89WrVqRbt27fD09MzxdUinUqnYunUrDRs2pE+fPpQrV44PP/yQq1ev6mbp79y5M2PHjmXUqFHUrFmTq1evZvrM/urVqxkwYECuY/gvVEpuZ254wz19+hRbW1uioqJydeOL7Gnj4ojZF0z0xp+JOXIKbeL/D3v3bP0QkxpNoOqHKGV9UWnMDBhp9pKTk9m6dSstW7bM8PyTEAWN3O+iMJH7XRRUCQkJXL58mdKlS2NmlvY3llar5enTp9jY2GQ/cZwoMOLj4/Hy8mLNmjW5GolQELzK+33btm2MGDGCU6dO5Whegsx+HtPlJg+VieNEnjCysMCmRStsWrRKW9pt/y6i1weRfPkCJpaJcH4rnN/KrSPOaC3dsG7ZFuv3+6C2tzd06EIIIYQQQrzRzM3NWbFihW7YuMgbsbGxLFu27JVNHJgVSdJFnlOZmGDVtBVWTVulFdw7B6dWoz2+huhrCkrqPWL+XcTtGYuwLO+GVav3sW7dCY1L5ms7CiGEEEIIIbL37PB0kTc++OADgxxXxr+IV8+5PDQdj2rkaUoFfINj45KY2qWCArFnb3HXfx4Xvb25/VFXSIgydLRCCCGEEEIIYTDSky5eG5XaGLOm3TFr2h2nxBiSQlYQ/fuvRJ+8RfxDE0wehoB/OSjfilSPNjwKvYp18+aYli+PSqUydPhCCCGEEEII8cpJki4Mw9QKE9+hFPEdSpGomySHLsPo3O8QcwH+3UD0H1t5cMSeB4EL0BR1xtq3JdbNm2FerRoqmQBFCCGEEEIIUUBJki4Mz7YYmve+gVZj4HYYnFyNJmo9VsXiib1jSvLtezwKCuJRUBBqB3usmzXHcfAgNEWLGjpyIYQQQgghhMhTkqTnU6lahaOXH3EvOgFnazNql3ZAbVTAh3yrVOBWHdyqY9l8MpYXd6M99jMx+0KIvmZMzC0zUh895smaNTg1KQlFOoOJBUnXr2Ps4ICRpaWhz0AIIYQQQggh/hNJ0vOh7f/eZsIf4dyOStCVFbU1Y1zrivhVLiS9x2oNeLXAyKsFNh0eY3NmI8qJX4n9+ySJTzQY7/0MDoyFim25/est4s9dxvLdd7Fu2hRrn0ao7ewMfAJCCCGEEEIIkXuSpOcz2/+9zZCfT6CgRW1xGZVxNEqKNXeiSjPk5xMEdq9ReBL1dOb2UKsvqlp9sXoYidWpNXByNTy5ivL3z6RcckZJNCZmzx5i9uzhtlqNRe23sW7WDOsmTWVpNyGEEEIIIcQbQ2bgykdStQoT/ghHbf0vlmWmY1FyEebFVmNRchEWZaajtv6XCX+Ek6pVDB2q4RTxBJ+v4dOT0Gc7qrd74vF+AqV97+FYKRpT22RITSXu0GHuTpzE7W++eWGTybduEX/mDPFnzpAQHo7pzZskhIfrypJv3XoNJyaEEEIIYTip2lSO3TnG1ktbOXbnGKnaVEOH9Eo1atSIzz77zNBhoFKp2LRpU47r9+7dm3bt2r2wXo8ePZgyZcrLB/YSFEVh4MCBODg4oFKpCAsLy7TsZYSEhKBSqXjy5AkA27dvp1q1ami12rw7gXxEkvR85OjlR9zXHses2M+ojPXXC1cZR2FW7Gfua49z9PIjA0WYj6hUULIutJmLauQFzAYswql9PTxaPsKz1V2cq0Zh7piMtd1VOPsnpCSRfPs2l1q34f6cOSSEh6MoCsm3bhHp14IrHT7gSocPuNH5Q0rOmcuNzh/qyiL9WkiiLoQQQogCa/fV3fhu8KXvjr58GfolfXf0xXeDL7uv7n4lx1uwYAHW1takpKToymJiYtBoNDRq1EivbnpyFhkZ+UpiyUpQUBAqlYoKFSpk2LZu3TpUKhWlSpV6rTHl1MmTJ9m6dSvDhg3TlV2+fJmuXbvi5uaGmZkZ7u7utG3blnPnzuXZcbdv305QUBB//vknt2/fpnLlypmW5QU/Pz80Gg2//PJLnrSX38hw93zkztNYTF3+ANJy0GepVKAoYOryB3eedgGKvP4A8yuNOVRun/aKuYfJ6fUUOfkrRe6cQlHuw5rDYG5P9OOaJEZEkBgRwYP5gWiKFcO8enWUpKRsm1eSkkh5/BiNm9trOiEhhBBCiNdj99XdDA8ZjoL+SM17cfcYHjKcWY1m0bRk0zw9po+PDzExMRw/fpx33nkHgNDQUFxdXTly5AgJCQmYmZkBEBwcTIkSJfD09Mz1cRRFITU1FWPjl0t5LC0tuXfvHocOHaJu3bq68iVLllCiRImXavN1mDt3Lh07dsTKygqA5ORkmjVrhpeXF7/99htFixblxo0bbNu2TdcznRciIyMpWrQo9erVy7Ysr/Tu3Zs5c+bQrVu3PG/b0KQnPR+J0l7ASBOVIUFPp1KBkSaKKO2F1xvYm8TKGeoOhcGhMOQvVPWHgZUrxD/G1mgPbu88xtpDjUqjJvnmTZ7++WfO2o2++2rjFkIIIYTIQ/Ep8cQlx2X6SkxNBNKGuE87Oi1Dgg6g/O+/aUen6Q19z6rN3PDy8qJo0aKEhIToykJCQmjbti2lS5fm8OHDeuU+Pj4AJCYmMmzYMJydnTEzM+Pdd9/l2LFjenVVKhXbtm2jZs2amJqacuDAAWJjY+nZsydWVlYULVqUmTNn5ihOY2NjunbtytKlS3VlN27cICQkhK5du2aoHxgYiKenJyYmJnh5ebFy5Uq97RERETRs2BAzMzMqVqzIrl27MrRx/fp1OnXqhJ2dHQ4ODrRt25YrV67kKF6A1NRU1q9fT+vWrXVlZ86cITIykvnz5/POO+9QsmRJ6tevz+TJk3UfkqSfW5cuXXBwcMDS0pJatWpx5MgRIPNh9p999plu5EPv3r355JNPuHbtmm6UQWZlAFqtlqlTp1K6dGnMzc2pWrUq69ev12t769atlCtXDnNzc3x8fDK9Bq1bt+b48eOvfZTF6yA96fmIo11intYr9FwqQfNJ0HQ8XApBfXI1thZ/YFvqOtoaKmLumPLkhiuxV7LvSQcgIerFdYQQQggh8onmW5pnua1BsQbMbzqfE/dOcDcu+46Iu3F3OXHvBG+7vg2A3wY/Hic+zlDvdK/TuYrPx8eH4OBgRo8eDaT1mI8aNYrU1FSCg4Np1KgR8fHxHDlyhL59+wIwatQoNmzYwPLlyylZsiTff/89vr6+XLx4EQcHB13bo0ePxt/fHw8PD+zt7Rk5ciT79u3j999/x9nZma+//poTJ05QrVq1F8bZt29fGjVqREBAABYWFgQFBeHn54eLi4tevY0bN/Lpp58ye/ZsmjZtyp9//kmfPn1wd3fHx8cHrVZL+/btcXFx4ciRI0RFRWV4Jj45ORlfX1/q1q1LaGgoxsbGTJ48GT8/P06dOoWJickL4z116hRRUVHUqlVLV+bk5ISRkRHr16/ns88+Q61WZ9gvJiYGb29vihUrxubNm3F1deXEiRM5fuY7ICAAT09PfvrpJ44dO4ZarcbExCRDGcDUqVP5+eefWbBgAWXLlmX//v10794dJycnvL29uX79Ou3bt+ejjz5i4MCBHD9+nBEjRmQ4ZokSJXBxcSE0NJT27dvnKM43hSTp+YiLZc5mIc9pPfE/Rmoo0yTtlRgN4ZsxOvkrNsahaCxuEnvFydARCiGEEEK8dvfj7udpvdzw8fHhs88+IyUlhfj4eP755x+8vb1JTk5mwYIFABw6dIjExER8fHyIjY0lMDCQoKAgWrRoAcCiRYvYtWsXS5YsYeTIkbq2J06cSLNmzYC05HPJkiX8/PPPNGnSBIDly5fj7u6eozirV6+Oh4cH69evp0ePHgQFBTFr1iwuXbqkV8/f35/evXszdOhQAIYPH87hw4fx9/fHx8eH3bt3c+7cOXbs2IHb/x6hnDJliu5cANasWYNWq2Xx4sWo/je0dtmyZdjZ2RESEkLz5ll/8JLu6tWrqNVqnJ3/P18oVqwYc+bMYdSoUUyYMIFatWrh4+NDt27d8PDwAGDVqlXcv3+fY8eO6T7wKFOmTI6uEYCtrS3W1tao1WpcXV115c+XJSYmMmXKFHbv3q17hMDDw4MDBw6wcOFCvL29dSMS0kc8eHl5cfr0aaZPn57huG5ubly7di3Hcb4pJEnPR2o418DFwiXLTzQVBVSpdtirvV5zZAWIqTVU75b2enIN1kyEnQdfuJs2Pv41BCeEEEIIkTd2ttqJtbU1RkYZn25VG6X1aDpZ5Kyj4tl62ztsz5P4GjVqRGxsLMeOHePx48eUK1dO15Pap08fEhISCAkJwcPDgxIlSnDq1CmSk5OpX7++rg2NRkPt2rU5e/asXtvP9iJHRkaSlJREnTp1dGUODg54eeX87+m+ffuybNkySpQoQWxsLC1btuTHH3/Uq3P27FkGDhyoV1a/fn0CAgJ024sXL65L0AG959whbcK3ixcvYm1trVeekJCQ4yHd8fHxmJqa6pL8dB999BE9e/YkJCSEw4cPs27dOqZMmcLmzZtp1qwZYWFhVK9eXW9Ewqtw8eJF4uLidB+ipEtKSqJ69epA2rV69vsFGa9VOnNzc+Licve4xZtAkvR8RG2kZnTt0QwPGQ6Q4fkgFZDwoAE9Fx9j7eC6uNtbGCDKAsSuBHi1Al6cpN8Y9wNFscfazy/DLz0hhBBCiPzG3NgcC41Fpkl6uvQOontx9zJ9Ll2FChcLF2o419CVWWjy5u/PMmXK4O7uTnBwMI8fP8bb2xtI6xktXrw4f/31F8HBwTRu3DjXbVtaWuZJjOm6devGqFGjGD9+PD169HjpieheJCYmhpo1a2Y6Y7mTU84+UHF0dCQuLo6kpKQMw+Otra1p3bo1rVu3ZvLkyfj6+jJ58mSaNWuGubl5tu0aGRmhKPr3SHJyco5ielZMTAwAW7ZsoVixYnrbTE1Nc93eo0ePcnxt3iQycVw+07RkU2Y1moWzhf6QdmMjY1CBhVMot+Nu0X3xEe49TTBQlIWP9mkMNz8fzvVBg0iNkufThRBCCPHmS+8ggrSE/Fnp77+s/aWu5z2v+fj4EBISQkhIiN7Saw0bNmTbtm0cPXpUN2lc+oRsBw/+f+dKcnIyx44do2LFilkew9PTE41Go5sADeDx48dcuJDziZgdHBxo06YN+/bt0z0f/7wKFSroxQZw8OBBXWwVKlTg+vXr3L59W7f92QnyAGrUqEFERATOzs6UKVNG72Vra5ujWNOfsw8PD8+2nkqlonz58sTGxgLw1ltvERYWxqNHmS/17OTkpBc78FJrnlesWBFTU1OuXbuW4RyLFy8OpF2ro0eP6u33/LWC/x9hkJO5Bd40kqTnQ01LNmVHhx0s9V3K9AbTWeq7lF0dduFp64mZaTKuDklceRhHt8VHeBSbg0nPRJaMba1RGWX85PhZKiMF+1q2qDQaUqOiMPrfchZCCCGEEG+6rDqIXCxcXsnya8/y8fHhwIEDhIWF6XrSAby9vVm4cCFJSUm6JN3S0pIhQ4YwcuRItm/fTnh4OAMGDCAuLo5+/fpleQwrKyv69evHyJEj2bt3L//++y+9e/fOdoRBZoKCgnjw4AHly5fPdPvIkSMJCgoiMDCQiIgIZs2axW+//cYXX3wBQNOmTSlXrhy9evXi5MmThIaGMmbMGL02unXrhqOjI23btiU0NJTLly8TEhLCsGHDuHHjRo7idHJyokaNGhw4cEBXFhYWRtu2bVm/fj3h4eFcvHiRJUuWsHTpUtq2bQtAly5dcHV1pV27dhw8eJBLly6xYcMGDh06BEDjxo05fvw4K1asICIignHjxvHvv//m6hpCWm/+F198weeff87y5cuJjIzkxIkTzJ07l+XLlwMwePBgIiIiGDlyJOfPn2fVqlUEBQVlaOvw4cOYmppmORT+TSbD3fMptZFaN4tmup+a/8TD+IdYqUrSccEhIu7F0GPJEVYNeAdbc42BIn2zaVwc8Wx1j5TErH9RG5tq0Vjexr6kI3g3Q/W/mSm18fEkXryIeZUqrytcIYQQQog817RkU3yK+3Di3gnux93HycKJGs41XlkPejofHx/i4+MpX7683mzp3t7eREdH65ZqSzdt2jS0Wi09evQgOjqaWrVqsWPHDuzt7bM9zowZM4iJiaF169ZYW1szYsQIonI5MtLc3DzbIeHt2rUjICAAf39/Pv30U0qXLs2yZct0IwSMjIzYuHEj/fr1o3bt2pQqVYo5c+bg5+ena8PCwoL9+/fz5Zdf0r59e6KjoylWrBhNmjTBxsYmx7H279+fFStW8PHHHwPg7u5OqVKlmDBhAleuXNEthzZhwgQ+//xzAExMTNi5cycjRoygZcuWpKSkULFiRebNmweAr68vY8eOZdSoUSQkJNC3b1969uzJ6dO5m9UfYNKkSTg5OTF16lQuXbqEnZ0dNWrU4OuvvwbSZm3fsGEDn3/+OXPnzqV27dpMmTIlwyiGX3/9lW7dumFhYcHTp09zHUd+plKef7iggHv69Cm2trZERUXl6mbPby7ei6HTko08irakhrsLK/vVwdJUPnPJtSfX4ceakJLNsnZqE7ArCQ8j0t5X6QQtpnMvcBkPFy/BvksXnD7/DPVzk3wIkd8lJyezdetWWrZsiUYjH/SJgk3ud1FQJSQkcPnyZUqXLo2ZmRmQtg7106dPsbGxyXWPsXjzxcfH4+XlxZo1awpkLzPAgwcP8PLy4vjx45QsWTLf3O+Z/Tymy00eKlndGypWFYlJiUCso104cbUX/ZcfZ1mftzHTvNpPPAscu+Lw8d8Q9xCA5JQUDh48SP369dGkTwpiUQSsnCFkGhycDafXolzaT+r1+qAoPF61iujdu3EZMwbr5s1kYjkhhBBCCGEw5ubmrFixggcPHhg6lFfmypUrzJ8/n9KlS+d4Lfc3iSTpbyi1Sg0qLZhfxKr4ag5d6sqQn/9mYY9amBjLJ6a5Ylc87QWQnEyUxU0oWhWe72lpOg7Kt4KNg1E9jKCowwZsBrTkzo6HJF27zs1PP8WqUSNcvx2L5pnlNYQQQgghhHidnp2IryCqVauW3lJ7BY1kc2+oyo6Vmdt4LqZqU1SWZ7B0X0/w+bt8uvofUlIL3qdJ+YZ7LRgcCnU/BlRYRm+ldNMbOH7YAjQaYkJCiHyvNdF7gw0dqRBCCCGEEOINJEn6G+xt17eZ1WgWxipjjKz/waLoH2z79zaj1p9Cqy1UUw28Xhpz8P0O+mwF+1IYxd3EiSV4fF4X8xrVUQFmFTKf+VMIIYQQQgghsiNJ+huuoXtDpjSYggoVartDmDnv4Ld/bjL2938pZHMCvn4l68Hgg/B2fwBMr62mZO1/KfXDaDTPzEQa9fvvpMbEGCpKIYQQQgghxBtEkvQCoEXpFoytOxYAr5JPUKlS+OXINb7bclYS9VfN1ApazYQem8DGHdWTq5gGD4DtX0NyPLF//cWtL0dzqdV7PN21y9DRCiGEEEIIIfI5SdILiI7lOjK70WzWtlvM9PY1AFh84DKzd0cYOLJCwtMHhv4F1bsDChyeBwsaoHpyCU2JEqTcvcvNT4Zx/aOPSb5929DRCiGEEEIIIfIpSdILkCYlm2CqNqXT28UZ914FjEzvELAngoX7Ig0dWuFgZgtt50HXtWDlCg8jsDj2CR6f1abIwP5gbEzMnj1EtnqPR8uXo6SkGDpiIYQQQgghRD4jSXoBpCgKj802YeUxB7VVOFO3nWPloSuGDqvwKOcLQw9BlU6gaDE6Ogdnsw14/DQV8xo1UOLiuDt1Gjc+/sTQkQohhBBCCCHyGUnSCyAFhYcJD1HQYlX8V9QWFxn7+xnWHb9u6NAKDwsH6LAIOv8MFo5w7wymu3tRsn9lXMd/i5GNDbbt2ho6SiGEEEIUcsm3bhF/5kyWr+Rbtwwan0qlYtOmTQaNIa/l9px69+5Nu3btXlivR48eTJky5eUDewmKojBw4EAcHBxQqVSEhYVlWvYyQkJCUKlUPHnyBIDt27dTrVo1tNqCv9y0JOkFkJHKiAn1JtC4eGO0JGNdciVGZtf4csMp/jxl2F+0hU6F1vDREajQBrQpqPZPwz4qkDKr5mLt66ur9nTXLqL37jVgoEIIIYQobJJv3SLSrwVXOnyQ5SvSr8UrS9Tv3LnDJ598goeHB6amphQvXpzWrVuzZ8+eV3K8FwkKCkKlUlGhQoUM29atW4dKpaJUqVKvP7AcOHnyJFu3bmXYsGG6ssuXL9O1a1fc3NwwMzPD3d2dtm3bcu7cuTw77vbt2wkKCuLPP//k9u3bVK5cOdOyvODn54dGo+GXX37Jk/byM0nSCyhjI2NmeM/gnaLvkEoidqWXg8ltPlsdxu7wu4YOr3CxdIROK6DDEjCzg9snUf/aCtXB2aBNJeXxY+58O44bQz/ixiefkHxXvj9CCCGEePVSHj9GSUrKto6SlETK48d5fuwrV65Qs2ZN9u7dy4wZMzh9+jTbt2/Hx8eHjz76KM+P96ykbM7Z0tKSe/fucejQIb3yJUuWUKJEiVca138xd+5cOnbsiJWVFQDJyck0a9aMqKgofvvtN86fP8+aNWuoUqWKrmc6L0RGRlK0aFHq1auHq6srxsbGmZblld69ezNnzpw8ay+/kiS9ADNRmxDgE0BVp6okE4u9RxCp6vsMXXWCAxEPDB1e4aJSQZUP0nrVy/lBahLsHg9LfTGKvYndBx+AsTHRu3ZzqWUrHq38GSU11dBRCyGEEOINpY2PRxsXl/krMfHl282izdwaOnQoKpWKo0eP0qFDB8qVK0elSpUYPnw4hw8f1qv74MED3n//fSwsLChbtiybN2/WbUtNTaVfv36ULl0ac3NzvLy8CAgI0Ns/fbj4d999h5ubG15eXlnGZWxsTNeuXVm6dKmu7MaNG4SEhNC1a9cM9QMDA/H09MTExAQvLy9Wrlyptz0iIoKGDRtiZmZGxYoV2ZXJkrzXr1+nU6dO2NnZ4eDgQNu2bbly5Uq21+9ZqamprF+/ntatW+vKzpw5Q2RkJPPnz+edd96hZMmS1K9fn8mTJ/POO+/onVuXLl1wcHDA0tKSWrVqceTIEb3r9qzPPvuMRo0a6bZ/8sknXLt2TTfKILMyAK1Wy9SpU3Xfp6pVq7J+/Xq9trdu3Uq5cuUwNzfHx8cn02vQunVrjh8/TmRkwZ4YW5L0As5CY8G8JvMoZ1+OZJ5SrewTklK0DFhxnGNXHhk6vMLH2hW6rE6bBd7UBm4cwyioCc71zCi9fh3mVauijY3l7nffceXDLiScPWvoiIUQQgjxBrrr05iIWm9zvkbNDK8bzwyJzq2LTZpm2mZuPHr0iO3bt/PRRx9haWmZYbudnZ3e+wkTJtCpUydOnTpFy5Yt6datG48epf0dq9VqcXd3Z926dYSHh/Ptt9/y9ddfs3btWr029uzZw/nz59m1axd//vlntvH17duXtWvXEve/Dx+CgoLw8/PDxcVFr97GjRv59NNPGTFiBP/++y+DBg2iT58+BAcH62Jr3749JiYmHDlyhAULFvDll1/qtZGcnIyvry/W1taEhoZy8OBBrKys8PPzy7bH/1mnTp0iKiqKWrVq6cqcnJwwMjJi/fr1pGbR8RMTE4O3tzc3b95k8+bNnDx5klGjRuX4me+AgAAmTpyIu7s7t2/f5tixY5mWAUydOpUVK1awYMECzpw5w+eff0737t3Zt28fkPZBRfv27WndujVhYWH079+f0aNHZzhmiRIlcHFxITQ0NEcxvqnybuyByLdsTW1Z2GwhYffCaFDMh4Er/mbfhfv0XXaMXwbU4S13O0OHWLioVGnrqXs0gt8/hkvBsOMrzErWp+S8uTzZfYx7M2eRcPo0lzt2oszOHWjc3AwdtRBCCCFEnrh48SKKolC+fPkc1e/duzddunQBYMqUKcyZM4ejR4/qnlGeMGGCrm7p0qU5dOgQa9eupVOnTrpyS0tLFi9ejImJyQuPV716dTw8PFi/fj09evQgKCiIWbNmcenSJb16/v7+9O7dm6FDhwLoRgH4+/vj4+PD7t27OXfuHDt27MDtf3/LTZkyhRYtWujaWLNmDVqtlsWLF6NSqQBYtmwZdnZ2hISE0Lx58xfGe/XqVdRqNc7OzrqyYsWKMWfOHEaNGsWECROoVasWPj4+dOvWDQ8PDwBWrVrF/fv3OXbsGA4ODgCUKVPmhcdLZ2tri7W1NWq1GldXV13582WJiYlMmTKF3bt3U7duXQA8PDw4cOAACxcuxNvbWzciYebMmQB4eXlx+vRppk+fnuG4bm5uXL16NcdxvokkSS8kHM0daVqyKQALutek+7K9/H01ip5Lj7J64DuUd7UxcISFkK079NgIx5fCzrFw9SCqhQ2wbz4Jqz//5O60qaitbSRBF0IIIUSuuQTvxcbaGiOjTAbOqtUv3W6ZPbv/Q1RpFEXJVf233npL97WlpSU2Njbcu3dPVzZv3jyWLl3KtWvXiI+PJykpiWrVqum1UaVKlRwl6On69u3LsmXLKFGiBLGxsbRs2ZIff/xRr87Zs2cZOHCgXln9+vV1w+3Pnj1L8eLFdQk6oEtS0508eZKLFy9ibW2tV56QkJDjId3x8fGYmprqkvx0H330ET179iQkJITDhw+zbt06pkyZwubNm2nWrBlhYWFUr15dl6C/KhcvXiQuLo5mzZrplSclJVG9enUg7VrVqVNHb/vz1yqdubm5bpRDQSVJeiEUnfKQZOcfcdKouB/Ri+6Lj7J20Dt4OFkZOrTCR6WCt/uBZ2P4/SO4ehC2DEfj8Qfu439Esfz/TyWTrl3j/py5OI8cicbFOZtGhRBCCFHYGZmbY2RhkXmS/l/atbD4z22ULVsWlUqV41nGNRqN3nuVSqUbkr169Wq++OILZs6cSd26dbG2tmbGjBm656rTZTasPjvdunVj1KhRjB8/nh49euTp5GfPiomJoWbNmpnOWO7k5JSjNhwdHYmLiyMpKSnDBxHW1ta0bt2a1q1bM3nyZHx9fZk8eTLNmjXD3Nw823aNjIwyfKCSnJyco5ieFRMTA8CWLVsoVqyY3jZTU9Nct/fo0aMcX5s3lTyTXgg9TnjMg/j7JKgjcfRczYPYWLotPsL1RwX7E6l8zaE09PoTfKeCsVnaEPj5dVGdXgP/++V457vvePrnn1xq1YpHq1bJxHJCCCGEeCM5ODjg6+vLvHnziI2NzbA9N7OPHzx4kHr16jF06FCqV69OmTJl8mRSMQcHB9q0acO+ffvo27dvpnUqVKjAwYMHM8RTsWJF3fbr169z+/Zt3fbnJ8WrUaMGERERODs7U6ZMGb2Xra1tjmJNHzUQHh6ebT2VSkX58uV11/ytt94iLCxM93z/85ycnPRiB15qzfOKFStiamrKtWvXMpxj8eLFgbRrdfToUb39nr9W8P8jDNJ74AsqSdILIS8HL+Y3nY+5sTmJmnAcS6/ndlRaon73aYKhwyu8jIyg7lAYfADc34bEp/D7UPj1Q4i+g/Pnn2P21ltoY2K4O3ESV7p2JeH8eUNHLYQQQog3lLG9PaoXDAFXmZhgbG+f58eeN28eqamp1K5dmw0bNhAREcHZs2eZM2dOlsOcM1O2bFmOHz/Ojh07uHDhAmPHjtVNVvZfBQUF8eDBgyyfnR85ciRBQUEEBgYSERHBrFmz+O233/jiiy8AaNq0KeXKlaNXr16cPHmS0NBQxowZo9dGt27dcHR0pG3btoSGhnL58mVCQkIYNmwYN27cyFGcTk5O1KhRgwMHDujKwsLCaNu2LevXryc8PJyLFy+yZMkSli5dStu2bQHo0qULrq6utGvXjoMHD3Lp0iU2bNigW36ucePGHD9+nBUrVhAREcG4ceP4999/c30dra2t+eKLL/j8889Zvnw5kZGRnDhxgrlz57J8+XIABg8eTEREBCNHjuT8+fOsWrWKoKCgDG0dPnwYU1PTXN0jbyJJ0gupas7VmO0zG42RhkTTMIqU2sy1RzF0W3yEhzEvvyyHyAOOZaHvDmg6HtQmcGE7zKuDWfK/lFr1Cy5jv8HI0pKEk6e43L4D9/z9X2rpEyGEEEIUbho3Nzy3b6PUhvVZvjy3b3sl8+N4eHhw4sQJfHx8GDFiBJUrV6ZZs2bs2bOHwMDAHLczaNAg2rdvT+fOnalTpw4PHz7UTeT2X5mbm1OkSJEst7dr146AgAD8/f2pVKkSCxcuZNmyZbolyoyMjNi4cSPx8fHUrl2b/v3789133+m1YWFhwf79+ylRogTt27enQoUK9OvXj4SEBGxscj5nVP/+/fWGzLu7u1OqVCkmTJhAnTp1qFGjBgEBAUyYMEH3QYGJiQk7d+7E2dmZli1bUqVKFaZNm4b6f3MW+Pr6MnbsWEaNGsXbb79NdHQ0PXv2zHFMz5o0aRJjx45l6tSpVKhQAT8/P7Zs2ULp0qWBtFnbN2zYwKZNm6hatSoLFixgypQpGdr59ddf6datGxZ58NhFfqZScjtzwxvu6dOn2NraEhUVlasbv6Dac3UPI/aNIFVJRRPTkEfXW1CxqC2/DngHWwvNixsoYJKTk9m6dSstW7bM8PyTQdwNh02D4fbJtPcV20KrWSTHpHL3uylE79wJgPPIkRTpl/lQLCGyku/udyFeIbnfRUGVkJDA5cuXKV26NGZmZkDa0l9Pnz7FxsYmz59JF/lTfHw8Xl5erFmzpsD2Mj948AAvLy+OHz+uS+4hf93vmf08pstNHio/tYVck5JNmFh/IgD2ThEUsUkl/PZTegcdJSYxxcDRCVwqQv890OhrMDKG8N9hXh00j47iPicA9/nzsaxXD/se3XW7FLLP3YQQQgghCj1zc3NWrFjBgwcPDB3KK3PlyhXmz5+vl6AXVDK7u6CNZxtUqHjb9W2eRFvw4U+H+efaE/ovP0ZQn9qYaV5+mQ6RB9QaaPQllPOFTUPgXjis6Q5VOmHd8nusG/voqiopKVzr2w+bli2x69QRlXx6LoQQQghRKKQPsy+oatWqRa1atQwdxmshf8ELAFp7tsbV0pXyrjas6FsbK4tYDl96xKCVf5OYIrOI5wtu1WBgCLw7HFRGcHotzHsHLuzUVYna/AdxR49yZ/x4rnbtRsKFCwYLVwghhBBCCJF7kqSLDG4mH0JTajoW9v+y78J9Pv01jJRUraHDEgDGptB0HPTbBUXKQswdWNUxbY31hKfYtm2Dy9dfY2RhQXxYWNrEcjNnoY2PN3TkQgghhBBCiByQJF1kcPzOcVKUJEyKrsbM+gLbz9zhi3Un0WrlWed8w70WDA6Fdz4CVPDPzxBYD9XVUBx69sBj6xasmzWFlBQeLlrEpTZtiTlw8IXNCiGEEOLNJHPSCGF4efVzKEm6yODrOl/TolQLUpUULIr/jInlZTaF3WLMpn/lfwD5icYc/KZAn61gXwqirsOKtrBlBBp7K9znzsV93o8Yu7qSfP06DwID5fsnhBBCFDDpqxXEyXKsQhhcUlISgG4Zu5clE8eJDNRGar5r8B2xKbHsv7Efm1IreRLZl1+PgrlGzdj3KqBSqQwdpkhXsh4MPgi7x8GxxWmvi7uhXSDWTZpgUecdHsydg13HjrrvmzYpCZWxsUwsJ4QQQrzh1Go1dnZ23Lt3D0hbd1tRFJKSkkhISDD4klRCvGparTZf3O9arZb79+9jYWGBsfF/S7MlSReZ0hhpmOk9kyG7h3D87nEcyqzgwYV+LD0IlqZqRjT3MnSI4lmmVtBqJpR/D37/GB5fgWUtoe5HqBt/g8tXX+lVvz9zFvGnT1N0wnhMy5Y1TMxCCCGEyBOurq4AukRdURTi4+MxNzeXjhVR4OWn+93IyIgSJUr85zgMnqTPmzePGTNmcOfOHapWrcrcuXOpXbt2lvVnz55NYGAg165dw9HRkQ8++ICpU6dmWCxe/HdmxmbMbTyX/jv7c+bhGXxqXWPPXy7M3XsRcxM1QxuVMXSI4nmePjD0L9jxddpz6od+hAs74P0Fac+xA6lRUTzZsAFtTAyX2negSL++OA4ejJH8DAkhhBBvJJVKRdGiRXF2diY5OZnk5GT2799Pw4YNdcPhhSio8tP9bmJikie9+QZN0tesWcPw4cNZsGABderUYfbs2fj6+nL+/HmcnZ0z1F+1ahWjR49m6dKl1KtXjwsXLtC7d29UKhWzZs0ywBkUfFYmVgQ2DWTTxU30rtSbhbaXmLbtHN9vP4+FRk3v+qUNHaJ4npkttJ0HFdrA5mHwMAKWNIP6n0Gj0ahtbfHY/Dt3Jk0mJjiYhwsW8nTbNoqOG4dlvXqGjl4IIYQQL0mtVuteKSkpmJmZGTxpEeJVK4j3u0EfUpk1axYDBgygT58+VKxYkQULFmBhYcHSpUszrf/XX39Rv359unbtSqlSpWjevDldunTh6NGjrznywsXezJ4+lfugUqkY7O3Jxz6lwSiB8X+Es/bYdUOHJ7JSzheGHoIqnUDRwoFZ8JMP3D6Jxs0N9/nzKDYnAGNnZ5KvXuNa337cHDWKlMePDR25EEIIIYQQhZbBetKTkpL4+++/+eqZZ2WNjIxo2rQphw4dynSfevXq8fPPP3P06FFq167NpUuX2Lp1Kz169MjyOImJiSQmJureP336FEA3FEjkTmJqIleNAylZ8TpXw3vy5W+n0BgpvPdWUUOHlifS74kCc29orKHNfFTlWqLe9gWqe2dQFjVG++4ItPU+w9zHhxJvv83DOXOJWr2amL3BOHz6KYqVlaEjF69BgbvfhciG3O+iMJH7XRQmb8r9npv4VIqB1mS6desWxYoV46+//qJu3bq68lGjRrFv3z6OHDmS6X5z5szhiy++QFEUUlJSGDx4MIGBgVkeZ/z48UyYMCFD+apVq7CwsPjvJ1LIPEx9yMKYhcQpcVgml+ZOZF+MFGP6emmp4iDLe+VnJslPqXpjOW5PjgHwxLwUJ0oOJNrcHQCz69cxfvyEmLeq6PZRP31Kqo2NQeIVQgghhBCioIiLi6Nr165ERUVh84K/r9+oJD0kJIQPP/yQyZMnU6dOHS5evMinn37KgAEDGDt2bKbHyawnvXjx4jx48OCFF0dkLvxhOIP2DCI2JRZHVTUuh3dEozZmYffqNCjjaOjw/pPk5GR27dpFs2bNCswzLXoUBVX4b6i3f4kq4QmK2gRtw9Fo3/kIjPTXc4wNDeX2p59h378f9v36YWRqaqCgxatS4O93IZ4h97soTOR+F4XJm3K/P336FEdHxxwl6QYb7u7o6Iharebu3bt65Xfv3tUtI/G8sWPH0qNHD/r37w9AlSpViI2NZeDAgYwZMybTmfRMTU0xzSS50Gg0+fqbmJ9Vda3K3CZzGbJ7CA9Sw/CoaMal8DYMXRXGir51qF3awdAh/mcF+v6o9iF4NoI/PkV1YTvq4ImoI7ZDu0Bw/P8Z++P374fkZB4HLiB223Zcx4/H8p06hotbvDIF+n4X4jlyv4vCRO53UZjk9/s9N7EZbOI4ExMTatasyZ49e3RlWq2WPXv26PWsPysuLi5DIq5Wp/X+GWhAQKH1tuvbzGo0C2OVMfeVw5Quv5OE5FT6Bh0j7PoTQ4cnXsTaFbqsTpsF3tQGbhyFBe/C4UDQagFwHTeOYrN/QO3kSNKVK1zr3Ztbo7+SieWEEEIIIYR4hQw6u/vw4cNZtGgRy5cv5+zZswwZMoTY2Fj69OkDQM+ePfUmlmvdujWBgYGsXr2ay5cvs2vXLsaOHUvr1q11ybp4fRq6N2Rqg6moUBFjfJganinEJKbQa+lRzt5+aujwxIuoVFC9Owz5Czx8ICUeto+G5a3h8RVUKhU2fn54bt2KfdcuoFIRtWkTl1q05OmOnYaOXgghhBBCiALJoOukd+7cmfv37/Ptt99y584dqlWrxvbt23FxcQHg2rVrej3n33zzDSqVim+++YabN2/i5ORE69at+e677wx1CoWeX2k/ElITKGlTknK2Veix5Agnrj2hx5IjrBlUF08nmSU837MrDj02wvGlsHMsXD0A8+tB80lQqy9qa2tcv/0W2zZtuP3tOBIvXEBlLB+KCSGEEEII8SoYbOI4Q3n69Cm2trY5emBf5F5UfDIfLgrh7K0kXG3MWDe4LsUd3pxZ9JOTk9m6dSstW7bM18+0vDKPLsPvH8HVg2nvPRtDm7lgmzYDvJKcTPTeYGx8m+t2SQgPx6RMGYxMTAwRsfgPCv39LgoVud9FYSL3uyhM3pT7PTd5qEGHu4uC53Z8JHHO3+HuHs6dpwl0XXyYO1EJhg5L5JRDaej1J/hOBWMziNwL8+vCP7+kzQyv0egl6CkPH3K1T18ut21H7NGjBgxcCCGEEEKIgkGSdJGntl/ezqPEh0Tb/ELRohe5/iiebosP8yAm8cU7i/zByAjqDoXBB8D9bUh8Cr8PhV+7QPQdvapJ166h0mhIunyZaz17cWvMGJlYTgghhBBCiP9AknSRp4bVGEYbzzZolVQSHJbj7HSVyPuxdF98hCdxSYYOT+SGY1nosx2ajAO1CVzYBvPfgdPr4X9PyVhUr47n1i3Yde4MQNSG37jUshVRmzfLigtCCCGEEEK8BEnSRZ4yUhkxod4EmpZoSoo2GcUliCJFbnPuTjS9lh0jOiHZ0CGK3FAbQ4PhMHAfuL4F8Y9hQz9Y1wtiH6RVsbGh6ITxlFy1CtOyZUh9/Jhbo77kev8BKCkpBj4BIYQQQggh3iySpIs8Z2xkzPSG06lbtC4JqfFo3JZiZ3ufk9ef0G/5ceKTUg0dosgtl4owYC80+gqMjCH8d5hXB87+oatiUaM6pTdswOnzz1GZmmJSsgQqY4MuICGEEEIIIcQbR5J08UqYqE2Y7TObak7ViE2JptpbR7E2Nebo5UcMXHmcxBRJ1N84ag00Gg3994BzRYh7AGu6w28D03rYAZWJCY6DBuLxx2acPv9ct2vS1avE/f23oSIXQgghhBDijSFJunhlLDQWzGs6jy7luzC/uT9Bfd/GXKMmNOIBH6/6h+RUraFDFC/DrRoMDIF3h4PKCE6tSZsBPmKXropJiRKora0BUBSF2+PGc7Vbd26P/ZbUqCjDxC2EEEIIIcQbQJJ08UrZmNjwdZ2vsdBYULOkA4t71cJEk8qu8LuMWHuSVK1MLvZGMjaFpuOg3y4oUhaib8MvH8DvH0PCU72qSlISJsXT1ll/sm4dkS1bEfXnFpJu3iT+zJksX8m3bhnizIQQQgghhDAoeWBUvDaKonA6dj0eb23n4skebD55C3ONmqntq2BkpDJ0eOJluNeCwaGwZxIcng//rIRLIdD2R/BoBICRqSlFJ03Ctm1bbo8bT1JkJLe++AJUKt0s8ZlRmZjguX0bGje313MuQgghhBBC5APSky5em8eJj1l9bjU34yIpX20tRkZJrDl+nYl/hstyXW8yjTn4TYHeW8C+FERdhxVtYcsXkBSrq2ZRqxalN/6G06fDwNg42wQd0nrgZc11IYQQQghR2EiSLl4bBzMHFjZbiLWJNVdjw3mr5iZQpRD01xX8d543dHjivypVHwYfhLf7p70/tggC68PVQ7oqRiYmOA4ZgvsPPxgoSCGEEEIIIfI3SdLFa+Xl4EVg00DMjc2JjDlBzVpbgVTmBUcyL/iiocMT/5WpFbSaCT02gY07PL4My1rAjjGQHK+rZuxW1HAxCiGEEEIIkY9Jki5eu6pOVQnwCUBjpOFCzF/UfnsPoGXGjvMsPXDZ0OGJvODpA0P/gurdAQUO/QgLG8INWYZNCCGEEEKI7EiSLgyirltdZnjPQK1SczZmL50aJAEw8c9wVh+9ZuDoRJ4ws4W286DrWrByhQcXYElT2DMRUpMNHZ0QQgghhBD5kszuLgymSYkmTKo/iYTUBD4o2x471Tl+2n+JrzaextxETdtqxQwdosgL5Xxh6CHY9iWcXguhM4E/c7Rryq3bUKnSq41PCCGEEEKIfER60oVBtfZsTcdyHVGpVHzVojxd67ihKDB87Ul2nLlj6PBEXrFwgA6LoNNKsHCER5dytNut0V8Sd/z4Kw5OCCGEEEKI/EOSdJFvPE58TKTxNOq8FUGqVuGTVf+w78J9Q4cl8lLFNjD0MMaetVAZvWjZPQVtbBzXhwwl9enT1xKeEEIIIYQQhibD3UW+8UfkH4Q/CkfFWd6uNIRjZ0owcMVxlvetzTseRQwdnsgrVk5oOk7F80YTUhKz/pzQyFjL/dg22Lz/IWobm9cYoBBCCCGEEIYjPeki3+hZsScdy3VEQSFC+Yka5e+QmKKlX9Ax/rn22NDhiTylQmOZirlDcpYvU5tUin37KTZ+frq9kq5eRZuYaMC4hRBCCCGEeLUkSRf5hkqlYkydMbQo3YJUJYVrxoG8VeYBsUmp9Fp6lPBbMuS5sFGpVLqvk+/c4WqPnlzr05eUx/KhjRBCCCGEKJgkSRf5itpIzXfvfoe3uzeJqYncNQ+kUukoniak0GPJES7eizZ0iMJAkm/dQhsfT/yJE1zp/CGJly4bOiQhhBBCCCHynCTpIt/RGGnw9/bnbde3iUuJxcRlPZWKWfEwNolui49w7WGcoUMUr4ui1X1pUaMGpX5dhaZYMZKvXeNKly7EHjlqwOCEEEIIIYTIe5Kki3zJzNiMuY3n0rxkc+Y0CWBl37qUc7Hi7tNEui4+zK0n8YYOUbwOIdNAm6p7a1qmDKXWrsG8alW0UVFc69+fJxs3GS4+IYQQQggh8pgk6SLfstRYMrPRTIpbF8fB0oSf+9ehZBEzbjyOp/viI9yPlgnE3lgWRcDY9MX1InbA7x/rJerGRYpQYnkQNi1bQHIyt7/6iqjNm19hsEIIIYQQQrw+sgSbeGOEPzlMkbILSNL25NKDWHosOcKvA97B3tLE0KGJ3LIrDh//DXEPs65z8zhsHQUnV4FKBW3mgpEaACMzM9z8/dEUL0FMSAhWjRu/psCFEEIIIYR4tSRJF2+EpNQkph2dxs2Ym5TxWklKeE/O3Ymm17Kj/NK/DtZmGkOHKHLLrnjaKytu1cDcHjYMgLBfgPREPW0AkMrICOfPP8Nx8CCMzM0BUBQFbWwsaiurVx+/EEIIIYQQr4AMdxdvBBO1CfObzMfe1J6LUWfxrLwWO0s4dSOKvkHHiEtKMXSI4lWo3AE6LAKVEYT9DH98AlqtXpX0BB3g0dKlXG73PomRka87UiGEEEIIIfKEJOnijeFh58GCZguw0lhx5vE/vFVjM9ZmcOzKYwat/JuE5NQXNyLePJU7QPv/Jer//Ax/DMuQqANoExJ4snYdyTducOXDLsQeOmSAYIUQQgghhPhvJEkXb5SKRSryY5MfMVWb8s+Dv6hdeycWJipCIx7w8aoTJKdmTN5EAVDlg2cS9ZXw56cZe9TNzCi5+lfMa9RAGx3NtQEDebxunYECFkIIIYQQ4uVIki7eODVdavJDox8wNjLm6P299Pa9j6mxEbvP3uPzNWGkahVDhyhehSofwPs/pSXqJ1bAn59lSNSN7e0psWwpNu+9Bykp3Bn7LfdmzkTJpOddCCGEEEKI/EiSdPFGauDegGkNptGpXCdG1O3Ogu410ahV/HnqNqM3nEIriXrB9FZHeH/h/xL15bDl84w96qamuM34HsehQwF4uGgxt774AkWRe0IIIYQQQuR/kqSLN5ZvKV/G1h2L2kiNT3lnAjpXw0gF6/6+wYQ/zkhSVlC91QnaLUhL1P8Ogi3DMyTqKpUKp2Gf4DZ9Gmg0mNeqhUqlMky8QgghhBBC5IIswSYKhGRtMvuj5tCpcQnW7C3J8kNXMTcx5ks/L0nOCqKqndP+3TgI/l6Wto56y5m65dnS2bZti3n16piUKKErUxRF7gkhhBBCCJFvSU+6KBB2XdnFlktb2HIrkM4+dwFYsC+SH/deNHBk4pWp2hneXwCo4PhS2PoFZDJ64tkEPfXJE650/pCYgwdfY6BCCCGEEELknCTpokBoUboF3St0B2DbnQA+bPQEgJm7LrA49JIBIxOvVNUPod180hL1JbBlRKaJeroHPy0i4dQprg8cxOM1a19fnEIIIYQQQuSQJOmiQFCpVIx8eyRtPduiVbTsvD+TTg3iAJi85SyrjlwzcITilanWFdrOQ5eobx2ZZaLu9Nmn2LZtA6mp3Bk3jrvTv5eZ34UQQgghRL4iSbooMIxURoyvN55mJZuRrE0m+Mn3dKiXAsCYTafZ+M8NA0coXpnq3aDtj4AKji2CbaMyTdSNTEwoOm0ajsM+AeDRsmXcGDYMbVzcaw5YCCGEEEKIzEmSLgoUYyNjpjWYRj23eiSkJPB3/A90e8cVRYEv1p1i+7+3DR2ieFWqd4c2cwEVHP0Jtn2ZaaKuUqlwGjoUN39/VBoNMbv3cLVHT5Lv3Xv9MQshhBBCCPEcSdJFgWOiNuGHRj9Qz60eUxtMZVKbGnSs6U6qVuGTX/8h+LwkYwVWjR7/S9SBowth++gsh77bvteKEsuDUNvZkRoVhUqtfo2BCiGEEEIIkTlZgk0USBYaCxY0XaBbamtah7eIT07lz1O3Gbzyb4L61KauZxEDRyleiRo9AAU2fwJH/jf7u9/UtGXanmNRowal1q5BSU7GuIjcD0IIIYQQwvCkJ10UWM+uhX01+jJxRebhXcGUxBQt/ZYf4++rjw0YnXilavSE1nPSvj4SCDu+zrJH3aRECUw9PXXvn2zcxKNffnkdUQohhBBCCJGBJOmiwFMUhTGhYzh25yjRdoHULWtOXFIqvZcd5d+bUYYOT7wqNXtB64C0rw/Phx1jsl2eDSDx4kVuf/stdydN5s6UKSipqa8hUCGEEEIIIf6fJOmiwFOpVExvOJ0iZkWIeHIBlesSapYyJzohhZ5LjxJxN9rQIYpXpWZveG922teH58HOb7JN1E08PXH6+GMAHq9YyY2PP0EbG/vq4xRCCCGEEOJ/JEkXhUIJmxL81PwnbExsOP3gFDalVlHF3YJHsUl0W3yEKw8kESuwavWB935I+/rQj9km6iqVCsdBAyn2wyxUJibEBAdzpUcPku/efY0BCyGEEEKIwkySdFFolLMvx/ym8zE3Nuf43SMU99pIORcL7kUn0m3xEa49iuPI5Uf8/UDFkcuPSNVmPzRavEFq9YVWs9K+PvQj7BqbbY+6TYsWlFyxHLWDA4nhZ7nSqTMJZ8++pmCFEEIIIURhJkm6KFSqOlVlbuO5mBiZEHormGb1TuPhaMnNJ/H4+IfQfelxVkSo6b70OO9O3yvrqhckb/eDlv5pX/81F3aPyzZRN69WjVJr12Di6UnK3bvE7Nv3mgIVQgghhBCFmSTpotCpU7QOM7xnUNOlJoOq96Z/g9IAGXrO70QlMOTnE5KoFyS1B/x/on4wAHaPz/4ZdXd3Sv26CueRIykyaNDriVEIIYQQQhRqkqSLQqlxicYs812GpbE1c/de/F+pFrVFJMY2YagtIlHQAjDhj3AZ+l6Q6CXqs2HPhGwTdbWNDUX69dUt6aeNj+fhkqUoKSmvIVghhBBCCFHYGBs6ACEMRaVScfTSQ25HJWDqug6NzRlU6gTddm2yLYl3W3M7qjJHLz+irmcRA0Yr8lTtAWmJ+baRcOAHQAVNvoX/JeJZURSFW1+OJnrnTmKPHqHYzFmorSxfT8xCCCGEEKJQkJ50Uajdi07ApMheTOz/1kvQAVTGUZgV+xlj63+5F52QRQvijVVnILT4Pu3rA7Ng76QXrqOuUqmwadUKlakpsfv2c7VbN5Jvy+MQQgghhBAi70iSLgo1RysNGvsjmeZm6Z2qpi5/4Gileb2BidejziDwm572dehM2Dv5hYm6jW9zSq5cgdrRkcTz57nSqTPx/555DcEKIYQQQojCQJJ0UaipLa5gpInKcpSzSgVGmijUFldea1ziNXpnMPhNS/s61B+Cv3thom7+1luUXrMa07JlSLl/n6s9ehC9Z89rCFYIIYQQQhR0kqSLQu1RwoM8rSfeUO8MAd+paV/vnwHBU16YqGuKFaPkqlVY1q+PEh/P7fHj0cbFvYZghRBCCCFEQSYTx4lCzcnCKUf1omLMX3EkwuDqDgUU2PE17P8eVEbg81W2u6itrSm+cAF3p03H9r1WGFlYvJ5YhRBCCCFEgSU96aJQq+FcAxcLF1RkPau3NtmWBTu0xCbKklsFXt2PoPnktK/3TYOQaS/cRWVsjOs3YzCvVk1XFnfiBKkxMa8oSCGEEEIIUZBJki4KNbWRmtG1RwNkSNTT3quwiG7P1YcJTN5y1gARiteu3ifQbFLa1yFTIWR6rnZPCA/nWv8BXO3SleSbN19BgEIIIYQQoiCTJF0Uek1LNmVWo1k4WzjrlbtYuPBDo1l836ojKnU8vx69xq7wuwaKUrxW9YdBs4lpX4dMgX3f53hXRVFQW1qSGBHB5c4fEn/69CsKUgghhBBCFESSpAtBWqK+o8MOfmryEx0tOvJTk5/Y3mE7pWxKMTv8Y7wqbwEUvtxwStZMLyzqfwpNJ6R9Hfwd7JuRo93MK1Wi1No1mHp5kfrgAVd79OTpjp2vMFAhhBBCCFGQSJIuxP+ojdTUcqlFVZOq1HKphdpITbI2mevR17mZdBz3kid4FJvEl+tPobxg5m9RQLz7GTQdn/Z18OS0md9zQFO0KCV/+QXLhg1QEhK4+emnPFy8WO4bIYQQQgjxQpKkC5GNCkUqMKLWCABiLTdhanmb4PP3+fnwVQNHJl6bdz+HJuPSvt47Gfb752g3tZUlxefPx75rVwDu+c/k6ZatrypKIYQQQghRQEiSLsQLdC3flUbFG5GiJOPsuQ6MEpm85SwX70UbOjTxujQYDk2+Tft67yQInZmj3VTGxrh+OxaXr7/GqlEjbPz+j737Do+i3Ns4/p0t6QklIdTQi/SqCIgoShdEOogUQRRERUAELBQVGygoYAERVJDQUSmKqDRpgqH3FkoSCIQQ0rO77x85Jx5eigR2syn351x7nZnZmee5FyaY387M87RwYUgRERERyQ1UpIv8C8MweKvhWxT2Kczl1HOUrLCa5DQ7Q0LDSEmzuzueZJXGw6DpG+nLa8fDho9u+9CCvZ6ixPRpGBYLAI7UVFIjI12RUkRERERyOBXpIrchv1d+PnjwA0yGiRjTZgIK7Wbv2StM/vWwu6NJVnpwODR9PX157TjY+PFtH2qY0v+5dTgcRI5/ixMdO5G4a5crUoqIiIhIDqYiXeQ21Slch0E1B3Ffkft47eG2AHy27hjbTlxyczLJUg++Ag//p1D/dSxsmpKpw+3xCSTu24vt4kVO9erNldWrnZ9RRERERHIsFekimdC/en++bPYlXetUo3PdEjgc8HJoGFeSUt0dTbJSk1fgodHpy2vehE2f3PahZj9fSn/7LX4PP4wjOZmzQ14m+osvNfK7iIiIiAAq0kUyxWwyYzaZARjTrirFgmM4ezmRscv3uTmZZLmHXoWHRqUvr3kD/vz0tg81+fpSYuqnFOj1FAAXPv6YiNdfx5GS4oqkIiIiIpKDqEgXuQMOh4Mpf79PXOD7WP33suTvs/y465y7Y0lWe2gkNBmZvvzL6/Dn1Ns+1DCbKTJ6NIXfeB1MJmIXL+HMy0NdFFREREREcgoV6SJ3wDAMvC3eAASELMWwxPDa0j1ExCa6OZlkuYdHQZNX05d/eQ02T8vU4QWffJKQzz/DFBBAga5dXBBQRERERHISFekid+iF2i9QPag6KY54Assu5EpSMsMW7MJu17PFec5Do+DBEenLP4/OdKHu9+CDlP91DX4PPpixzZ6c7MyEIiIiIpJDqEgXuUNWs5X3H3wfP6sfyebj+BZey5/HLjJr0wl3R5OsZhjw8Oj0kd/hP4X69Ew1YQ4IyFhOOXWKY81bEPvTCmemFBEREZEcQEW6yF0I8Q9hbMOxAJgK/o7Z5wgfrD7E/nNX3BtMsp5hwMOvQePh6es/j4Itn91RUzHz5pEWFcW54cOJ/uwzjfwuIiIikoeoSBe5Sy1Kt6BTxU6Ag3ylFpFiT2RI6N8kpdrcHU2ymmFA09eh8bD09dUjYesXmW4meMQICvbtC8CFKZ8QMXIUdo38LiIiIpInqEgXcYIR946gTnAd3rz/DYJ8/TkcdZUPVh9ydyxxB8OApm/AA/8ZqX3VCNj6ZeaaMJsp/OoIiowdC2YzscuXc/rpftguX3Z6XBERERHJXlSkiziBt8Wb2S1n075SCz7sVBOAWZtOsOHIBTcnE7cwDHjkTXjg5fT1Va/AthmZbqZAt66EfP45Jl9fEv76i5Ndu5F6TlP9iYiIiORmKtJFnMQwDAAevieYTvf5Y/I8x/CFu4iJ123KeZJhwCNjoNFL6esrh99Roe7X+AFKfT8PS7GimPLnw1ywoJODioiIiEh2oiJdxMn2Ru9lS/Jr+Jf6jqirlxm9dI8G/sqrDAMeHQcNX0xfXzkcts/MdDNeFStSJjSUkOnTMXl5OTmkiIiIiGQn2aJInzZtGqVLl8bLy4v69euzbdu2m+770EMPYRjGda82bdpkYWKRmysVUAp/Dz/s5kv4FFvMqr0RLN551t2xxF0MA5qNh4YvpK+vGAbbv8p0M5ZChbAEBmasn58yhQufTtUXQCIiIiK5jNuL9NDQUIYOHcqYMWPYuXMnNWvWpEWLFpw/f/6G+y9ZsoSIiIiM1969ezGbzXTu3DmLk4vcmL+HPx82+RCLYcHsvxdr/q2MWb6X8IsJ7o4m7mIY0OwtaDA4fX3FUPhr1h03l7hvHxc/+5zoadM4N+JVjfwuIiIikou4vUj/6KOPeOaZZ+jbty9VqlTh888/x8fHh1mzbvwLbMGCBSlSpEjGa82aNfj4+KhIl2ylWlA1htQdAoB3kZ9INM4wdEEYaTa7e4OJ+xgGNH/7n0L9p5fhr6/vqCnvqlUp+vZbYLFw5ccfCe/7NGkxMU4MKyIiIiLuYnFn5ykpKezYsYNRo0ZlbDOZTDz66KNs3rz5ttr46quv6NatG76+vjd8Pzk5meTk5Iz1K1euAJCamkpqaupdpJfc6L/nhDPOjW4VurHl3BY2ntuIT4nv+ev4YKb9doRBD5W967YlB3t4DCZbGuZtn8NPQ0iz2XDU6Z3pZnwff5xihQsTOXQYiTt2cLJLV4pOm4pHmTK33YYzz3eR7E7nu+QlOt8lL8kp53tm8hkONz7QeO7cOYoXL86ff/5JgwYNMraPGDGCdevWsXXr1lsev23bNurXr8/WrVu57777brjP2LFjGTdu3HXb582bh4+Pz919AJF/EW+PZ2rcVOIccSRHNyUtuhlDqtko5efuZOJWDgfVzs6j3IWfAfg75GnCgx66o6Y8oqIo/vVsrDEx2Ly9OfdUTxLLlXNiWBERERG5WwkJCfTo0YPY2FgCAgJuua9br6Tfra+++orq1avftEAHGDVqFEOHDs1Yv3LlCiEhITRv3vxf/3Ak70lNTWXNmjU0a9YMq9XqlDZLR5Vm9cnVRJla8POFyyw9F8CyQffj45Gjf/zkbjlaY1vzOubtX1D79Cyq16iBo1bPO2oqrV07Il58ieTdu6lXugz+rVvf1nGuON9Fsiud75KX6HyXvCSnnO//vaP7dri1SggKCsJsNhMVFXXN9qioKIoUKXLLY+Pj45k/fz7jx4+/5X6enp54enpet91qtWbrv0RxL2eeHw1LNKRhiYZcrpPCrtMbOHExgfd/OcqEJ6o7pX3JwVq/DyYDtn6OZcXLYLZAnacy3Yy1SBFKfzOHq+vWE9CieeaP17+HkofofJe8ROe75CXZ/XzPTDa3Dhzn4eFB3bp1Wbt2bcY2u93O2rVrr7n9/UYWLlxIcnIyPXve2ZUnkayW38eDDztXx5pvO/O2HefX/VH/fpDkboYBLd+D+54FHPDDC/D3d3fUlMnL65oCPe3CBSLfmYD9f8bkEBEREZHsz+2juw8dOpQZM2YwZ84cDhw4wMCBA4mPj6dv374A9OrV65qB5f7rq6++on379gT+z7zBItndjxET8Sq2GM9Cq3l18W4uxKmAyvMMA1q9D/cNABywfDD8PfeumnQ4HJx5aQgx335LeO8+pF265JysIiIiIuJybi/Su3btysSJE3nzzTepVasWYWFhrF69msKFCwMQHh5ORETENcccOnSIjRs30q9fP3dEFrljrcukPyvsEbiRy8YuXl28GzeO3SjZhWFAqw/g3mdIL9Sfh7B5d9GcQaEXX8QUEEBiWBgnu3Ql+dgx5+UVEREREZdxe5EOMHjwYE6dOkVycjJbt26lfv36Ge/98ccfzJ49+5r9K1WqhMPhoFmzZlmcVOTuPBTyED0rpz+i4V1sIb8fPcLcreFuTiXZgmFA6w/h3v6AA5YNuqtC3ff++pSe/z3WkBBSz5zhZLfuxG/Z4ry8IiIiIuIS2aJIF8lLXq77MpULVsYwJ+BVbD5vr9jLsQtX3R1LsgPDgNYToV4//inUv7/j5jzLlqV06Hy8a9fGHhdHeP9nuPjVVyTu20fivn0k7d+P59mzJO3fn7Et9dw5530eEREREck0zQElksU8zB582ORDuvzYhQTfEyTnW8OQ+flYMqghVrO+N8vz/luo44C/ZsGygenbana7o+YsBQtScvbXRIx+jSsrVnB+4iT4n0csSgFnPvn0n+49PCi3ehXWYsXu8oOIiIiIyJ1QRSDiBqUCSvFGgzcA8Axcz97IM0z59YibU0m2YTJB60lQty/ggKXPwa7QO2/O05NiEz8k/5NPXlOg34gjJYW0mJg77ktERERE7o6KdBE3eazsYzxX8zlerDIFh82f6X8cZftJjcIt/2EyQZuPoG4f0m99fw52L7zj5gzDIH+HJ5wWT0RERERcQ0W6iBs9X+t5nqnfmI51SmB3wMuhYcQlpbo7lmQXJhO0+Rjq9AaHHZYOuKtCXURERESyPxXpItnA2HZVKFoomkj7Rsb8sM/dcSQ7MZngsclQp9c/hfqeRe5OJSIiIiIuooHjRLKBiMQTJBaajJfdwbL9hWm6O5jHamjgLvkPkwkem5L+PPnf38KSZ9K3V+/k3lwiIiIi4nS6ki6SDVTIX4GHQx7CMGx4F/+e0cv+IiI20d2xJDsxmaDtJ1C7Z/oV9SXPwN7F7k4lIiIiIk6mIl0kGzAMg7ENx1LUtxgmj4uk5F/AsIVh2O23Holb8hiTCdp+CrX+U6gvfgb2LnF6N2nR0U5vU0RERERuj4p0kWwin2c+PnjwfUyGGWu+XWy78DOzNp1wdyzJbkwmaPcp1HoSHDZY3B/2Lb2tQy0FCmB4eNx6J7MJz/LlnRBURERERO6EnkkXyUZqBdfihdqDmbJzCl5FfuDD30rzQIUg7ikS4O5okp38t1B3OGDXPFjUL3171VtPsWYtVoxyq1dlzIOelpbGpk2baNSoERaLBUdyMpbChfEoXtzVn0BEREREbkJX0kWymaerPU2Dog0wTKkQsJkh88NISrW5O5ZkNyYzPD4VanZPv6K+qB/sX/6vh1mLFcO7alW8q1bFq0oVkosXx6tKFbyrVsWnTp2MAt2eksKZl18mYft2V38SEREREfkfKtJFshmTYWJC4wkMrjkcv/gOHIyMY+LPh9wdS7IjkxkenwY1uv2nUH8a9v/glKYvzphB3KrVhA94lvgtW53SpoiIiIj8OxXpItlQkHcQz9bqzQcdawEwc+MJNh3VYF5yAyYztJ+eXqjb02BRXzjw4103G9ivH76NG+NITOT0s89yddMmJ4QVERERkX+jIl0kG3ukcmG63heMZ+HlvLz4Ny4npLg7kmRHGYV61/RCfWGfuy7UTV5elJj6KX5NmuBITubMwEFcXb/eOXlFRERE5KZUpItkc0bQUjwKbuZqvtmMWhKGw6Fp2eQGTGZo/xlU7/w/hfpPd9ekpyclPv0Ev0cfwZGSwpnnBxP32+/OySsiIiIiN6QiXSSbe7HOYHwsfpi9T7M26huW/n3W3ZEkuzKZof3nUK3Tfwr13nBwxV01aXh4UOLjj/Fv0QJHaioRo0djuxrvpMAiIiIi8v+pSBfJ5or5FeOdB94CwDNoHW/+soTTlxLcnEqyLbMFnvgCqnVML9QX9IaDK++qScNqpfikieTr1JES06dh9vN1UlgRERER+f9UpIvkAI+WepQuFbsC4Cg0jxdC12Gz67Z3uQmzBZ748j+Feios6AWHVt1Vk4bFQrG338anTp2Mbba4uLtNKiIiIiL/j4p0kRxixH2vUCagPCZLPIccXzD9j8PujiTZ2X8L9aod0gv10Kfg0GqnNZ+0fz/Hmrfg8rJlTmtTRERERFSki+QYnmZPJjedhNXwxOQZySfrtrL7zGV3x5LszGyBDjOg6hP/uaL+FBz+2SlNx65YgS0mhohRo7m8eLFT2hQRERERFekiOUrZfGWZ0vRjGni+Q2pyIEPmh5GQkubuWJKdmS3QYSZUaQ+2FJj/JGz5HM6FQcQu8iWchIhd6evnwuDy6dtqNnjYMAr06AEOBxGvvU7M/FDXfQYRERGRPMTi7gAikjmNSzSmeocUWoSv53h0PBNWHuDt9tXdHUuyM7MFOs6E1Hg4sgZWvwqAFXgI4ND/7GvxhME7IH/ILZs0TCYKv/E6htXCpTnfEDl2LA5bGgWffNJFH0JEREQkb9CVdJEcKL+PB5M618Liv4dFpyax9kCkuyNJdme2QpOR/75fWjIkXLytJg3DIHjkSAr2exqAqLfe5tKcOXeTUkRERCTPU5EukkOVL5aGb4lQrPl3MPzn6URfTXZ3JMnuTM6/ecowDIKHDyfw2WcBiPvtdxxpegRDRERE5E6pSBfJoYr4FuHlukMBSM33Ay8s/gmHQ9OySdYzDINCQ16i6DvvEPLZdAyLnqQSERERuVMq0kVysN5Ve1K3UCMMk43dyVOZs0XTsol7GIZB/o4dMPn4AOBwOIjfskVfHImIiIhkkop0kRzMMAwmN30PP3MgJs9oPvzrXY5fuOruWCJET5tOeJ++XJgyRYW6iIiISCaoSBfJ4fJ75efTRyaCw8AUsIP+iz8n1WZ3dyzJ40y+vgBc/PwLLkyapEJdRERE5DapSBfJBeoVrUevygMAOBN/kk/WHnFzIsnRnFBQB/btQ+HRowG4OPMrzr/3vgp1ERERkdugIl0klxh670CeKf8hKRdaMe33o/x18pK7I0l24xOYPg/6v/n7G6d0V7DXUxQZ8yYAl+bMIertd1Soi4iIiPwLDcErkkuYTWZebNSSk2fDWLLzLEMW/M2qFx/E38vq7miSXeQPgcE7MuZBT01LY9OmTTRq1AirxQJHfoHf34G/ZkHRmlC3z113WaB7d7BYiHxzDDFz5+Kw2yg6ZsxdtysiIiKSW6lIF8llxrWrypZTx7no+wWDlp7k2+793B1JspP8IekvgNRUYn3OphfkVisUqwUOO/zxLvw0FPKFQPlH7rrLAp07Y1isRLz2Gl6V7rnr9kRERERyM93uLpLL+HtZaVLvGBbfE/yd+AVzd+xydyTJSZq8CjW6gsMGC3pD1H6nNJv/ifaUW7mCAt26OqU9ERERkdxKRbpILjT+wSEEWsthmBN576/XORujadnkNhkGtPsUSjWClDiY1wXiIp3StEfp0hnLaTExnP94Mo60NKe0LSIiIpJbqEgXyYWsZiuzWn2C4fACr5P0XvY2drsG7JLbZPGErt9BYHmIPQ3fd4OUeKc177DbOT3gWS5+8QVnhw3HkZrqtLZFREREcjoV6SK5VNkCJRla+zUAIo2VjP91uZsTSY7iUxCeXJg+Ivy5v2HxM2C3OaVpw2Qi6LlnwWol7uefOTt0KI6UFKe0LSIiIpLTqUgXycX61GxPjXwtMAwHi05/wLZTp9wdSXKSgmWh2/dg9oRDK+CXN5zWtP8jjxAy9VMMDw/i1vzKmZeGYFehLiIiIqIiXSS3m9FmPF6OYtht3oxavo3kNOdcDZU8omR9eOKz9OUt02DbDKc17dekCSWmT8fw9OTq779zZvBg7MnJTmtfREREJCdSkS6Sy/lYfZjV8nO8zg/l2DkfJv1y2N2RJKep1hEeeTN9edUIOPyz05r2e6ARIV98juHtTfz6DUSOG++0tkVERERyIhXpInlA9SJleL9DPQBmbDjOusPn3JxIcpwHhkLtnunzqC/sCxG7nda07/33U/LLL/AoW5aggc85rV0RERGRnEhFukge0axKYbrdWwJrwT94YUNPzly+5O5IkpMYBjw2Gco0gdT49KnZYs86rXmfe++l7I8/4BESkrHN4dCMBCIiIpL3qEgXyUOGtiyFd+B2HJYLPPXDcOx2u7sjSU5itkKXb6DQPRAXAd93heQ4pzVvmM0Zy3G//UZ4r97Y4pzXvoiIiEhOoCJdJA8J9s3PmPoTcDhMRDu28/pvM90dSXIa7/zQYwH4FoLIPbDoabClObULe2IiEW+OIWH7dsL79cd25YpT2xcRERHJzlSki+QxHao2pEH+pwD48fRnrD/pvGeLJY8oUAq6h4LFG478AqtfBSfemm7y9qbkl19gzpePpN27Ce/TF9vly05rX0RERCQ7U5EukgdNe2wIPrZqYErj5d+HczU53t2RJKcpURc6zgAM2D4Ttnzm1Oa9qlSh5DdzMBcoQNL+/Zzq05e0mBin9iEiIiKSHalIF8mDPCwWZraciCMtgBRTBH1/et3dkSQnqtwWmr+VvvzzaDi4wqnNe1WqRKlv5mAOCiL54EHCe/ch7eJFp/YhIiIikt2oSBfJo6oXK06v8qNw2K3sPubLnjOX3R1JcqIGg6He04ADFveHszud2rxnhQqU+mYOlkKFSD58mJh53zu1fREREZHsRkW6SB72yoNtqG+ZRPKlBgwJDSMxxebuSJLTGAa0+hDKPwqpCfB9N7gc7tQuPMuWpdS331Cwb1+CBg10atsiIiIi2Y2KdJE8zDAMJnZoRLC/J8cuxDN+5Q5SbanujiU5jdkCnb6GwtXgahTM6wpJsU7twqN0aQq/OiJjmjZHWhpp0dFO7UNEREQkO1CRLpLHFfD1YGLnmpi8zvDDhREM+3WCuyNJTuQVAD1Cwa8InN8PC3qDi77wcdhsnBs5ipPdupNy5qxL+hARERFxFxXpIsKDFQvRrLoXJo+L/B65iB+PrHV3JMmJ8pVIL9StPnD8d1gx1KlTs/2X7fJlEnfvJvXMGU71eoqU06ed3oeIiIiIu6hIFxEAprTriU/SQwC8+efrRMZHujeQ5EzFakGnWWCYYOc3sGmK07uwBAZS6ttv8ChdmrRzEZzq+RQpJ086vR8RERERd1CRLiIAeFnNfNlmDPakYqRxlX4rh2KzayA5uQOVWkHL99KXfx0D+5Y5vQtr4cKU/GYOHuXKkRYVxamnepF8/LjT+xERERHJairSRSRDzRJB9Cn/Bg6bB+EJe/hg6zR3R5Kcqv6zUP+59OWlz8Lp7U7vwhocTKlv5uBZoQJpFy5wqldvko8ccXo/IiIiIllJRbqIXGPYw40IsT8FwLxDM9lyzvnFleQRLSZAxVaQlpQ+NdulE07vwhIYSMlv5uB5zz3Yr1wh7cIFp/chIiIikpVUpIvINUwmg686PQtx9UiLr8Da3e5OJDmWyQwdZ0LRmpAQDfO6QGKM07uxFChAqdlfEzJjBr4NGzq9fREREZGspCJdRK5TLL834xqNIfF0H75ad54dp5xfWEke4ekH3UMhoDhEH4bQpyAtxendmPPnx7f+fRnrycdPkLhnr9P7EREREXE1FekickMdapfmidoh2B3wcmgYB6KPuTuS5FQBRaHHAvDwg5Mb4MeXXDI123+lnD5NeO/ehPftS2JYmMv6EREREXEFFekiclPjHq9KsfxWojy/oeuKjuy7uM/dkSSnKlINOs8Bwwy75sH6iS7rylygINZSJbFfvUp4v/4k7Nzpsr5EREREnE1FuojcVICXlY8618FkTsSBjefXDOVqylV3x5KcqsKj0OY/xfnvb8PuhS7pxuznS8kvv8Snfn3s8fGE93+G+G3bXNKXiIiIiLOpSBeRW7q/XBDdyw7Hnpqfi8nneG3DWBwuvFVZcrl6T0PDF9KXlw+CU3+6pBuTjw8hn3+Gb8OGOBISOD3gWeK3bHFJXyIiIiLOpCJdRP7VyOZ1KJrcD4fDxG9nfmbpkWXujiQ52aPjoXJbsKXA/B5w0TXjHZi8vSnx2XR8H2yMIymJ088+R8KOHS7pS0RERMRZVKSLyL/ysJj4vHNHbBebA/DWlnc4fvm4m1NJjmUywRNfQvG66VOyze0ECZdc05WnJyWmTsXv4YfxLF8ezwoVXNKPiIiIiLOoSBeR21I+2J9RDQaSdrU8aY5kXvxtGDa7zd2xJKfy8IHu8yFfSbh0PP2KemqSS7oyeXhQYspkSn49C3NAgEv6EBEREXEWFekictuealCGOj6DsCUVJj6iBWl2dyeSHM0vGJ5cCJ75IHwzLH/eZVOzGR4e1xTol775liu//OKSvkRERETuhop0EblthmHwcafGeJ5/hROnQ/jol8PujiQ5XfA90PUbMFlg7yL4fYLLu7y6YSNREyZw9uWhXFm1yuX9iYiIiGSGinQRyZRgfy/e71ATgC83HOeHfXs5d/Wcm1NJjlb2IXhscvry+g8gbJ5Lu/Nt2IB8j7cDm42zw4YT++NPLu1PREREJDNUpItIpjWvWoTu94Vg8j7Ka9v6MvT34aTaU90dS3KyOk9B42Hpyz+8CCfWu6wrw2ym6IQJ5OvYAex2zr36KpeXLnNZfyIiIiKZoSJdRO7I622qUMy3OA4H7Lu0h6l/T3V3JMnpHn4dqnYAeyqE9oQLh1zWlWE2U/Stt8jftSvY7USMHs3lRYtc1p+IiIjI7VKRLiJ3xNfTwiedHyElshMAs/bO4s+zf7o5leRoJhO0/wxC6kNSLMztDFcvuKw7w2SiyNgxFOjRAxwOIl5/g6QDB1zWn4iIiMjtUJEuInesdskCPH9fB1Ji7gfg1fUjiU6MdnMqydGsXtBtHhQoA5dPwfzukJrosu4Mw6DwG69TsHcvCg15Ca/KlV3Wl4iIiMjtUJEuInfl+YfLcY9HD2xJRbicEsPI9SOxOzQ3m9wF36D0qdm88sOZ7bD0WbC77pwyDIPgkSMJeu65jG2OVI2xICIiIu6hIl1E7orFbOKTrvfB+Z447Fa2Rm5l8ZHF7o4lOV1QBeg2F0xW2L8c1o5zaXeGYWQs267Gc6pXby7OnOnSPkVERERuREW6iNy1UoG+jG3ZlKTIx0mLaUg5rybujiS5QekH4PFp6cubJsOO2VnSbdwvv5D499+cnziJ6M8+y5I+RURERP5LRbqIOEXneiV4tMRjJEa245WF+0lMsbk7kuQGNbvCQ6PSl38aCkfXurzL/B2eoNCQlwC4MOUTLnw6FYfD4fJ+RUREREBFuog4iWEYTOhQnWB/T45diGfCyr2sPL5SxY3cvSavQo2u4LDBgt4Qtd/lXQY99xzBw9PnbY+eNo0Lk6foXBYREZEs4fYifdq0aZQuXRovLy/q16/Ptm3bbrn/5cuXef755ylatCienp5UrFiRlStXZlFaEbmVgr4efNi5JuBg0dlxvLrhVeYfmu/uWJLTGQa0+xRKNYKUOJjXBeIiXd5tYP/+BI98FYCLX3zB+Q8nqlAXERERl3NrkR4aGsrQoUMZM2YMO3fupGbNmrRo0YLz58/fcP+UlBSaNWvGyZMnWbRoEYcOHWLGjBkUL148i5OLyM00qViIPg3LkHa1EgAfbv+Qg5cOujmV5HgWT+j6HQSWh9jT8H03SIl3ebeBffpQ+PXXAYhdtoy0866bt11EREQEwOLOzj/66COeeeYZ+vbtC8Dnn3/OihUrmDVrFiNHjrxu/1mzZnHp0iX+/PNPrFYrAKVLl75lH8nJySQnJ2esX7lyBYDU1FRSNcWO/D//PSd0btydYY+WY8OR5pyLOwr+Bxn+x3DmtpyLj9XH3dHkf+S4893qD12/xzK7Jca5v7Ev6oet42wwmV3arX/XLjg8rHhWqQoFC+ScPy+5Ro4730Xugs53yUtyyvmemXyGw0337qWkpODj48OiRYto3759xvbevXtz+fJlli9fft0xrVu3pmDBgvj4+LB8+XIKFSpEjx49ePXVVzGbb/xL2tixYxk37vqpe+bNm4ePjwoGEVc5Ew8f7U/Cq/QnmKxXqG2tTUffju6OJblAwauHaXj0fcyOVI4WasG+Ek9meQaPqChSChUCk9ufGhMREZEcICEhgR49ehAbG0tAQMAt93XblfTo6GhsNhuFCxe+ZnvhwoU5ePDGt8YeP36c3377jSeffJKVK1dy9OhRBg0aRGpqKmPGjLnhMaNGjWLo0KEZ61euXCEkJITmzZv/6x+O5D2pqamsWbOGZs2aZdytIXfO2HiCSeu74V1qBn+n/s0TlZ/gsTKPuTuW/EfOPd9b49hfCpY+Q/kLP1OmTlPs9fplWe+Jf/3FubFj8WvRkuCxYzBu8iWxZC8593wXyTyd75KX5JTz/b93dN8Ot97unll2u53g4GC+/PJLzGYzdevW5ezZs3z44Yc3LdI9PT3x9PS8brvVas3Wf4niXjo/nOPZJhVYf+QiO6OP41noVz7e+TEty7bE2+Lt7mjyP3Lk+V6zC1w5DWvHY/5lFObAMlCxRZZ0nXDpEo7kFOKWLcPksFN0wgQV6jlIjjzfRe6QznfJS7L7+Z6ZbG67Ty8oKAiz2UxUVNQ126OioihSpMgNjylatCgVK1a85tb2ypUrExkZSUpKikvzikjmmU0Gk7rUwvNqc1Ji7uPhfG+qQBfneWAo1O4JDjss7AsRu7Ok23xt2lD8o0lgNhO7/AfOvTICR1palvQtIiIiuZ/binQPDw/q1q3L2rVrM7bZ7XbWrl1LgwYNbnhMo0aNOHr0KHa7PWPb4cOHKVq0KB4eHi7PLCKZVzy/N2+3r0FyZAe+25DCzvAYd0eS3MIw4LHJUKYJpManT80WezZLug5o2ZLikz8Gq5UrK1dydugwHNl8wBoRERHJGTJdpJcuXZrx48cTHh5+150PHTqUGTNmMGfOHA4cOMDAgQOJj4/PGO29V69ejBo1KmP/gQMHcunSJV566SUOHz7MihUrmDBhAs8///xdZxER13m8VnEer1UMm93By6Fh/Hn2Lzae3ejuWJIbmK3Q5RsodA/ERcD3XSE5Lku6DmjWjBJTpmBYrcT98gtnhryMQ3d1iYiIyF3KdJE+ZMgQlixZQtmyZWnWrBnz58+/ZoqzzOjatSsTJ07kzTffpFatWoSFhbF69eqMweTCw8OJiIjI2D8kJISff/6Z7du3U6NGDV588UVeeumlG07XJiLZy/jHq1E8vzdnEnfz3K/9eHX9q0TGR7o7luQG3vmhxwLwLQSRe2DR02DLmtvP/Zs+TInp0zA8PDBMRvrVfREREZG7cEdFelhYGNu2baNy5cq88MILFC1alMGDB7Nz585MBxg8eDCnTp0iOTmZrVu3Ur9+/Yz3/vjjD2bPnn3N/g0aNGDLli0kJSVx7NgxRo8efdPp10Qk+8jnbWVSl5rYE0uTlliMKylXeHX9q6TZ9SyvOEGBUtA9FCxecOQXWP0qZNEMo36NG1Nq7lyKT5qEkY0HrBEREZGc4Y6fSa9Tpw6ffPIJ586dY8yYMcycOZN7772XWrVqMWvWLNw0/bqIZGP3lw3k2QcrkXi2O9g92Xl+J9PCprE9cjsrj69ke+R2bHabu2NKTlWiLnSYARiwfSZs+SzLuvauXg3jP2OjOBwOLn37HfbExCzrX0RERHKPOy7SU1NTWbBgAe3atWPYsGHUq1ePmTNn0rFjR0aPHs2TTz7pzJwikksMbVaRykFlSDzXAYCZe2by9M9P8+qGV3n656dpsbgFv5761c0pJceq0g6av5W+/PNoOPBTlkc4P3EiUe+8w+lnn8MeH5/l/YuIiEjOlukifefOndfc4l61alX27t3Lxo0b6du3L2+88Qa//vorS5cudUVeEcnhPCwmpnSrhcVkueHdyOcTzjP0j6Eq1OXONRgM9Z4GHLC4P5zN/KNYd8P/kUcx+fqSsG0b4QOexXZVhbqIiIjcvkwX6ffeey9Hjhzhs88+4+zZs0ycOJF77rnnmn3KlClDt27dnBZSRHKXsoV8KFBy5Q3fc/znf+9ve1+3vsudMQxo9SGUfxTSEuH7bnD57mckuV0+dWpTctZXmPz9Sdyxg9P9+2OLy5oR50VERCTns2T2gOPHj1OqVKlb7uPr68vXX399x6FEJHfbeX4nV9Mu3nIg7MiESHae38m9Re7NumCSe5gt0Olr+LoVRO2FeV3h6dXglS9LuveuWZOSs2YR3r8/iWFhnHqqF4VHjcTk53fD/S0FCmAtVixLsomIiEj2luki/fz580RGRl4zCjvA1q1bMZvN1KtXz2nhRCR3ioo/79T9RG7IKwB6hMKMR+D8fljQG55cmD63ehbwrl6NUrO/5lTvPiQfPEh47z433dfw8KDc6lUq1EVERCTzt7s///zznD59+rrtZ8+e5fnnn3dKKBHJ3aIvezp1P5GbylcivVC3+sDx32HF0Cybmg3Aq3Jliowd+6/7OVJSSIuJcX0gERERyfYyXaTv37+fOnXqXLe9du3a7N+/3ymhRCR3y2eqiD01301rJYcD7Kn5yGeqmLXBJHcqVgs6zQLDBDu/gU1TsrR7j1Ils7Q/ERERydkyXaR7enoSFRV13faIiAgslkzfPS8ieVCRAF+So9oC11/UdDjSx/2yJZSmSICvG9JJrlSpFbR8L3351zGwTzOQiIiISPaU6SK9efPmjBo1itjY2Ixtly9fZvTo0TRr1syp4UQkd7qvTEEKmeqRdLYnjrRrB/Jy2LwBsAbsxvA+6o54klvVfxbqP5e+vORZOL3NvXlEREREbiDTl74nTpzIgw8+SKlSpahduzYAYWFhFC5cmG+//dbpAUUk9zGbDMa0rcLA75JIiKuCyecEhiUOR5o/toQyeBVdjDX/DkZtHMnCtgsJ8g5yd2TJLVpMgJhTcHgVfN8d+v8KBcu4O5WIiIhIhkxfSS9evDi7d+/mgw8+oEqVKtStW5cpU6awZ88eQkJCXJFRRHKhltWK8lnPOhTJ54MtoRxpV2phSyiH1WwmKfJxPO3FiE6MZuT6kZovXZzHZIaOM6FIDUiIhnldIFEDtomIiEj2cUcPkfv6+jJgwABnZxGRPKZltaI0q1KEbScucT4uiWB/Lwr5e9L2041cOtGN/OWnczz2OOfizxHiry8BxUk8/aDHApj5CEQfhtCnoOcSsHi4N1fWDTovIiIi2dgdj/S2f/9+wsPDSUlJuWZ7u3bt7jqUiOQdZpNBg3KB12x7s20VRi2xEX/6KaY9+bgKdHG+gKLphfqsFnByA/z4ErSfnj5qoZNZChTA8PDA8f/+e/n/xa1Zg3e1qk7vX0RERHKWTBfpx48f54knnmDPnj0YhoHjP0MzG//5xcZm022pInJ3ut0bwtoD5/n1AIxZepIfBpfAy2rG4XBk/FsjcteKVIPOc9Jved81DwqWhSavOL0ba7FilFu96qbzoMetWUPcL2so0KOH0/sWERGRnCfTz6S/9NJLlClThvPnz+Pj48O+fftYv3499erV448//nBBRBHJawzD4P2O1Qny8+Rw1FU+/PkQPx77kUFrB5FmT3N3PMlNKjwKbSamL//+Nuxe6JJurMWK4V216g1fwUOGUHbZUqyFg13St4iIiOQsmS7SN2/ezPjx4wkKCsJkMmEymXjggQd49913efHFF12RUUTyoEA/Tz7oVB2AWZv3MH7z22w8u5FpYdPcnExynXpPQ8MX0peXD4JTf2Z5BMPjn+fhY3/8iasbNmR5BhEREckeMl2k22w2/P39AQgKCuLcuXMAlCpVikOHDjk3nYjkaU3vKUzP+0visPlhP98ZgJl7ZrL+zHo3J5Nc59HxULkt2FJgfg+4eMwtMa6uX8+5V17hzIsvkRgW5pYMIiIi4l6ZLtKrVavGrl27AKhfvz4ffPABmzZtYvz48ZQtW9bpAUUkb3utdRXKFvLl4vnKFDUeAWD0xtFExke6OZnkKiYTPPElFK+bPiXb3E6QcCnLY/jefz++DzyAIzGR088+R/LRo1meQURERNwr00X666+/jt1uB2D8+PGcOHGCxo0bs3LlSj755BOnBxSRvM3bw8zkrrWwmAwOH3iYol4ViE2OZfi64aTaU90dT3ITDx/oPh/ylYRLx9OvqKcmZWkEw8ODEp9MwatmDWyxsYT360/qf+5YExERkbwh00V6ixYt6NChAwDly5fn4MGDREdHc/78eZo2ber0gCIiNUrkZ8ijFcBh4dzhTvha/Nh1YRdTdkxxdzTJbfyC4cmF4JkPwjfD8ufBkbUTmJt8fAj5/HM8ypUjLSqK8H79bzoyvIiIiOQ+mSrSU1NTsVgs7N2795rtBQsW1LRIIuJSAx8qT71SBbgan4/88T0xMLCYLBnTQIo4TfA90GUOmCywdxH8PiHLI1gKFKDkzBlYihYl5cQJTg94FntiYpbnEBERkayXqSLdarVSsmRJzYUuIlnObDL4uGst/DwtHDxemi5FpzCk7hB9QSiuUe5heGxy+vL6DyBsXpZHsBYtSsmvZmLOnx/f++/H8PLK8gwiIiKS9TJ9u/trr73G6NGjuXQp6wfUEZG8LaSgD2PbVQVg9h+J7DkTC0CqLZVUm55PFyer8xQ0Hpa+/MOLcCLrZxXwLFuWsj/+QPCwofpCSkREJI/IdJE+depU1q9fT7FixahUqRJ16tS55iUi4kod6xSndfUipNkdDAn9m+Mxp+m9ujcT/5ro7miSGz38OlTtAPZUCO0JF7J+qlFLoUIZy/akJC4vWqTHPERERHIxS2YPaN++vQtiiIjcHsMweKd9df46GcOxC/G8t/Z39sTvYU/0HuoWrkvz0s3dHVFyE5MJ2n8GV87C6a0wtzP0Xwt+hf79WCdz2GycHvAsCdu2kXr+PIUGDcryDCIiIuJ6mS7Sx4wZ44ocIiK3rYCvBxM716TXrG388lcg7Zt2ZW1EKGP+HMM9Be+hZEBJd0eU3MTqBd3mwcxHIeYEzO8OvX8Eq3eWxjDMZvybNSNh2zaiP/kUS8GCFOjWLUsziIiIiOtl+nZ3EZHs4MGKhejbqDQAG7bdS7XAmlxNvcqwdcNItiW7N5zkPr5B6VOzeeWHM9th6bNgt2d5jIJP9SRo0EAAIseN58rqn7M8g4iIiLhWpot0k8mE2Wy+6UtEJKu82vIeKhb24+LVNKwXe1HAswAHLx3kg20fuDua5EZBFaDbXDBZYf9yWDvOPTFeeIH8XbuCw8G5V14hfvNmt+QQERER18h0kb506VKWLFmS8QoNDWXkyJEULVqUL7/80hUZRURuyMtqZnLX2ljNBusPpNKy8MsYGCw4vICVx1e6O57kRqUfgMenpS9vmgw7Zmd5BMMwKPLmG/g3b44jNZUzzw8mce++LM8hIiIirpHpZ9Iff/zx67Z16tSJqlWrEhoaSr9+/ZwSTETkdlQpFsDw5pV4d9VBvvvdmx4t+rDr0maqBVVzdzTJrWp2TX82/Y934aehkC8Eyj+SpREMs5liEz/k9IArJB84AGmaglBERCS3cNoz6ffffz9r1651VnMiIretf+Oy3F+2IAkpNraH3cvsFt9o8DhxrSavQo2u4LDBgt4QtT/LI5g8PCgx9VNKff893rVqZXn/IiIi4hpOKdITExP55JNPKF68uDOaExHJFLPJYFKXWvh7Wdh1+goz1p/OeO9ozFE3JpNcyzCg3adQqhGkxMG8LhAXmeUxzH5+eJYtk7GedPAgtsuXszyHiIiIOE+mi/QCBQpQsGDBjFeBAgXw9/dn1qxZfPjhh67IKCLyr4rn9+bt9um3uH/621H+Do/hs12f0eGHDiw/utzN6SRXsnhC1+8gsDzEnoZ5XSEl3m1x4rdt49STPTk9cBD2xES35RAREZG7k+ln0j/++GMMw8hYN5lMFCpUiPr161OgQAGnhhMRyYzHaxVn7YHz/LDrHC+HhtGhqR0HDt7e8jZVA6tSvkB5d0eU3ManYPrUbDMfhYgwWPwMdP0WTFk/24k5X34wm0n8+2/ODnmZElM/xbBaszyHiIiI3J1MF+l9+vRxQQwREed46/Fq/HXyEicvJnDuZCMaFN3F5ojNDFs3jO/bfI+P1cfdESW3KVgWus2DOe3g0Ar45Q1oOSHLY3hVqkjI558R3vdprq5bR8Trr1P03XcxTE4bfkZERESyQKb/y/3111+zcOHC67YvXLiQOXPmOCWUiMidyudjZWKXmhgGzN9+lhbBLxPsHczx2OO8veVtHA6HuyNKblTyfnjis/TlLdNg2wy3xPCpU4fikz8Gs5nY5T9w/oMPdc6LiIjkMJku0t99912CgoKu2x4cHMyECVl/5UBE5P9rWC6IAY3LAvDOj2cYde9bmA0zPx7/kSVHlrg5neRa1TrCI2+mL68aAYd/dksM/4cfpug7bwNwafZsLn31lVtyiIiIyJ3JdJEeHh5OmTJlrtteqlQpwsPDnRJKRORuDW1ekcpFA7gUn8LcPywMrjUYgHe3vUvE1Qg3p5Nc64GhULsnOOywsC9E7HZLjPzt2xM8YgSQPqCcw2ZzSw4RERHJvEwX6cHBwezeff0vHbt27SIwMNApoURE7panxczkrrXwsJj4/dAFPOIfoVmpZrxW/zWK+BZxdzzJrQwDHpsMZZpAanz61GyxZ90SJfDpvhT/aBIhU6dimLN+IDsRERG5M5ku0rt3786LL77I77//js1mw2az8dtvv/HSSy/RrVs3V2QUEbkjlYr4M7LlPQBMWHmQgZXH8USFJ66ZoULE6cxW6PINFLoH4iLSp2ZLjnNLlIDWrTE8PABwOByknHHPFwYiIiJy+zJdpL/11lvUr1+fRx55BG9vb7y9vWnevDlNmzbVM+kiku30aViaxhWCSEq1M3TBLlLS7ABcTrrM+jPr3ZxOci3v/NBjAfgWgqg9sOhpsKW5LY7Dbifqrbc58cQTJB086LYcIiIi8u8yXaR7eHgQGhrKoUOHmDt3LkuWLOHYsWPMmjULj/98Wy8ikl2YTAYTO9ckv4+VPWdj+WTtEaLio+j8U2eG/D6EfRf3uTui5FYFSkH3ULB4wZFfYHE/OPc3nAu7/nX5tEujOFJTSTp8CHtcHOHPPEPKadf2JyIiIncu0/Ok/1eFChWoUKGCM7OIiLhE4QAvJjxRnUFzdzL9j6M8WPF+KheszO+nf2f4H8MJbRtKgEeAu2NKblSiLrR4F1a8DPuXpb9uxOIJg3dA/hCXxDB5ehIyfTqnnupF8qFDhPfrT+m532EpVMgl/YmIiMidy/SV9I4dO/L+++9ft/2DDz6gc+fOTgklIuJsrasXpWOdEtgdMHTBLl6tN4bifsU5c/UMb256U3NJi+sUr/Pv+6QlQ8JFl8YwBwQQMuNLrCVKkBoeTviAZ7HFuedZeREREbm5TBfp69evp3Xr1tdtb9WqFevX6/lOEcm+xrarQokC3pyJSeSj1WeY2GQiFpOFteFrmXtgrrvjibicNTiYkl/NxBwYSPKBA5wZ9Dz25GR3xxIREZH/keki/erVqzd89txqtXLlyhWnhBIRcQV/Lysfd62FyYDFO88QHhHI8HrDAZi0YxK7L7hnTmuRrORRqhQlZ3yJydeXhB07SPjrL3dHEhERkf+R6SK9evXqhIaGXrd9/vz5VKlSxSmhRERc5d7SBRn4UDkARi/dQ9OiHWhWqhlp9jQm75zs3nAiWcSrShVKTJ9OiU+m4NeokbvjiIiIyP/I9MBxb7zxBh06dODYsWM0bdoUgLVr1zJv3jwWLVrk9IAiIs720iMVWX84mj1nYxmxeDdTnxxLoFcgg2sPdnc0kSzjW/++a9btCQmYfHzclEZERET+K9NX0tu2bcuyZcs4evQogwYNYtiwYZw9e5bffvuN8uXLuyKjiIhTeVhMfNy1Fl5WExuORLP4r4u8dv9r5PPM5+5okpelxLuv6zNnOdGhI5fmzHFbBhEREUmX6SIdoE2bNmzatIn4+HiOHz9Oly5dGD58ODVr1nR2PhERlygf7MdrbdIf0Xlv9UEORaaPcu1wOFhwaAE7o3a6M57kRcueg+gjbun66m9rSTl5kqh33yP2xx/dkkFERETS3VGRDumjvPfu3ZtixYoxadIkmjZtypYtW5yZTUTEpXrWL8nDlQqRkmZnSGgYyWk2FhxawFtb3uKV9a9wKemSuyNKbuATmD4P+r+5HA4zmsKh1a7P9P8UeOopCvR6CoBzo0ZzVbO1iIiIuE2mnkmPjIxk9uzZfPXVV1y5coUuXbqQnJzMsmXLNGiciOQ4hmHwfqcatJy8gQMRV/jol8O82OwxvjvwHSevnGT0htFMf3Q6JuOOv88UgfwhMHjHv8+DvnokhG+G77vBw69B42FgyppzzzAMCo8ciS3mMld+/JEzL75Eya9n4VO7dpb0LyIiIv+47f/6t23blkqVKrF7924mT57MuXPn+PTTT12ZTUTE5YL9vXivQ3UAvtxwnF3hiUx6aBJeZi82ndvEV3u+cnNCyRXyh0CxWrd+9foB7u0POOD3t2FhL0iOy7KIhslEsQnv4PtgYxxJSZx+biDJR9xz+72IiEhedttF+qpVq+jXrx/jxo2jTZs2mM1mV+YSEckyzasWoft9ITgcMGzBLgp7lmF0/dEATA2byvbI7W5OKHmCxQPaTIK2n4DZAw78CDMfhYvHsiyCYbVSYvJkvGvWxB4bS+Rbb2dZ3yIiIpLutov0jRs3EhcXR926dalfvz5Tp04lOjraldlERLLM622qUDrQh4jYJN5YvpcnKjxBu3LtsDvsjFg/guhE/XsnWaRub+izAvyKwIWDMONhOPJrlnVv8vEh5IvPCWjThuIfTcqyfkVERCTdbRfp999/PzNmzCAiIoJnn32W+fPnU6xYMex2O2vWrCEuLutuyRMRcTZfTwsfd62F2WTww65zLA87y2v1X6N8/vJcSrrE1oit7o4oeUnIfTDgDyhxHyTFwtxOsOEjcDiypHtz/vwUnzQRS1BQxjZHFvUtIiKS12V6RBpfX1+efvppNm7cyJ49exg2bBjvvfcewcHBtGvXzhUZRUSyRO2SBXihaXkAXl+2l5h4g0lNJjGj2QzalG3j5nSS5wQUhT4/QZ1egAPWjoNFfd0yn/rlJUs5/eyzOFJSsrxvERGRvOauho2tVKkSH3zwAWfOnOH77793ViYREbcZ/HB5aoXkJy4pjaGhYZQKKMN9Re9zdyzJqyye6c+ot/kITBbYtxS+ag6XTmRZhLSLF4l6+23i12/g3MiROOz2LOtbREQkL3LK3C5ms5n27dvzww8/OKM5ERG3sZhNTO5aCx8PM1tPXGLmhuMZ752MPcmAXwZwPuG8GxNKnmMYcG8/6P0T+AZD1N7059SP/Z4l3VsCAyn+6SdgtXJl5Sqi3pmgW99FRERcSJP/ioj8P6WDfBnTtgoAE385xP5zV3A4HIz5cwybIzYzYv0I0uxpbk4peU6pBunPqRerA4kx8F0H+PPTLHlO3a9RI4q//x4YBjFz5xI9fbrL+xQREcmrVKSLiNxAl3ohNK9SmFSbgyGhf5OcZmdcw3H4WHzYEbWD6WEqUsQN8hWHvqug1pPgsMMvr8OSZyAlweVdB7RuTeHXXgMg+tOpxOgxNxEREZdQkS4icgOGYfBuh+oE+XlyOOoq768+SOl8pRnXcBwAM/bMYMOZDW5OKXmS1QsenwatPgTDDHsWwqwWcDnc5V0X7PkkQYMGARA5/i0S9+x1eZ8iIiJ5jYp0EZGbCPTz5MPONQD4etNJ1h++QMsyLelaqSsAozeOJjI+0p0RJa8yDKg/AHotB59AiNwNXz4EJ1z/xVHQC4PJ360rQQMH4lWtqsv7ExERyWtUpIuI3MLDlYLp1aAUAMMX7iImPoUR946gSmAVLidfZvi64aTaU92cUvKsMo1hwDooUgMSLsI3j8OWz136nLphGBQZM4ZCL76AYRgu60dERCSvUpEuIvIvRrWqTLlCvpyPS2b00j1YTVYmNpmIv9UfgLiUODcnlDwtfwj0+wVqdAWHDVa/CssGQWqSy7r83+LcnpjIuVdfJfl41k0LJyIikpupSBcR+RfeHmYmd62NxWSwam8ki3eeJcQ/hK9bfs3XLb+moFdBd0eUvM7qDU98AS0mgGGCXfPg61YQe9blXUe9/z6xy38gvH8/UqOiXN6fiIhIbqciXUTkNlQvkY+Xm1UEYMzyvYRfTKBSwUpYTdaMfVJsKe6KJ5L+nHqD56HnEvAuAOd2wpdN4NRml3Zb6MUX8ShdmrRzEZzu3x/b5csu7U9ERCS3U5EuInKbnmtSjntLFyA+xcbQBWHY7OnP/abaU5m4fSJ9Vvch1abn08XNyj2cPp964WoQfwHmPAbbZ7rsOXVLwYKEzJyJJTiY5CNHOT1wEPbERJf0JSIikheoSBcRuU1mk8FHXWrh52nhr1MxfL7uGAAXEy+y9OhS9kTvYdKOSW5OKQIUKJ3+nHrVDmBPgxXD4McXIS3ZJd15lChOyMwZmAICSPz7b84OeRlHqr6wEhERuRMq0kVEMiGkoA/j2qVPO/XxmsPsPnOZIr5FmPDABADmHpjLmlNr3BlRJJ2HL3SaBY+OAwzY+Q3MbgNXIlzSnVfFioR8/hmGlxdX160j8p13XNKPiIhIbqciXUQkkzrUKU6b6kVJszsYMj+MhJQ0moQ0oW+1vgC8uelNTl857eaUIqQ/p/7AEOi5CLzywZnt6c+pn97mku586tSh+OSPsRQqRP6OnVzSh4iISG6nIl1EJJMMw+CdJ6pROMCT49HxTFh5AIAXar9A7eDaXE29yrB1w0i2uebWYpFMK/8oPPM7FKoMV6Pg69awY45LuvJ/6CHK/fIz3tWruaR9ERGR3E5FuojIHcjv48GkzrUA+G5LOL8djMJqsvLBgx9QwLMABy4d4INtH7g3pMj/CiwH/ddA5bZgT01/Rv2noZDm/FkJTN7eGcuJu3YRu3y50/sQERHJrVSki4jcoQcqBPF0ozIAjFi0m+iryRTxLcK7jd/Fz+pHvSL13JxQ5P/x9Icu30LT1wED/voKvmkHca6Z3zz5+AlO9X2ac6NGE/frry7pQ0REJLdRkS4ichdGtKxExcJ+RF9NYeTiPTgcDhoVb8TqjqtpVaaVu+OJXM8w4MFXoEcoeAZA+Gb48iE4u8PpXXmUKU1Aq5Zgt3N26DAStm93eh8iIiK5TbYo0qdNm0bp0qXx8vKifv36bNt28wFtZs+ejWEY17y8vLyyMK2IyD+8rGYmd62Nh9nErweimL89fcC4fJ75MvaJTowmMU3zRks2U7EFPPMbBFWEuHMwqxX8PdepXRiGQdFx4/Br2hRHSgqnBw4i6eBBp/YhIiKS27i9SA8NDWXo0KGMGTOGnTt3UrNmTVq0aMH58+dvekxAQAAREREZr1OnTmVhYhGRa1UpFsArLSoBMP7H/ZyIjs9476/Iv+j0Qyfe2/aeu+KJ3FxQBei/Fiq1BlsyLB8Eq14Fm/PmODcsFop/NAnvenWxX71KeP9nSDmt2Q9ERERuxu1F+kcffcQzzzxD3759qVKlCp9//jk+Pj7MmjXrpscYhkGRIkUyXoULF87CxCIi1+v3QBkalA0kMdXGkNAwUm12ANIcaVxKusSSI0v44dgPbk4pcgNeAdB1LjQZmb6+9XP4pj3ERzutC5OXFyHTp+NZqRK26GjCn+5HWrTz2hcREclNLO7sPCUlhR07djBq1KiMbSaTiUcffZTNmzff9LirV69SqlQp7HY7derUYcKECVStWvWG+yYnJ5Oc/M80SFeuXAEgNTWV1FTnXSmQ3OG/54TODbkT73eoymNT/2TX6ct88ushXmxanrpBdXm2+rN8vudz3tr8FpXyVaJsvrLujgrofJf/54HhGIWqYP5hIMapjTi+aEJapzlQtKZz2vf2puhn0znzVC+sZctg8/DAkYXnns53yUt0vkteklPO98zkMxwOh8OFWW7p3LlzFC9enD///JMGDRpkbB8xYgTr1q1j69at1x2zefNmjhw5Qo0aNYiNjWXixImsX7+effv2UaJEiev2Hzt2LOPGjbtu+7x58/Dx8XHuBxKRPG9ntMGcI2ZMOHixmo0y/mB32JkTP4djaccINgXznP9zeBge7o4qckP+iWe578Rk/JKjsBlWwkr240zBhk5r3xIbS5qfH5jNTmtTREQku0tISKBHjx7ExsYSEBBwy31zXJH+/6WmplK5cmW6d+/OW2+9dd37N7qSHhISQnR09L/+4Ujek5qaypo1a2jWrBlWq9XdcSSHGrZwDz/sjqBkQW+WD2qAn6eFS0mX6LaqG9GJ0bQp3YbxDcZjGIZbc+p8l5tKisW87FlMx9KnTbPVH4i96RgwOfcGPIfDwdUVK/Fr2QLD4tqb+3S+S16i813ykpxyvl+5coWgoKDbKtLdert7UFAQZrOZqKhr52eNioqiSJEit9WG1Wqldu3aHD169Ibve3p64unpecPjsvNforiXzg+5G289UZ0d4ZcJv5TIe6uP8H6nGhS2FubDBz+k3y/9WHFyBQ+GPEjrsq3dHRXQ+S43YA2CJxfA7xNgw0TMWz/DfH4/dJ4NPgWd1k3kW28TM3cuyTt3UGR81nxxpfNd8hKd75KXZPfzPTPZ3DpwnIeHB3Xr1mXt2rUZ2+x2O2vXrr3myvqt2Gw29uzZQ9GiRV0VU0QkU/J5W5nUpSaGAaF/nebnfZEA1CtSjxdqv0DrMq1pEtLEzSlF/oXJDI+8AZ3ngNUXTqyDL5tA5B6ndeFzf30wmbi8cBEXJk9xWrsiIiI5mdtHdx86dCgzZsxgzpw5HDhwgIEDBxIfH0/fvn0B6NWr1zUDy40fP55ffvmF48ePs3PnTnr27MmpU6fo37+/uz6CiMh17i8byIAH0weIG7l4N+evJAHQr1o/3mv8Hr5WX3fGE7l9VdtD/zVQoDRcDoevmsPeJU5pOqBZM4qMGwvAxS++4NKcOU5pV0REJCdze5HetWtXJk6cyJtvvkmtWrUICwtj9erVGdOqhYeHExERkbF/TEwMzzzzDJUrV6Z169ZcuXKFP//8kypVqrjrI4iI3NDQZhWpUjSAmIRUXlm0G4fDgWEYGbf0OhwO1p1ehxuHBhG5PYWrwjO/Q7mmkJoAi/rCmjFgt9110wU6d6bQyy8DEPXue8T++ONdtykiIpKTub1IBxg8eDCnTp0iOTmZrVu3Ur9+/Yz3/vjjD2bPnp2x/vHHH2fsGxkZyYoVK6hdu7YbUouI3JqnxcyUbrXwtJhYd/gC3245lfGew+Fg+LrhDP5tMAsPL3RjSpHb5FMQnlwEjV5KX980GeZ2hsSYu246cMAzFOzdC4Bzo0Zzdf36u25TREQkp8oWRbqISG5VobA/o1rdA8A7Kw5w9HwcAIZhUKNQDQDe2/Ye+y/ud1tGkdtmMkOz8dDxK7B4w7G18OXDcP7AXTVrGAbBr75KQNu24HBgu3zZOXlFRERyIBXpIiIu1qtBaRpXCCI5zc6Q0DBS0uzp26v04qGQh0i1pzLsj2HEpcS5OanIbareCfr9AvlKQswJmPEI7P/hrpo0TCaKvfM2pb79lnzt2jkpqIiISM6jIl1ExMVMJoOJnWuS38fK3rNXmPzrYSD96uHbjd6muF9xzlw9w5ub3tTz6ZJzFK0BA/6AMg9CajwseAp+exvs9jtu0vDwwKfOP4+wpV24QOq5c04IKyIiknOoSBcRyQKFA7x4r0N1AD5bd4xtJy4BkM8zHxObTMRisvBr+K/MOzjPnTFFMsc3EHouhfufT19f/yHM7w5JsXfddEp4OCd7PEn40/1Iu3TprtsTERHJKVSki4hkkZbVitK5bgkcDng5NIwrSakAVAuqxvB6wwGYsnMKMUl3PxCXSJYxW6DlBHjiC7B4weHVMKMpXDh8V80aHh440tJIOXmS0wOexXY13kmBRUREsjcV6SIiWWhMu6qEFPTm7OVExv6wL2N7j3t60OOeHsxoPoMCXgXcmFDkDtXsBk+vhoAScPFoeqF+cOUdN2ctUoSSX83EnD8/SXv3cvbFF7CnpDgxsIiISPakIl1EJAv5eVr4uEstTAYs2XmWn3anP29rGAaj6o+iZqGabk4ocheK1U5/Tr1UI0iJS7/1/Y/37/g5dc+yZQn58gsMHx/i/9xMxMiROGx3Pze7iIhIdqYiXUQki9UrXZDnHy4PwGtL9xIRm3jdPodjDrPs6LIsTibiBH6FoNdyuG9A+vofE9IHlUu6ckfNedeoQYlPPwGrlSsrVxH1zgQNsCgiIrmainQRETd48ZEK1CiRj9jEVIYv3IXd/k/RcSL2BD1W9GDsn2MJOx/mvpAid8pshdYfwuPTwOwBB3+CmY9C9NE7as6vUSOKf/A+GAbxmzdjj9N0hSIiknupSBcRcQOr2cTkrrXwtprZdPQiszadyHivdEBpmpZsis1hY/i64RpITnKu2j2h7yrwLwrRh9KfUz/8yx01FdCqFcU/mkSpud9hDghwclAREZHsQ0W6iIiblC3kx2ttKgPwwc+HOBiZfjuwYRiMaTCG0gGliUqIYtTGUdgddz73tIhblagHA9ZBSH1IjoV5XWDDJLiDW9YDWrXCUrBgxnrahQvOTCoiIpItqEgXEXGjJ+uXpOk9waSk2RkyP4yk1PRBsXytvkxsMhFPsyebzm5i1t5Zbk4qchf8C0Pvn6De04AD1o6Hhb0h+eodNxkTuoCjzZoT/+efzsspIiKSDahIFxFxI8MweL9jDQJ9PTgYGcekXw5lvFepYCVeq/8aAJ/+/SnbI7e7K6bI3bN4wGMfw2OTwWSF/cvhq2Zw6Ximm3I4HCRs3YIjKYkzg18gcc9e5+cVERFxExXpIiJuVsjfk/c71gBgxoYT/Hk0OuO99uXb065cO+wOO4sOL3JXRBHnqdcX+qwAv8Jwfj98+TAcXZupJgzDoOh77+HT4H7sCQmcHjCA5BMn/v1AERGRHEBFuohINvBolcJ0v68kAMMW7iI2IRVIL0Zeq/8aI+8byYQHJrgzoojzlKyf/px68XqQdBnmdoJNn2TqOXWThwclPp2KV9Wq2GJiCO/Xj9SoKNdlFhERySIq0kVEsok3HqtMmSBfImKTeG3Znoy5oH2sPjxZ+UnMJrObE4o4UUBR6LsyfQR4hx3WvAGL+0NKwm03YfbzJWTGl3iULk3auQhO9++P7fJl12UWERHJAirSRUSyCR8PCx93rYXZZPDT7giWh527bp9kWzJvb3mbzec2uyGhiJNZPKHdVGg9EUwW2LsIZjWHmFO330TBgoTMnIklOJjkI0eJ/eFHFwYWERFxPRXpIiLZSK2Q/Lz0SAUA3li2lzMx115VnL13NqGHQhm5YSQXEjT9lOQChgH3PQO9fgDfQhC5B758CI6vu+0mPEoUJ2TmDIJfGU6Bp3q6LquIiEgWUJEuIpLNDHqoHLVL5icuOY2hC3Zhs//znG7vqr2pWKAil5IuMWL9CNLsaW5MKuJEpRvBgD+gaC1IvATfPgGbp9/2c+peFSsS2K8fhmEA4EhJwWG3uy6viIiIi6hIFxHJZixmE5O71sLHw8y2E5eYseGfKaq8LF5MajIJH4sPf0X9xfSw6W5MKuJk+UrA06uhZndw2ODnUbD0OUhNzFQz9vh4Tg8cxPn3P8gY20FERCSnUJEuIpINlQr0ZWzbqgBM+uUQe8/GZrxXOl9pxjUcB8CMPTPYcGaDWzKKuITVG9p/Bi3fA8MMu+fDrJYQe+a2m4jfuo34TZu4NGcOkW+/Q+K+fSTt34/n2bMk7d9P4r59JO7bR+q568d9EBERcTcV6SIi2VTneiVoUbUwqTYHQ0LDSEq1ZbzXskxLulbqCsDojaOJjI90V0wR5zMMuH8g9FoG3gUhIgy+aAInN93W4f5NHyZw4EAALs+dy8mOnTjTtRulPvmUM127cbJjJ0527MSxlq1UqIuISLajIl1EJJsyDIN3O9SgkL8nR89f5b1VB695f8S9I6hcsDJ2h53TcafdlFLEhco8mP6cepHqkBAN37SDbTNu6zl1/0cf+dd9HCkppMXEOCGoiIiI86hIFxHJxgr6evBhpxoAzP7zJOsO/zOiu4fZg48e+oiFbRdyb5F73RVRxLUKlIKnf4FqncCeBiuHww+DIS3Z3clERERcQkW6iEg291ClYHo3KAXA8IW7uBSfkvFeCf8SFPMrlrFus9uuO14kx/PwgY4zofnbYJjg7+/g69ZwRbeqi4hI7qMiXUQkBxjZqjLlg/24EJfM6CV7bjhi9foz62m3rB3nrqpwkVzIMKDhC9BzMXjlh7N/pc+nHr7V3clEREScSkW6iEgO4O1hZnLXWljNBqv3RbJwx7UjXdsddr7Y/QXhceEMXzecVFuqm5KKuFi5punPqQdXhatRMLsN/PW1u1OJiIg4jYp0EZEcolrxfLzcrCIA437YR/jFhIz3TIaJDx/8kACPAPZE7+GjHR+5K6aI6xUsA/1+gSqPgz0VfhoCPw6BtJR/O/I6ibt2OT2eiIjI3VCRLiKSgzz7YDnuK12Q+BQbLy8II81mz3ivmF8xJjwwAYDvDnzHmlNr3BVTxPU8/aDzHHhkDGDAjq9hTluIi8pUM1Hj3+LCJ5/isGk8BxERyR5UpIuI5CBmk8GkLjXx97Sw41QMn/1x7Jr3m4Q0oW/VvgC8uelNTl/R1GySixkGNB4KTy4Ez3xwegt82QTO7MBSoACGh8etjzel/xoUPX064f36k3bhwq33FxERyQIq0kVEcpiQgj6Mb18VgMlrjxB2+vI1779Q5wVqFarF1dSrDFs3jGSbpqqSXK5CMxjwOwRVgrgI+Lol1qjfKLd6FaUXL6L04kWUCJ3PqRdfoETo/Ixt5X9dQ7EP3sfw9iZhyxaOd+hA/BYNRCciIu6lIl1EJAdqX6s4j9Uois3u4OXQMBJS0jLes5qsfNjkQ/J75qdKYJUbjgQvkusEloNn1sI9j4EtBZY/j3XrW3jnS8S7QCpe//Py/s/L6mMjX7t2lFm0EM8K5bFdiCZhx1/u/iQiIpLHWdwdQEREMs8wDN5pX52/TsZwIjqed1Yc4J0nqme8X8S3CEvaLaGQTyE3phTJYp7+0OVb2DARfn8Hds1LfwFW4CGAQ/+zv8UTBu/As1w5SoeGEjM/lIK9e2V9bhERkf+hK+kiIjlUPh8rk7rUBGDu1nDWHrh2wKz/LdBtdhsXEy9maT4RtzCZoMkIaD7h3/dNS4aE9J8Lk48PgU/3xTCbAbAnJXH62edI+EtX1kVEJGupSBcRycEalQ+i/wNlABixaDcX4q5//vxS0iUGrR3EgDUDSEpLyuqIIu5RutFdHX5xxkyurlvHqd59iJ4xA4fd/u8HiYiIOIGKdBGRHG54i0rcU8Sfi/EpjFy8+7pn0G12GwcvHeRwzGHe2/aem1KK5CyBT/cloG1bsNm4MOkjTg8cSFpMjLtjiYhIHqAiXUQkh/OympncrRYeZhNrD55n3rbwa94v5FOI9x98HwODxUcW8+OxH92UVCTnMPn6UuyD9yny1ngMDw/i163nRIeOJPz9t7ujiYhILqciXUQkF7inSAAjWlYC4O2fDnD8wtVr3r+/6P0MrDkQgLe2vMXhmMP8FfUXu1J28VfUX9jstizPLJLdGYZBgc6dKb0gFI9SpUiLiODUU72IXbHC3dFERCQXU5EuIpJLPN2oDA3LBZKYauPl0DBSbdc+QzugxgDuL3o/iWmJdPmxCwPWDmBhwkIGrB1Ai8Ut+PXUr25KLuJGtzFFodc991B68SICWrfC5OuLT61ars8lIiJ5lop0EZFcwmQymNSlJgFeFnadieXTtUeued9sMtO6TGsAbI5rr5yfTzjP0D+GqlCXvGf9+3Abd5KY/fwoNmkSZRYvxlq8eMb21KjzrkwnIiJ5kIp0EZFcpGg+byZ0SJ8vfervR9lx6lLGeza7jWlh0254nIP0q4nvb3tft75L7uATmD4P+r85tAqWDABb6r/uahgGHiX+KdDjfv+dY82acenb764bsFFEROROWdwdQEREnOuxGsVYe+A8S/8+y8uhu1j5UmP8PC3sPL+TqISomx7nwEFkQiQ7z+/k3iL3ZmFiERfIHwKDd2TMg56alsamTZto1KgRVst/fv05uwNWjYC9iyAtCTp9DRaP2+7i6m+/4UhJIeqdd0jYvp2i77yN2d/fFZ9GRETyEF1JFxHJhcY9XpXi+b0Jv5TA+B/3AXAh4cJtHXu7+4lke/lDoFit9FfRmsT6lIaiNf/Zdm8/6PodmD3g4E8Q+iSkJt5280XGj6fw6NFgtRL3yy+c6NiJxH37XPNZREQkz1CRLiKSCwV4WfmoS00MAxb8dYbVeyMo5FPoto693f1EcoVKraBHKFi84cgvMK8LpMTf1qGGYVCw11OUnvsd1mLFSA0P51S37sTMn6/b30VE5I6pSBcRyaXqlw3kuSblABi5ZA/FvatQ2KcwBsZNj7EYFgK9A7Mqokj2UK4p9FwEHn5wYj181xGSrtz24d41alBmyWL8mjbFkZpK5NhxJO7c6cLAIiKSm6lIFxHJxV5+tCJViwVwOSGVkYv38eq9rwLctFBPc6TRc0VP1p1el5UxRdyv9APw1DLwzAfhm+GbxyHh0r8e9l/m/PkpMW0qwSNGUODJJ/GpW9d1WUVEJFdTkS4ikot5WExM7loLT4uJ9YcvcO5cBT566COCfYKv2a+ITxHGNhhL7eDaxKXGMfi3wUwPm+6m1CJuEnIv9P4BvAvCuZ0wpx3ER9/24YZhEPh0X4q88XrGtrToaC4vW6bb30VE5LapSBcRyeUqFPZndOvKAExYeYBSXvX5uePPfPnIl3T26cyXj3zJ6o6r6VixI181/4ru93R3c2IRNypWC/qsAN9giNoDX7eGuMg7asphs3H2lVeIGDmKiJEjsSckODeriIjkSirSRUTygF4NStGkYiGS0+y8ND8Mm92gXuF61PSoSb3C9TCbzABYzVZG1x/NF49+wXM1n8s4XlcBJU8pXAX6roKA4hB9CL5uBZdPZ74dw8C3QUMwm4ld/gMnOnch+cgR5+cVEZFcRUW6iEgeYBgGH3aqQQEfK/sjrjDxl0NsPXGJHdEGW09cwma/tghvWLwhJiP9PxFJaUn0Wd2HFcdXuCO6iHsElYe+KyF/Sbh0PP2K+qXjmWrCMJkIGvAMpWZ/jaVQIVKOHeNEl65cXrrMNZlFRCRXUJEuIpJHBAd48W6HGgB8uf44PWf9xTdHzPSc9RcPvP8bq/dG3PC4BYcWsPP8TkZuGMn7294n1Z6albFF3KdAaei7GgLLQ2x4eqF+4XCmm/G5917KLFuKb8OGOBITiRg1inOvvYY98fbnZBcRkbxDRbqISJ5y49vWI2OTGPjdzhsW6k9WfpJnqj8DwHcHvqP/z/2JTrz9wbREcrR8xaHPSihUGeIi0m99j9yb6WYsgYGEzPiSoBdfAJOJxB07cdjsLggsIiI5nYp0EZE8wmZ3MO7H/Td877+l+7gf919367vZZObFOi8y5eEp+Fp92Xl+J11/7ErY+TDXBhbJLvwLpw8mV6QGJETDnMfgbObnQTfMZgoNGkTJWbMoPmUyZj9fQGM+iIjItVSki4jkEdtOXCIiNumm7zuAiNgktp248dzQTUs25fs231MuXznOJ56n7899+fnkzy5KK5LN+AamT89WvB4kxqTPox6+9c6aur8+XpUqZazHfPMNEWPGYk9OdlZaERHJwVSki4jkEefjbl6g3+5+ZfKVYW6buTQr1Qw/qx/Vg6o7K55I9uddAHotg1KNIPkKfPsEnNhwV02mnj/P+UkfcTk0lJPdupNy6pRzsoqISI6lIl1EJI8I9vdyyn6+Vl8mNZnE/MfmU8yvWMb2+NT4u8onkiN4+sOTi6Dsw5AaD3M7wdFf77g5a3AwJaZPx1ywIMkHDnCiQ0eurNYdKiIieZmKdBGRPOK+MgUpms8L41/2C90eTlzSrUdwNwyD4n7FM9bXnV5Hq8Wt+PPsn05IKpLNefhA9/lQsSWkJcH33eHgnU9R6PdAI8osXYp3vbrY4+M5O2QIkW+9jT0lxYmhRUQkp1CRLiKSR5hNBmPaVgG4rlA3/uf/l4Wd47FPN7Lr9OXbatfhcDD3wFxikmN47tfnmLlnpgbCktzP6gVdvoUqj4MtBRb0gr2L77y5wsGUmj2bwAEDAIiZO5fwXr1x2GzOSiwiIjmEinQRkTykZbWifNazDkXyXXtLe5F8Xnzesw4Ln2tA8fzenLqYQMfP/uTzdcew229dcBuGwaePfErHCh1x4GDKzikM+X0IV1OuuvKjiLifxQM6zoIaXcGeBov7Q9i8O27OsFgIHvoyIV98jjlfPvybN8cwm50YWEREcgIV6SIieUzLakXZ+GpTvnu6Hr0q2Pju6XpsfLUpLasVpV7pgqx8sTFtqhclze7gvVUH6TVrG+ev3HrQOU+zJ2MbjmVMgzFYTVZ+O/0b3Vd059jlY1n0qUTcxGyB9p9Dnd7gsMOygbD9q7tq0q9JE8qu+ImCfftkbEuNiMCh299FRPIEFekiInmQ2WRQv0xB6gY5qF+mIGbTPzfA5/OxMrVHbd7rUB0vq4mNR6NpOWUDvx88/6/tdqrYiTkt51DYpzAnr5ykx4oeRFyNcOVHEXE/kwnaToH6z6WvrxgKm6ffVZOWoCAMI/3n0h4fT/jT/Tj51FOknjt3t2lFRCSbU5EuIiLXMQyDbveV5KcXHqBy0QAuxafQd/Z2xv+4n+S0Wz8jW71QdUIfC+W+IvfRtlxbivoVzaLUIm5kGNDyPWg0JH3951GwfqJTmk4+fpy0ixdJ2rWbE090IO6PP5zSroiIZE8q0kVE5KbKB/uzdFBD+jQsDcCsTSd4YtqfHLtw6+fNA70D+aLZF7x676sZ22KSYohJinFlXBH3Mgx4dCw8NDp9/be3YO1bcJcDKXpXr06ZJUvwql4dW2wsZ54byPmJE3Gk3noWBhERyZlUpIuIyC15Wc2MbVeVr3rXo6CvB/sjrvDYJxtZsP30LUdxt5gsWM1WANLsabyy/hW6/tSVfdH7siq6SNYzDHjoVWg2Pn19w0T45fW7LtQ9ShSn9NzvKNDrKQAuzvyKU336khoVdbeJRUQkm1GRLiIit+WRyoVZ9VJjGpYLJDHVxojFu3nh+7+JTfz3q3kXEy8SGR9JRHwEvVb1YumRpVmQWMSNGr0ErT5MX948FVYOB7v9rpo0PDwoMno0xadMweTnR+KOHURNeNcJYUVEJDtRkS4iIretcIAX3/arz4iWlTCbDH7aHUHrKRvYcerSrY/zLcz3bb7noZCHSLGn8OafbzJ+83hSbBqtWnKx+gOg7SeAAdtnwg8vgP3u5z0PaNGcMksW4/tgY4q8/trd5xQRkWxFRbqIiGSK2WQw6KHyLHquASEFvTl7OZEuX2xh6m9HsN1iTnV/D3+mPDyFwbUGY2Cw8PBC+q7uS2R8ZBamF8lidXtDhy/BMEPYd7DkGbDd/bPkHiVLUvLLL7EUKpSx7dJ3c0mN+vdZGEREJHtTkS4iInekdskCrHixMe1qFsNmdzDxl8M8OXMLEbGJNz3GZJh4tuazTHtkGgEeAeyO3s2I9SNu+Wy7SI5Xowt0/hpMFti7GBb2gbRkp3ZxZdUqot5+mxMdOhD/559ObVtERLKWinQREbljAV5WpnSrxcTONfHxMLPl+CVaTdnAL/tufXW8cYnGzH9sPrWDa/PG/W9kzActkmtVeRy6zQOzJxz8CeY/Cak3/0IrszzvuQfPSpWwXbxIeL/+XPh0Kg7b3d9aLyIiWU9FuoiI3BXDMOhUtwQ/vfAA1YoHcDkhlQHf7uDN5XtJSr15kRDiH8KclnOoUKBCxrZNZzeRkJqQFbFFsl7FFtAjFCzecHQNzO0MybeezvB2eZYpQ+nQ+eTv3AkcDqKnTSO8f3/SoqOd0r6IiGQdFekiIuIUZQv5sWRgI55pXAaAbzafov20TRyJirvpMf97BT3sfBiD1w7myZVPcurKKZfnFXGLcg/DU0vAww9OboDvOkJSrFOaNnl5UfSttyj2wfsY3t4kbN7C8SeeIH7bNqe0LyIiWUNFuoiIOI2HxcRrbaow5+n7CPLz4GBkHI99upG5W0/d1nPn+b3yc/TyUbr91I0/Tv/h8rwiblGqIfRaDl754PQW+OZxSLj1DAmZka9dO8osWohnhfLYLkRjj7v5F2UiIpL9qEgXERGna1KxEKteepAHKxYiOc3Oa0v3MvC7nVxOuPmUa7WCa7HgsQXUDq7N1dSrvPDbC0z9eyo2J0xZJZLtlKgHvX8Cn0A49zfMaQtXLzitec9y5SgdGkrxjz/C/5FHMrZrkEYRkexPRbqIiLhEIX9PZve5l9daV8ZqNli9L5JWUzaw9fjFmx/jU4ivmn9Fj3t6APDF7i8Y/NtgYpOdczuwSLZStAb0WQF+hSFqL8xuA1cinNa8yceHgFatMtZTIyI48UQHEnbscFofIiLifCrSRUTEZUwmg2ceLMuSgY0oHehDRGwS3Wds4eM1h0mz2W94jNVsZVT9UUx4YAJeZi82nt3IqhOrsji5SBYJrgx9V0FACYg+BF+3gsvhLunqwuQpJB88yKlevbk4cyYO+41/BkVExL1UpIuIiMtVL5GPn15sTMc6JbA7YMraI3T7cgtnYm4+knvbcm35tvW39Kzck66VumZhWpEsFlgO+q6E/KUg5gR83RouHXd6N0XefIOAxx4Dm43zEydxZuAg0mJinN6PiIjcnWxRpE+bNo3SpUvj5eVF/fr12Xabo5DOnz8fwzBo3769awOKiMhd8/O0MKlLTaZ0q4Wfp4W/TsXQesoGVu65+e299xS8h1fvezVjFPiE1ARm7J5Bqj01q2KLZI0CpdKvqAeWh9jTMKsVXDjk1C5Mvr4U+/ADiowbh+HhwdV16zjRoSOJYWFO7UdERO6O24v00NBQhg4dypgxY9i5cyc1a9akRYsWnD9//pbHnTx5kuHDh9O4ceMsSioiIs7weK3irHyxMTVD8nMlKY1Bc3cyasluElP+fYC4MX+O4ZO/P6H/z/2JTtT8z5LL5CueXqgHV4GrkelX1CP3OLULwzAo0LULpUPnYy1VkrSICE72fIqrGzc5tR8REblzbi/SP/roI5555hn69u1LlSpV+Pzzz/Hx8WHWrFk3PcZms/Hkk08ybtw4ypYtm4VpRUTEGUoG+rDouQYMfKgchgHfbztN26kbORBx5ZbHtSrTCj+rHzvP76TLj10IOx+WNYFFsopfcPqo70VrQkI0zH4Mzu50ejdelStTZvFi/Fu2xLNsWXzq1XV6HyIicmcs7uw8JSWFHTt2MGrUqIxtJpOJRx99lM2bN9/0uPHjxxMcHEy/fv3YsGHDLftITk4mOTk5Y/3KlfRfAFNTU0lN1e2Scq3/nhM6NyQvyA7n+9BHynF/6fy8sngvR89f5fFpmxjZoiI964dk3OL+vxoXbcy3Lb5l2IZhHI89Tt+f+zK8znA6V+h8w/1F/is7nO+3zSMAeizBPL8rprN/4fimHbau83GE1HduP56eBH/wPvYrcdjMZmypqTjsdlJPnMCjXDnn9iVZKked7yJ3Kaec75nJZzjcOGHmuXPnKF68OH/++ScNGjTI2D5ixAjWrVvH1q1brztm48aNdOvWjbCwMIKCgujTpw+XL19m2bJlN+xj7NixjBs37rrt8+bNw8fHx2mfRURE7tzVVJh71MT+y+k3eFUrYKd7OTt+1hvvn+xIZmnCUvam7gWgtrU27XzaYTVucoBIDmSxJVL/+McEXT1ImsmDrWWHEu1fxaV9FvztNwJ/XcuFNq253LAh6MsvERGnSEhIoEePHsTGxhIQEHDLfd16JT2z4uLieOqpp5gxYwZBQUG3dcyoUaMYOnRoxvqVK1cICQmhefPm//qHI3lPamoqa9asoVmzZlit+mVfcrfsdr53djj4dutp3lt9iL0xJj455M2HnarRoGzgDfdv72jPtwe/5ZOwTzhtPk3Dpg0p5F0oi1NLTpHdzvfbltoK+6LeWI7/TsOTk7F1nI2j/KMu6crhcBD561ribTaCf/iRMolJBI8bi9nf3yX9ievk2PNd5A7klPP9v3d03w63FulBQUGYzWaioqKu2R4VFUWRIkWu2//YsWOcPHmStm3bZmyz/2eOT4vFwqFDhyj3/27P8vT0xNPT87q2rFZrtv5LFPfS+SF5SXY63/s1LkeDcoV44fudHLsQT+/ZOxj0UDmGPFoRq/n6YVT61ehHtULV8DB7UCygmBsSS06Tnc7322LNBz1CYWEfjEMrsSx8CjrPhsqPuaS7kE+mEPPNN0R9OJH4NWs4c+gQJSZ/jFcV117BF9fIcee7yF3I7ud7ZrK5deA4Dw8P6taty9q1azO22e121q5de83t7/91zz33sGfPHsLCwjJe7dq14+GHHyYsLIyQkJCsjC8iIi5QpVgAP77wAN3uDcHhgGm/H6Pz55s5fenGc6rXL1qf2sG1M9ZXn1zNzD0zcePTXCLOZfGELt9AlfZgT4UFvWDvYpd0ZRgGBXv3pvTc77AUK0pqeDgnu3UnZv58/UyJiGQRt4/uPnToUGbMmMGcOXM4cOAAAwcOJD4+nr59+wLQq1evjIHlvLy8qFat2jWv/Pnz4+/vT7Vq1fDw8HDnRxERESfx8bDwXscaTOtRB38vC2GnL9N6ygaWh5295XFR8VG8uelNpuycwpDfh3A15WoWJRZxMbMVOn4FNbuDwwaL+8Pfc13WnXfNmpRdsgS/hx/GkZJC1IR3ST1zxmX9iYjIP9xepHft2pWJEyfy5ptvUqtWLcLCwli9ejWFCxcGIDw8nIiICDenFBERd2hToyirXmpM3VIFiEtO46X5YQxfuIv45LQb7l/YtzAj7h2B1WTlt9O/0X1Fd45dPpbFqUVcxGyBx6dD3b7gsMPyQbB9puu6y5+fEtOnEfzKKxR+7TU8dMeiiEiWyBYDxw0ePJjBgwff8L0//vjjlsfOnj3b+YFERCTbKFHAh9AB9/PJb0eZ+tsRFu04w45TMXzavTbViue7bv9OFTtRqUAlXv7jZU5eOUmPFT14+4G3aVaqmRvSiziZyQSPfQwWL9j6GawYBmnJ0OB5l3RnGAaB/Z6+Zlvinr0kHzpIvo4dNfWhiIgLuP1KuoiIyL+xmE0MbVaRec/cT9F8XpyIjueJ6ZuYueE4dvv1z8lWL1Sd0MdCua/IfSSkJTD0j6F8tOMjPVMruYNhQMt34YGX09d/Hg3rP8ySrm1Xr3L25ZeJeP0NIkaOxJ5w47EiRETkzqlIFxGRHOP+soGseqkxLaoWJtXm4O0VB3h6znairyZft2+gdyBfNPuCPlX7pG9woKt+knsYBjwyBh5+LX39t7dh7Xhw8RdRJh8f8nfuDCYTsct/4ESXLiQfPerSPkVE8hoV6SIikqPk9/Hg8551ebt9NTwtJv44dIGWkzew/vCF6/a1mCwMqzeML5t9yYt1XszYrivqkisYBjQZAc3eSl/fMAl+fs2lhbphMhH07ABKzZmNpVAhUo4e40TnLlxetsxlfYqI5DUq0kVEJMcxDIOe95fih8EPUKmwP9FXk+k1axvvrjxASpr9uv0bFGuAxZQ+DEuqLZVnfnmGpUeWZnVsEddo9CK0npi+vGUarBgK9ut/DpzJ5957KbNsKb4NG+BITCRi5CjOvfYa9pQUl/YrIpIXZIuB40RERO5EpSL+LB/ciHdWHODbLaf4Yv1xNh+/yJRutSkT5HvDY5YdW8bWyK1sjdzK7ujdjLpvFB5mTeEpOdx9z6QPJvfDC/DXLEhNgsengsnssi4tgYGEzJhB9OefEz11GmnR0RgWC6nnzpEWE3Pz4woUwFqsmMtyiYjkdCrSRUQkR/OymnmrfTUeqBDEq4t3s/tMLI99soG32lejQ50S1+3fsUJHYpJimPr3VBYdXsShS4f46KGPKOJbxA3pRZyozlNg9YYlA2DXPEhLgg5fps+x7iKG2Uyh55/Hp249PCtVJC0ykmMtW+G4xRV1w8ODcqtXqVAXEbkJ3e4uIiK5QouqRVj1UmPqlylIfIqNoQt2MWT+38QlpV6zn8kwMaDGAKY/Op0AjwD2RO+h609d2R653U3JRZyoeifoPBtMVti3BBb2SZ+izcV876+PpUAB0mJiblmgAzhSUm55pV1EJK9TkS4iIrlG0XzezHvmfoY1q4jZZLAs7BxtPtlI2OnL1+37QPEHmP/YfO4peA+Xki7xzC/P8OOxH7M+tIizVWkH3eaB2RMO/gTze0BqortTiYjIbVKRLiIiuYrZZPDCIxUIHXA/xfN7E34pgU6f/clnfxy7bk71EP8Qvmn1DW3LtsXb4k2NQjXclFrEySo2hycXgNUHjv4KcztD8lV3pxIRkdugIl1ERHKleqULsvKlxrSpXpQ0u4P3Vx+k16xtnL+SdM1+3hZv3nngHRa2XUipgFIZ26+mqKCRHK7sQ9BzCXj4w8kN8F0HSIp1dyoREfkXKtJFRCTXyudtZWqP2rzfsTreVjMbj0bTcsoGfj94/pr9DMOghP8/g8xtPreZlkta8sfpP7I2sIizlWoAvZaDVz44vRXmtIOES+5OJSIit6AiXUREcjXDMOh6b0l+fOEBKhcN4FJ8Cn1nb2fcj/tITrPd8JjvD35PbHIsL/z2AlP/norNfuP9RHKEEnWh90/gEwgRYTD7Mbh6wd2pRETkJlSki4hInlA+2I+lgxrSt1FpAL7edJInpv3J0fPX39Y+qckketzTA4Avdn/B4N8GE5us24QlBytaA/qsBL/CcH4fzG4NV865NdLVTZtIjYhwawYRkexIRbqIiOQZXlYzY9pWZVafehT09WB/xBXafrqR0O3hOBz/DCpnNVsZVX8UEx6YgJfZi41nN9L1p64cunTIjelF7lLwPdB3FQSUgOjD8HUruBzu1C4sBQpgeHjcch/DwwN7UjJnXxrC8fZPcOXnX5yaQUQkp7O4O4CIiEhWa3pPYVa/1JiXF4Sx6ehFXl28h/VHopnwRHXyeVsz9mtbri0VClRgyO9DOHv1LD1X9mRRu0XXDDAnkqMEloO+K+GbdhBzEma1gt4/pG93AmuxYpRbveqW86BbChTAYbPhUaYMSXv2cPall4jv3InCo0Zh8vFxSg4RkZxMV9JFRCRPCg7w4tun6/Nqy3uwmAxW7I6g9ZQN7Dh17aBa9xS8h9DHQmlUvBHNSzenpH9JNyUWcZICpdKvqAdWgCtn4OvWcP6g05q3FiuGd9WqN31ZixXDIySE0vPmEjhgABgGlxcu4kSHjiTu2+e0HCIiOZWKdBERybNMJoOBD5Vj0cCGlCzow9nLiXT5Ygufrj2C7X/mVM/nmY9pTacxpsEYDMMAIDY5lujEaHdFF7k7AcXSr6gHV4WrkTC7DUTuydIIhtVK8NCXKfn111gKFybl5ElOduvOxa9nZ2kOEZHsRkW6iIjkebVC8rPixQd4vFYxbHYHk9YcpseMLUTEJmbsYzaZ8TCnP2trd9gZtWEUXX/sStj5MDelFrlLfsHQ5ycoWgsSotNHfT+7I8tj+N5fnzLLluLf7FFITSUtKirLM4iIZCcq0kVERAB/LyuTu9ZiUuea+HiY2XriEq2mbOCXfZHX7RuTFMO5q+c4n3ievj/3Zf7B+dcMPCeSY/gUTH8mPaQ+JF2GOY/Dqc1ZHsNSoADFP/mEYpMmUmjoyxnb7SkpWZ5FRMTdVKSLiIj8h2EYdKxbghUvNqZ68XxcTkhlwLc7eGPZXpJS/5krPdA7kHlt5tG8VHPS7Gm8s/UdXt/0OklpSW5ML3KHvPJBzyVQujGkxMF3HeD4uiyPYRgG+dq0wfSf0eEdaWmE9+5D5Pjx2JP0syUieYeKdBERkf+nTJAviwc2ZMCDZQH4dsspHp+6icNRcRn7+Fh9mNhkIsPrDcdkmPjh2A/0WtWLM3Fn3BVb5M55+sGTC6H8o5CaAHM7w2H3To0Wv3kLiX//Tcy87znZuTNJhzQFoojkDSrSRUREbsDDYmJ068rMefo+gvw8ORQVR9tPN/LdllMZt7YbhkHvqr35stmXFPAswIFLBxj6x1Dd+i45k9Ubus2DSm3Algzze8CBH90Wx6/xA4TMmIE5KIjkI0c52bkLl779Tj9fIpLrqUgXERG5hSYVC7HqpcY0qViI5DQ7ry/by3Pf7eBywj/PytYvWp8FbRdQt3Dda0aAF8lxLJ7QZQ5UfQLsqbCgN+xZ5LY4fo0foOzyZfg2eRBHSgpR77zD6eeeI+3iRbdlEhFxNRXpIiIi/6KQvydf97mX19tUxmo2+HlfFK2mbGDr8X8KhSK+Rfi6xddUDaqasW3zuc1cTbnqjsgid85shY5fQc0e4LDB4v6w81u3xbEEBhLy+ecUfu01DA8P4tet59yrI92WR0TE1VSki4iI3AaTyaB/47IsHdSIMkG+RMQm0X3GFj5ac5g0mx3gmivo+y7uY/DawXRf0Z1jl48BYLPb2B65nZXHV7I9cjs2u+2GfYm4nckMj0+Dek8DDvhhMGyb4bY4hmFQ8KmelF64EK/q1Sk8SkW6iOReFncHEBERyUmqFc/HTy88wJgf9rFoxxk+WXuEP49GM7lbLUoU8PlnRwcU8CrAySsn6b6iO10qdmH1ydVEJfwzB3Rhn8KMvG8kj5Z61A2fRORfmEzQ5iOweMGW6bByOKQlQcMX3BbJq1JFSi8IveYLsZiFC/GpUwfPcuXclktExJl0JV1ERCSTfD0tTOxckyndauHnaeGvUzG0mrKBFbsjMvapGlSV0MdCua/IfSSmJTJn/5xrCnSA8wnnGfrHUH499WtWfwSR22MY0GICNB6Wvv7L67DuQzdH+qdAT9i5k8gxYznRsRMxoQs0qJyI5Aoq0kVERO7Q47WKs/LFxtQKyU9cUhrPz9vJqCW7SUhJA9LnU5/+yHR8LD43PN5BekHx/rb3deu7ZF+GAY+8CU1fT1///W1YOx6yQUFsLVEC3/vvx5GUROSYMZx98UXSYmLcHUtE5K6oSBcREbkLJQN9WPhcAwY9VA7DgO+3nabtpxvZf+4KALujd5OQlnDT4x04iEyIZOf5nVkVWeTOPPgKNH8nfXnDJPh5tNsLdWtwMCEzZxA8YgRYrcSt+ZUT7Z8gfstWt+YSEbkbKtJFRETuktVsYkTLe5jbrz7B/p4cuxBP++mbmL3pBOcTzt9WGxcSLrg4pYgTNBwMbSalL2+ZDj+9DHa7WyMZJhOBT/el9Pzv8ShThrSoKML79uXCtGluzSUicqdUpIuIiDhJw/JBrB7yII/cE0xKmp2xP+5nzoZLt3Vs+JVwPU8rOcO9/eHx6WCYYMfXsHwQ2NLcnQrvqlUps3gR+Tt3BocDS2CQuyOJiNwRFekiIiJOVNDXg5m96zGuXVU8LCa2HcgPafn+9bhpu6bR9aeurDu9TsW6ZH+1n4QOM8Aww67vYUl/sKW6OxUmHx+KvjWeUnO/I3/XLhnb0y5d0s+ViOQYKtJFRESczDAMejcszbJBjShXyJ/EyLY4HNc/vvvfbdXzP4CPxYcDlw4w+LfBPLnySTad3aSiQrK36p2gyzdgssK+pbCgF6QluzsVAD5162aMAm+Li+Nkp86cGzYc25Urbk4mIvLvVKSLiIi4SJViASx//gGsyTVJOtsTx/+7ou5Iy0fS2Z6c2N+JFU+som+1vnhbvNkTvYfnfn2OE7En3JRc5DZVfgy6f58+l/qhlfB9N0i5+UCJ7pCwbRupUVFcWbmSE+2fIGGnBmkUkezN4u4AIiIiudmes7EkptggpRppcVUw+5zAsMThSPPHllAGMBFBEkciHAytO5ReVXoxa+8sLiVdomz+shntnI47TYh/iPs+iMjNVGgGPRakF+jHfoNv2kGz8WC98dSD+ARC/qw7l/0feYTS8+ZydvgrpJ4+zameTxE0cCBBA5/DsOhXYRHJfvQvk4iIiAudj0v6nzUTtoRyt9wvyDuIEfeOuOZW94irEbRb1o66hesyuNZgagXXcmFikTtQtgk8tRS+7QBntsPXrW6+r8UTBu/I0kLdu2ZNyixdQtRbbxO7fDnR06YR/+efFPvwQzxKFM+yHCIit0O3u4uIiLhQsL/Xbe337eZT7Dj1z0jw/32eFsiYQ31rxFaeWvUUz/36HHsu7HFuUJG7VfJ+eGzSv++XlgwJF12f5/8x+/lR7P33KPbhh5j8/Ej8+28uTJmS5TlERP6NinQREREXuq9MQYrm88L4l/3+OhVDx8820+mzP1mzPwq7/Z8r6W3KtuGnJ36iY4WOmA0zm85uosfKHgxeO5gDFw+49gOIZEahyu5O8K/ytX2MMsuW4t+8+f+1d9/RUVT9H8ffsy2b3nulhRYgQABBUKoggoCgqICIgpVHBFSwYhcfFctPREUFBQUeOgiCgKI0hdCRFkooIb33ZHfn98eShSUJBAQSyPd1zpxkZ+/M3Nmdzcln75178X/pxequjhBClCMhXQghhLiGtBqFSX2bAJQL6srZZVLfJtwXE4JeqxB7IpNRP8TS4+M/mLftJMUmMwDBLsG83uF1lvdfzt317kajaPjj9B+MWD2C/NL863pOQtzoDCEhhHz2KTpPTwBUVSXlo48o3LOnmmsmhBAS0oUQQohrrldUINOGtiLA3b7re4C7kWlDWzHi1jr8d1ALNk7oyhO318PVQcfR1HwmLNxLp/d/Z9r6o2QXWuegDnUL5Z2O77C031J61+nNkMZDcNY72/Z5Ovf0dT03IW4GOStXkj79G+IfHELaV1+jms3VXSUhRC0mA8cJIYQQ10GvqEB6NAlg6/EMUnKL8HM10raOF1rNufZ1fzcjE+9sxNNd6jFn60m+2xhPUk4R7686yNTfj/BguzBG3BpBoLsjEe4RvH/b+3YDzG1L2sajqx+lV51ePNniSeq416mOUxXi0paNhg7PQOO7QV+1cRuuJZdOnXC9sxe5v6wi9eOPyd+0iaD/vo8+IKC6qyaEqIWkJV0IIYS4TrQahfb1vOkXHUz7et52Af18rkY9j91Wjz9f6MKH97Yg0t+FvGITX/95jE7v/874/+3mUFIuYD/AXGxSLCoqvxz/hf5L+/Pyxpc5mXPyupybEJclaS8sGgVTGsPqlyHtSLVWR+vmRvCUKQS++y6KkxMFW7dyrF9/cn79tVrrJYSonSSkCyGEEDWUQadhUOsQVo25je8ejqFdHS9MFpWFO07T85M/eWTmNv46lm5rTX8y+knm9ZlH55DOWFQLy44u4+4ldzNp8yQS8hKq+WyEOE/MI+AWAoUZsOVz+Lw1fN8X/lkMppJqqZKiKHjcM4C6ixZijIrCkp1NwjNjSPnkk2qpjxCi9pKQLoQQQtRwGo1C10b+zHu8PYuf6sCdUQEoCvx2MIX7v/6L/l9s5pe9iZgtKk28m/B/3f6POXfNoWNwR8yqmUVxi3hy7ZN2XeOFuCacvK3zoF+MzgE6joNn98AD86BBT0CB43/C/Ifh46aw9g3IjL8OFS7PEBFBxE8/4j1qFGi1OLdrVy31EELUXnJPuhBCCHEDaRnmybShrTmels83G44xf/tpdp/K4skfdxDh7cTITnUZ1DqEKJ8opnWfxq6UXUzdNZW+9frausaXmkvJLM7Ez8mvms9G3HQ8QmH09ovPg+7kbS0H0LCXdck6CTt+sC55ybBxCmz8GOp3t7a6N7gDtNfv31bFYMBv/Dg87rsXQ2iobX3xkSMY6tZF0Ug7lxDi2pGQLoQQQtyA6vg4886AZjzbPZIftsTzw5YTxKcX8MqSfXy85jAPd4hgWPtwov2imX7HdLtW9MVHFvPfbf/l3sh7ebTZo/g4+lTjmYibjkfouRBe5W3CoOsrcPsEOLQSYmfAsd/hyBrr4hoErYdDy2HgHnxt6l2B8wN6ycmTxN83GMfoaAInv4feT77kEkJcG/I1oBBCCHED83V1YPwdDdk8sSuT+jYh2MOR9PwSPlpzmPbv/cbry/7hVEaB3QBzW5O2UmwuZvaB2dy58E6mxE4hoyijGs9CiLO0emjSDx5aAv/ZYR0B3skbcs/A+vfgkyiY8yDErQWL5bpWrfjwYVSLhfzNmznerz+5v/9+XY8vhKg9JKQLIYQQNwFnBx0jbq3D+uc78+n90TQJdKOw1MzMzfF0/nA9Y+bu5J8z2QB8cNsHfNn9S5r5NKPIXMSMf2bQa2EvPtvxGdnF2dV8JkKc5V0P7ngLxh2Agd9CeEdQLXBoBfw4ED5rARs+gryUINeSpAAAVhtJREFU61Id1+7dqbNgPg6NGmHOzOT0k0+R9NbbWIqKrsvxhRC1h4R0IYQQ4iai12roFx3Mimc6MuvRtnSs74PZorJ01xnu+mwjw779m01H0ukQ1IEfe//I1G5TaezVmEJTIdP3TmfS5knVfQpC2NM5QLNBMGIFPL0V2j0JRnfrfezr3rRO4/a/4XDsD7jGgyM61K9PxLy5eA1/CIDMH38k/t77KDp8+JoeVwhRu0hIF0IIIW5CiqLQqYEvs0e24+f/dKRviyA0CmyIS2Pot3/T5/82snxPIh0COzKvzzw+6fIJkZ6RPBL1iG0f2cXZ5JXkVeNZCHEB34Zw52QYdxD6T4OQNmAxwf4l8MPd8HkMbP4/KLh2t29oHBzwf/FFQqd/jdbbm+K4OHKWL79mxxNC1D4S0oUQQoibXFSwO//3QEv+eL4LD3eIwKjX8M+ZHJ6Zs5POH67n+83xtA+4nQV9F9Dct7ltuy93f0mvRb34Zu83FJQWVOMZCHEBgxNEPwgj18ITGyHmUTC4QvoR+PUV+KgRLHoMTmy5Zq3rLp06UXfpEryGD8f3P/+5JscQQtROEtKFEEKIWiLUy4nX727K5ondGNs9Ei9nA6czC3l9+X46TP6Nj9fGkZ5XDIDZYmZb0jayi7P5dMen3LnoTr7/53sKTYXVfBZCXCCgGfSZAuMPQt9PIaA5mIthzzyY0Qu+aA9/fw2FWVf90DofH/xfnIhiMACglpZyavRo8jZuuurHEkLUHhLShRBCiFrGy9nAmO4N2DShK2/1jyLMy4msglI+WxdHh8m/8cqSvZzKKGJun7m82/FdQl1DySjK4MPYD7lz4Z3M3j+bYnNxdZ+GEPYcXKD1w/D4nzDqN+t0bTpHSD0AvzxvbV1f+jQkbL9mreuZP/1E3tp1nBo5kuT3/4ulpOSaHEcIcXOTkC6EEELUUo4GLcNuCef35zrzxZBWNA9xp9hkYfZfJ+n60XrGzNlDmKETS/sv5c0ObxLsEkx6UTrvb3ufr3Z/Vd3VF6JiigLBraHf59bW9Ts/AN/GYCqEnbNhelf46jbrXOzFuVf10B6DB+P54AMAZMyYQfz991N87NhVPYYQ4uYnIV0IIYSo5bQahd7NAln69K3MGXULnRv6YlFhxd5E+k3dxLBvYvGw3Mqyfst4rf1rRLhF8GDjB23bpxWmUWoprcYzEKISjh7Q7jF4ags8shqaDwatAyTtgZ+ftbau/zwWkvZelcNpjEYCXnuNkC+movXwoHj/AY4PHETm/Pmo13jkeSHEzUNCuhBCCCEA64jw7et5M3NEW1Y924l7WgWj0yj8dSyDETO20ff//kKT254FfZbg4+hj2+6VTa/Qd3FfFsctxmQxVeMZCFEJRYGwW+Cer62t63e8A971oSQPYr+DLzvC9G6w80co+feDJLp27UqdpUtx7tAetbCQpFdfI/WTT6/CiQghagMJ6UIIIYQop1GAG1Pui+bPF7owsmMdnA1aDiXnMn7+bjp/uJ5vNhwjr9hEZlEmB9MPkpCXwGubX6Pfkn4sP7ocs8Vc3acgRMWcvKDDaBgdC8OXQ9MBoNFBQiwsfQqmNIJfJkDKwX91GL2/H6HffIPf88+jcXPDvV+/q3QCQoibnYR0IYQQQlQqyMORV/o0YfOL3XihV0N8XR1IzC7i7RUHaP/eOr5en8z3PRYzvvV4PB08OZl7kpc2vsSAZQP45fgvWFRLdZ+CEBVTFKhzG9w7E8YdgG6TwCMMirLh7y/hi3YwozfsmQ+mKxsoUdFo8H70EeqvW4tD3Tq29fmbN6OWyi0iQoiKSUgXQgghxCW5O+p5qnN9Nk7owvsDm1HX15ncIhPT1h+lx0d/cfBQK764fQFjWo3BzeDG8ezjvPDnC6w4tqK6qy7Epbn4Qadx8MxuGLIQGvUBRQsnNsGikTClMfz6KqQfvaLda11dbb8XbNvGyZGjiB8ylJKTJ6/WGQghbiIS0oUQQghRZQ46LYPbhLF27O18Paw1rcM9KTFbmLvtFH0/28bfO6N5v+1cno5+moaeDekV0cu2bUpBigyeJWo2jQYadIf7f4Sx+6DzS+AWDAXpsPkz+L9W8EM/2L8UzFfWEm7Oy0Pj4kLRnj0c7z+A7KVL5XMhhLAjIV0IIYQQl02jUbijaQALn+zAgifa06OJP6oKa/YnM3T6HtZubs6oev+HVtEBYLKYGLFqBPevuJ8/T/8poUTUfG5B0HkCjNkD98+B+j0ABY6th/89BB83hXVvQdbltYa7dulC3SWLcYqJwVJQwJkJEznz3POYc6/udHBCiBuXhHQhhBBC/CsxEV5MfyiGteNuY3BMKAathtgTmTw+awc9Pv6DedtO8k/aQVILU9mfvp+n1z3N0JVD2ZywWcK6qPm0OmjUG4YugDG7odN4cPaDvGTY8CF80hx+vBcO/QJVHDBRHxRE2Pcz8X12DGi15KxYwfH+AyjYsfMan4wQ4kYgIV0IIYQQV0V9P1feH9ScjRO68GTnergadRxNzWfCwr2MnJ7E/QFf8kDDYRi1Rvak7eHxtY/z8KqH2Zq4tbqrLkTVeIZDt9dg7D9w7/dQ53ZAhbhfYc798EkzWP8+5Jy55K4UrRafJ54g4sfZ6ENCKE1IoPjokWt/DkKIGk9CuhBCCCGuKj83IxN6NWLzxK683LsxAW5GUnOL+WxNIj/90oKe7p8yoO79GDQGdqTs4NFfH+Wf9H+qu9pCVJ3OAE37w/Bl8J8d0OE/4OgFOQmw/l34OArmDoEja8Fy8RkOHKOjqbNkMf6vvILHoEG29eolthNC3LwkpAshhBDimnA16hl1W13+fKELH93bgkh/F/KKTczelMlPv7SkneEDeoUO5NagW2nq3dS2XWpBajXWWojL5F0P7njbOo3bPd9AWAdQzXDwZ5g9EP6vJWyYAnkple5C6+KC19AhKIoCgDk7m+MD7iHnl1+u11kIIWoQCelCCCGEuKYMOg0DW4ew+tnbmPFwG9rV8cJkUVm5s5D5v7ah6PTD/HUsHVVVySzKpM/iPjy19in+SZPWdXED0Ruh+b3wyC/w1F/Q7glwcIfMeFj3BkxpAvNHwPE/4RJjMWR8/z3Fhw6RMHYcZ156GUt+/vU5ByFEjaCr7goIIYQQonZQFIUujfzo0siPXaey+PrPo/yyL4n1h9JZfyidFiHutG+eQLG5mA0JG9iQsIEuoV14KvopGnk1qu7qC1F1fo3hzveh2yT4ZxHEzoCEWOvv/ywC7wYQMwJaPABOXuU293nySQDSvvyK7EWLKNgeS/CHH+LYrNn1PhMhRDWQlnQhhBBCXHfRoR58MaQ1v4/vzNBbwnDQadh9OpsvV7rgkvYSUW5d0Sgafj/1O/cuv5dx68cRlxlX3dUW4vIYnKDlUBi1Dh7/E1qPAIMLpMfB6pfgo0aw6HE4+bdd67qi1+P7zDOEfz8TXWAgpSdOEv/Ag6RNny73qgtRC0hIF0IIIUS1ifBx5u3+zdg0sSvPdK2Pu6Oe0ynObPn7DrQJz1PPsRMKCmtOrOH+n+8nsyizuqssxJUJbAF9P4HxB6HPxxDQDMzFsGcufHcHTOsAW6dDUbZtE6c2bai7ZDGuvXqByUTqR1NImzat+s5BCHFdSEgXQgghRLXzcXFg3B0N2TyxK5P6NiHYw5GMbE927biL0pPjCNa3o0doXzyNnrZt0grTqrHGQlwhB1eIeQQe3wAjf4PooaBzhJT9sPI5a+v60tGQsAMArbs7wR9PIfCddzDUrYvXkCHVfAJCiGtNQroQQgghagxnBx0jbq3DH8935tP7o2kS6EZhvi8H9wxg/q8xPDNnJ/sSsjmYcZAe83vw6qZXOZ17urqrLcTlUxQIaQ39p1pb1+/8L/g2gtIC2DkLpneBr26H7TNRSvLxGHgPdZctRevhAWAdaHH+fCwFBdV7HkKIq04GjhNCCCFEjaPTaugXHczdLYLYeCSNr/88xoa4NJbtPsOy3WdoEPkXJq2JJUeW8PPRn+nfoD+PNXuMQJfA6q66EJfP0QPaPQ5tH4OTf0Hsd7B/CSTuguVjYPUr0Pw+lJhHICAKgOzFS0h69TUyZswk+MMP0Hp4YMq03g5iMplwSEigaP9+TDrrv/s6T0/0QUHVc35CiMsiIV0IIYQQNZaiKHRq4EunBr7sS8jm6z+PsWJvInGHb0FjDMI7ZD1F+v0sOLyAJUeWMLDBQEY1G4W/s79tH2aLmdjkWHaX7MYv2Y+2QW3RarTVeFZCVEJRILy9dek1GXb9CNtnQMYxiP3WuoS0hZgR6H2D0Pn6UnLsGMfvG2wdeM5stu0qHDj92f+d27VBT71VqySoC3EDkJAuhBBCiBtCVLA7nz3Qkud7NuTbjceZt01L6pEwtI7xuAauw+QQx7xD89hwegMr71mJVqNl7Ym1TN46meSCZADmr5uPv5M/E9tOpHt492o+IyEuwtkbbn0G2o+G+D+tresHV8DprXB6K85GD+qMGUjiqnTyNm695O7UklJMJw9KSBfiBiD3pAshhBDihhLq5cTrdzdl88SujOsRiYcmkqxjj1JwYhQU1SVEeweZBSbWnljL2PVjSc5Ptts+OT+ZsevHsvbE2mo6AyEug0YDdTvDfT/A2P3Q9VVwD4OiLHT7viUkeAneMY5V29d5I8cLIWouaUkXQgghxA3J09nAM90a8NhtdVmw/TTTNzhx4nhd1h1XuXX7Wpzrv4+KtQexHcXaM/iNTe/SJbSLdH0XNw5Xf7jtOeg4Fo7+BrHfoRxehavXSdLxre7aCSGuEmlJF0IIIcQNzajXMvSWcH4b35kvhrSmRYgnJsNRSpXM8gH9LEWBrNJUtiVtv76VFeJq0GihQQ94YA48uxca9a3uGgkhrqIaEdKnTp1KREQERqORdu3asXVr5ffVLFq0iJiYGDw8PHB2diY6OppZs2Zdx9oKIYQQoibSahR6NwtkydO3ck8btypt89eJ49e4VkJcY+4h0OTuKhXN2/Q3lpKSa1whIcS/Ve0hfd68eYwbN45JkyaxY8cOWrRoQc+ePUlJSamwvJeXFy+//DJbtmxhz549jBgxghEjRrB69errXHMhhBBC1ESKohDk6lelsn8cKOLnPWdIzim6xrUSovqlzVrKkfYxpL72DKWJp6u7OkKISlT7PelTpkxh1KhRjBgxAoAvv/ySFStW8N133zFx4sRy5Tt37mz3eMyYMXz//fds3LiRnj17litfXFxMcXGx7XFOTg4ApaWllJaWXsUzETeDsmtCrg1RG8j1Lm5mrX2j+eagO4ouu8Iu76oKqtmZnXFejD68E0WXg1vETOoZu3BH2J10qhtKfV8XNJpK+ssLUYOYzpt67WK0DmbM+ZD2vzWkzf+V4GHNcRr0GGp4R2sXeiFuQDfK/zOXU79qDeklJSVs376dF1980bZOo9HQvXt3tmzZcsntVVXlt99+49ChQ7z//vsVlnnvvfd44403yq3/9ddfcXJyuvLKi5vamjVrqrsKQlw3cr2Lm5FFBV16H8z+P6Kq9oPHqerZnyn96egPx3NVUh23Y9GfIc78I4ePzuOTXVEoOW2I0EVQ1xXquqmEOYNBcoyogTwTD+KnUVEtlX+ppGhU8h/qjsupo2i3H6ckQ8E571e0P62mSOdOgi6ahKCOZLpFVjDaohA1X03/f6agoKDKZas1pKelpWE2m/H397db7+/vz8GDByvdLjs7m+DgYIqLi9FqtXzxxRf06NGjwrIvvvgi48aNsz3OyckhNDSUO+64Aze3qt2vJmqP0tJS1qxZQ48ePdDr9dVdHSGuKbnexc1OH9GaZ1coOPgvR9Gfm3pKNblTnNyXT+4aQs+m1v9BEnPbMWNPA35L+JkMUzx6913gvouTxT4cyWpLaUJb9IojTYPcaB3mQeswT1qFe+DtbKimsxPiPNnNUeM/x1xgqrSI1kmHMvx56z3sFjOmnSsh+XfUg8sxFmai+eUfAgsO0jhKh1v/Pmja3g/+URLYRY13o/w/U9ajuyqqvbv7lXB1dWXXrl3k5eWxbt06xo0bR926dct1hQdwcHDAwcGh3Hq9Xl+j30RRveT6ELWJXO/iZtUnOgSd7iFeX96K1NIDKLpcVJMrvvrGfNQvil5RgbayYV6+TOr8OK+pj7E/fT/zDs3nl+MrKXJIw8l/DXrTraTlqOw6lc2uU9l8u+kEAHV9nGkd7kmbCC9aR3hS18cZRUKNuN586sDEbVCQDkCpycSmTZu49dZb0evO/rvv5A0eoWc30KO/5R7gHrjrI0zbl1G64k3MhaWkbVNJ374Mt/B5eLX1xtjlPogaBD71q+XUhKiqmv7/zOXUrVpDuo+PD1qtluTkZLv1ycnJBAQEVLqdRqOhfn3rH4ro6GgOHDjAe++9V2FIF0IIIUTt1SsqkB5NAthypDm/bvibOzq1o319P7SV3GuuKApNfZrypk9TJrR9nl+O/0J6YTqPPdSXUxmFxJ7I4KsDb5Kb40vi6WYcS4NjafnM324dhMvb2UCrcE/aRHjSOtyLZsHuGHTVPk6vqA08Qs+F8NJSsp0SILAFXCoY6Azo2g2iwaa7yVmxjIxvv6LoyGmyjzuRfbwQp9++xqfZRzi3aAxRA6HpPeeFfSHEtVCtId1gMNC6dWvWrVtH//79AbBYLKxbt47Ro0dXeT8Wi8VucDghhBBCiDJajUK7Ol6kH1BpV8er0oB+IWe9M4MiB9keh3k7Uaic4szeLeAE7g1X0NSjPT7qbZxJDGP36RzS80tYsz+ZNfutDRAOOg0tQj2IOdva3irME3enmtvSI2ovxWDAfcAg3PoPpGj3bjJmfkfOmnUUpDpgLimExN3WZc1rEHoLNBsETfqDi291V12Im061d3cfN24cw4cPJyYmhrZt2/LJJ5+Qn59vG+39oYceIjg4mPfeew+wDgQXExNDvXr1KC4uZuXKlcyaNYtp06ZV52kIIYQQohYIcwvjrVvfYuHhhexK3cWezI3ARoJ8ghjTrj+NnLtzJFFD7IlMYuMzyCwoZevxDLYezwCOAtDQ35XWEZ624B7i6Shd5EWNoSgKjtHRBH/yGX7JyWQvWYrr/f3g8M+wbxHpq3dRsu0AnnsnYvR8Aercbg3sjfqAo0d1V1+Im0K1h/TBgweTmprKa6+9RlJSEtHR0axatco2mNzJkyfRaM51E8vPz+epp57i9OnTODo60qhRI2bPns3gwYOr6xSEEEIIUUs46hzpX78//ev350jmERbGLWTZ0WWcyT/Dl3u+4OPODXj89u48jnUWmmNp+cTGZxAbn0nsiUyOp+VzKDmXQ8m5/PT3SQD8XB1oE+FFTIQnMeFeNA50RaeVLvKi+un9/fF5/DHrgzaPokY/RMZ3XTClppN11Bkn/2K8IjfjcuR3FP1YqN8Dmg2EyDvBILMoCXGlFFUtm4ikdsjJycHd3Z3s7GwZ3V2UU1paysqVK+ndu3eNHnhCiKtBrndRm1zL673YXMyaE2tYE7+GDzt/iF5j3f+cg3NIL0znngb3EOQSBEBqbjHbT2Sy/UQG2+Iz2ZeQjcli/6+Yk0FLyzAPYsKtwb1lmCcuDtXeriJuINfqeldVlcLYWDJmzSZ37VqwWADQuyl41cvCvU4BWoMKemdoeKe1hb1eN9DJLAji2rlR/p+5nBwqf/GFEEIIIf4FB60Dfer2oU/dPrZ1ZouZGftmkJifyNd7vqZDcAcGNRjE7aG30ysqgF5R1gFyC0vM7D6dxfYTmWyLz2D7iUxyi0xsOpLOpiPWkbo1CjQOdLOOIB/uSUyEJ4HujtVyrqJ2UxQFpzZtcGrThtKEBDLnzCFz/gJKs7NJ3ulOsWNLApufgqwTsG+BdTG6Q+O7rYE9ohNotNV9GkLUeBLShRBCCCGuMhWVca3HsSBuAX8n/s2mhE1sStiEt9Gb/vX7M7DBQELdQnE0aLmlrje31PUGwGJROZySa+0eH59B7IlMTmcW8s+ZHP45k8PMzfEABHs4WkeQj/CiTYQnkX6uaKo4IJ4QV4M+OBi/557D56mnyF62nIzZs/B87r/QuDEkbKd43UxKd6zB2SMJZecs2DkLnP2g6QBrYA9pI3OwC1EJCelCCCGEEFeZTqOjV51e9KrTi5M5J1kUt4glR5aQXpTOt/u+JaMogzdvfbPcdhqNQqMANxoFuDH0lnAAkrKLiD1Rdl97BvvP5JCQVUjCrkKW7DoDgKtRZ21lD/ckJsKLFiEeOBqkxVJcexonJzzvH4zH4PvODYAYEkP64cVkr9ZgCGmJZ4wnHi470eSnwNavrIt7GETdYw3s/lES2IU4j4R0IYQQQohrKMwtjGdbP8vTLZ/mj1N/sCBugd3UbgczDrLi2AoGNhhIhHtEue0D3I30aR5En+bW+9rzik3sOpll6x6/46S1i/z6Q6msP5QKgE6jEBXsbgvtMRGe+Lg4XJfzFbXThTMU6Ly80Dg7U3I6meTTyaS6+uHR9U48G+RhSPkNsk/Cpk+si08kRA2yzsPuU79a6i9ETSIhXQghhBDiOtBr9HQP70738O526+cdmseCwwuY+c9MYvxjGBQ5iO7h3XHQVhyqXRx0dGzgQ8cGPgCYzBYOJuWy7Wz3+Nj4DJJzitl1Kotdp7L4ZuNxAOr4ONM63NPaTT7ci3q+zjL1m7hm/MaPx/vxJ8hevJjM2bMpOXGCjKXryVAUPAaNIPD+1rBvIRz+FdIOw/p3rUtgi7OB/R5wD6nu0xCiWkhIF0IIIYSoRt3CupFakMqGhA3EJscSmxyL+1Z3+tbty8AGA6nvefGWRZ1WQ1SwO1HB7oy4tQ6qqnI6s/BcF/n4TA6n5HI8LZ/jafks2H4aAC9nA63CrKE9JsKTqGB3HHTSRV5cPVoXZ7yGDcVzyIPkb9hAxg+zyN+0CV1gkPXe9KYDUPMzUP/5Gc3hpXD0d0jcbV3WvAph7a2t6036g4tvdZ+OENeNhHQhhBBCiGrUMbgjHYM7kpSfxOIji1kUt4ik/CRmH5jNryd+5deBv6K9jBGxFUUh1MuJUC8nBrS0tkRmF5Sy46T1nvZt8ZnsPpVFRn4Jaw8ks/ZAMgAGnYYWIe7W7vHhnrQO98TDSabOEv+eotHgcvvtuNx+O8VHj6L18rI9l7dlB4kvf4HHfffhOfRN9Bl/WVvYT2yCk1usyy8ToO7t1sDeqA84elTfyQhxHUhIF0IIIYSoAQKcA3iyxZM81uwxNp/ZzILDC2jk3cgW0E0WE5/t/Iy76txFQ6+Gl7Vvdyc9XRr50aWRHwAlJgv7zmSzPf7c1G/p+SVsi89kW3ymbbsGfi620N4mwotQL8cqd5E3W1S2Hs8gJbcIP1cjbet4oZUR6Gs9h3r17B7nrFqNOTub9OnTSf/uO1x79MDrobdxHOCHsn+JdRq3Mzvh6G/W5eex0OAOa3f4yDvB4FQ9JyLENSQhXQghhBCiBtFqtHQK6USnkE6oqmpbv+H0Bmbsm8GMfTOI8o5iYORA7qxzJ85658s+hkGnoVWYJ63CPBl1W11UVeV4Wr7tnvbYE5kcS80nLiWPuJQ85mw9CYCvq4PtnvY2EZ40CXRDp9WU2/+qfYm8sXw/idlFtnWB7kYm9W1Cr6jAK3hVxM0q6P3JuPXqScas2RT8/Te5q1aRu2oVxiZN8HxoGO4jf0PJPA77FlkDe+pBOPizddE7Q6Pe1hb2et1AJz0/xM1BQroQQgghRA11fqu1v7M/PSN6su7kOval72Pfln18sO0D7qxzJ/dG3ksT7yZXPBCcoijU9XWhrq8L98WEApCeV8z2E5m24L43IZvU3GJW7k1i5d4kABz1WlqGedhGkW8Z5sGmI2k8OXsH6gXHSMou4snZO5g2tJUEdWGjaLW4du+Oa/fuFB06RMasWeQs/5mi/fvJ/PEn3Pv1A+96cPvzcNtzkLIf9i6wdonPOgF751sXowc0udsa2CM6wWXcIiJETSMhXQghhBDiBtDEuwkf3v4h6YXpLDu6jIVxCzmRc4KFcQtZGLeQRXcvooFng6t2PG8XB+5oGsAdTQMAKCo1s+d0tq17fGx8BjlFJjYfTWfz0XQAFECrUcoFdAD17PNvLN9PjyYB0vVdlGNs2JCgt9/Gb/x4sv43H4f69WxfPJlzckh+9z08H3wAx+6ToNtrkLDdGtj/WQR5ybDjB+vi7GcdmK7ZIAhpI3OwixuOhHQhhBBCiBuIt6M3I6JG8HDTh4lNjmXB4QWcyTtjF9AXxy2mrkddmvs0v2rTrBn1WtrW8aJtHeugXxaLypHUPGtoj89k24kMTmUUYrJUFNGtVCAxu4j1h1Lo1tj/qtRL3Hx0np74PP6Y3bqshYvIXrKE7CVLcGzRAs9hw3DreQdKSAz0fMc60NzeBbB/KeSnwNavrIt7mPX+9WaDwD9KAru4IUhIF0IIIYS4ASmKQpuANrQJaINFtdjW55bk8t7W9yg0FVLfoz6DIgfRp24f3B3cr+rxNRqFSH9XIv1dGdIuHIAftsTz2tJ/Lrnto9/HEuBmpIG/C5H+rjTwc6GBvysN/F1wM+qvaj3FzcG5/S249+tHzsqVFO7eTeHu3aT81w/PBx/A47770NW5DercBr0/hGO/WwP7wRWQfRI2fWJdfCKtc7A3G2TtQi9EDSUhXQghhBDiBqdRzg3eVlBaQI/wHqyOX82RrCNM3jqZj7d/zB3hdzAwciCt/Fpdtdb1CzXwc61y2aScIpJyitgQl2a3viy8N/BzJdLfxfq7v6uE91rO2KgRQe9Pxu/558icN4/MuXMxpaSQ+smnpH89nfp//oHWxcU6eFxkT+tSUgBxq633rx/+FdIOw/p3rUtgC2tgj7oH3EOq+/SEsCMhXQghhBDiJuLv7M87Hd/hhTYvsOLYChbELSAuM47lx5az/NhyJradyJDGQ67JsdvW8SLQ3UhSdlGF96UrQIC7kRXPdOJ4Wj5xybkcTs4jLiWXuOQ8W3C/VHi3tsC7UN/PFXdHCe+1ic7HB9+nn8Zn1ChyVq8m44dZGEJDrAH9rILYWByjo1EMTtZ705sOgKJsa8v6voVw9HdI3G1d1rwKYe2tA841HQDOPtV4dkJYSUgXQgghhLgJuTu482DjB3mg0QPsTdvLwriF/Br/K93CutnK7E7dTZGpiDYBbexa46+UVqMwqW8Tnpy9AwXsgnpZ2/2kvk3wcjbg5Wygdbin3fY5RaXEJecRl5xLXEoeh5NzOZKSR2J25eHd382BSH9X6vvZd52X8H5zUwwG3Pv2xa1PH9Sic1P9FR87zomhw9AFBeL14IN4DBqE1sMDjO4Q/aB1yU+D/Uus07qd2AQnt1iXXyZA3dutLeyN7gJHj+o6PVHLSUgXQgghhLiJKYpCc9/mNPdtzkvtXsJB62B7btquaWw6s4lQ11AGNhhIv/r98HH8dy2JvaICmTa0Vbl50gOqME+6m1FP63DPSsP7kZSylndrkE/MLiI5p5jknOIKw3tZq7ut67yfK+5OEt5vJoqioDg62h6XxMej9fDAdCaRlA8/IvXzqbjffTdew4bi0ODs4IrOPtBmpHXJTrCODr9vIZzZCUd/sy4/G6DBHdYW9sheYHCqpjMUtZGEdCGEEEKIWuL8gG5RLYS4huCsd+ZU7ik+2fEJn+/8nC5hXRjYYCDtg9pfcet6r6hAejQJYOvxDFJyi/BzNdK2jtcVT7t2sfB+5Gxgj0vO43AF4X3jEfvw7ud6Qcu7vwuREt5vGq5du+C8/ndyVqwg44dZFB86RNb//kfW//6HU/tbCHr7bfTBwec2cA+GDv+xLulHrWF97wJIOwQHf7Yuemdo1Nvawl6vq/W+9zJZp6AgvfIKOXmDR+i1O2FxU5KQLoQQQghRC2kUDa/c8grjWo9jdfxqFsQtYE/qHtacWMOaE2voHtadj7t8fMX712oU2tfzvoo1Ls/NqKdVmCetwuzDe25RKXEpeRxJtnaZP5ySx5HkXM5kF5GSW0xKbsXh3f6ed1cJ7zcojdGIx8CBuN9zDwXbtpE5aza569ZRvP8AWu9z16SqqvaDKHrXg9tfgNueh+R/rIF93wLIOgl751sXowc0udvawu5ZB6a2AVNx5ZXROcDo7RLUxWWRkC6EEEIIUYs56Z0Y0GAAAxoM4HDmYRYeXsjyY8u5LeQ2W5ns4mx2p+7m1qBb0Wq01VjbqnG9SHi3trxbw3tZt/nzw/umI/ator6uDrau8udPGefhZEDUbIqi4Ny2Lc5t21JyOoGSY0fRGI0AqBYL8YPvt865PuRBHOrUOX9DCIiyLt1eg9Ox1sD+zyLIS4YdP1gXR6+LB3SwPl+QLiFdXBYJ6UIIIYQQAoBIz0hebPciY1uPtWth/PnYz0zeOpkA5wAG1B/AgPoDCHSp/N7ymsrVqKdlmCctLxLe487e934kJY+ErEJSc4tJrSS8Nzivy3zZfe8S3msmQ0gwhpBz3dwLtm6jaO9eivbuJXP2bJxvvw2vocNwvrUDiua82zwUBULbWJee70D8Rmtg378UCjOq4UxEbSAhXQghhBBC2DHqjHaPLaoFdwd3kvKTmLZ7Gl/u/pKOwR0ZGDmQ20JuQ68p3yXcbDGzI2UHqQWp+Dr50sqvVY1tha8svOcVm2wjzZ/7aR/eNx+1D+8+LmUt79ZR5sta3j2dJbzXJE7t2hL23bdkzJpN3vr15P/xJ/l//Imhbl08hw7Bo18/NM7O9htptNbR3+veDr0/hNhvYdXESx/s5BZw9gW3IGvoF+ISJKQLIYQQQoiLGtZkGPc1vI91J9axMG4hW5O2siFhAxsSNhDoHMjPA37GoD0XQteeWMvkrZNJLki2rfN38mdi24l0D+9eHadwRVwcdJWG9yPnTRF3+OzAdQlZhaTlFZOWV3F4t7a8W8N7WSu8hPfqoSgKzh064NyhAyUnTpDx449kL1xEybFjJL/5Fg516+J8yy2V70BnsM6vXhWrJloXR0/wj4KAZmd/RoFvI+t960KcR0K6EEIIIYS4JAetA73r9qZ33d6cyDnBwriFLD2ylKbeTe0C+he7vuDL3V+i2s2SDikFKYxbP44pnafcUEG9Ii4OOqJDPYgO9bBbXxbez299P3xBeN9y7MLwbrB1la/v70rk2RZ4rysM72aLyt/HM9iepuB9PIP29f2ueFT92sIQHk7ASy/h+8wYspcsIf+vLTi1a2d7PmvJEvQBATi1a2c/0FxVeURA9ikozIT4DdaljEYHPpHnQntZiHfx+/cnJm5YEtKFEEIIIcRlCXcLZ1zrcfwn+j9kl2Tb1h/LPsa03dMq3EZFRUHh/a3v0yW0S43t+v5vXCy8H72g5f1ceC8hLS+90vDe4IKW94uF91X7Es+bn17LD3GxBFZhfnphpXVxxmvoELyGDrGts+Tnk/zOu1hyc3GIjMRz2FDc+/RBc3Zu9tJ8Labiyqcq1DlY0D/2vbXFPPUgJO+DpH1nf+6FoixI2W9d9v7v3IbOfvah3T8KfBqAVmYbqA0kpAshhBBCiCui1+rxcfSxPV5/cv1Fy6uoJBUksSNlB046J7YkbsFR54iTzglH/dmfOkccdY5EuEXgYnABrPfEKyhX1opZA7g46GgR6kGLC8J7flnLu63V3doCfzqz8vDu7WywG2W+LMBvi8/gydk7ULGgdTqOostFNbmSlF2HJ2fvYNrQVhLUr4ClpAS3PneRvWQpxYcPk/Tqa6R++BEe992HS4tQTq7wQ7VUfl0qGpV6D6ahDzJCULR1KaOqkJNwNrTvPRfe049Cfgoc/c26lNEarGH//O7y/lHg5HXNzl9UDwnpQgghhBDiqghwDqhSudSCVNIK0/h0x6eVlvmy+5fcGnwrAIvjFvPWX2/ZBfqyMO+kc+KJFk8Q7RcNwKGMQ6w7uc72vKPOESf9ufBfz70eHkYPAEwWEwA6TfX8S+x8kfB+NDWPw8nnus4fTs7ldGYh6fklpB/L4K9j9iOLaxTQuu7DwX85Gv253g2WUneKk/syaZkDt0f64Wi4+XowXEs6T08CJ03Cb+xYshYsJPPHHylNSCB9+nTSNQpcJKADqBYFU7GGCtu/FQXcQ6xLw17n1pfkQ8oBa0u7reX9HyjJhaQ91uV8bsHnhfam4N/MOuf7TdhbpbaQkC6EEEIIIa4KXyffKpdzc3Cjf/3+FJoKKSgtoNBUaFsKTAW4Glxt5QtNhZhVM3mleeSV5kGh/f6GND7XPXl/+v5Ku9wDfHD7B/SKsAai307+xvg/xmPQGMoFf0edIyObjbR9UXAs6xhLjy6tMPg76Zyo51EPPyfrfcSlllJKzaUYdUY0SuVdoSvj7KCjeYgHzUM87NYXlJQNWGedKq5syrhTGYVoXPZhDJ5dbl+KLhtj8GzSE6Dxa8UYtBpcjDqcHbQ4G3S4OOhwdij7qcXFQY+LgxZnu/XWn+fKWNc5GbQ3bO+Gy6V1c8P7kRF4DX+IvN9/J+OHWRRs21a1jV39L+9gBmcIibEuZSwWyDpRvrt81glra3xOAsStPlde5wh+jc8G92bnArzR/fLqIqqFhHQhhBBCCHFVtPJrhb+TPykFKeUGjgNQUPB38rdNx9YxuGOV9jsochA9wnvYhfjzQ31Dr4a2shHuEQxuOLjC4F9oKsTDwcNWtsBUAECJpYSS4hKyi7Ptjntv5L22349lH+O7fd9VWsfX2r9mK78taRuPr3kcAKPWWC7UP9T0IdsXBadyT/HTgZ8qDP6OOkfqedQjxDUEAL1OJdRHJTLABwdtsC0gz9sWz5u737O+xhdkZkWx9qp28F+OKbcJJWbIyC8hI79KL/1FKQrnBf1z4d0+1OuqHPr12sv/QuN6U7RaXLt3x7V7d3J/X8/pJ5+85DY5q1ZhTk/H5bbbrvzAGg141bEujfueW1+UY21lLwvtyfsgeT+YCuHMDutyPo+w80L72dZ3jwjr/kWNISFdCCGEEEJcFVqNloltJzJu/TgUFLugrmBNjxPaTrjsQeOMOmO5udsr09KvJS39Wlap7F1176JzSOcKw3yBqYAWPi1sZUNcQxjaeGiFZQtNhfgYz92bX2g619RfZC6iyFxEZnGmbV1OcY7t94S8BGYfKN8CXmZc63GMiBoBwMH0gzy48kEANIrGFuhLTapdF/cLKQoo+mxG3ZlB/0Y90FicKSixkF9sIr/YRN55P/OKzfbrS6zr8opKyT/7XF6JCVW1hv+8s+WuBoNOU3m4N+jO9gA4t97FQYezwbrO1Vj2BYE19Dvqr30rv86vaj1HMqZ/Q86KFTT47dz95QnPv4A5PR1dUCD6gED0gYHoAwPQBVp/1xirdr1jdIPw9taljMUMGcfOhvZ/zrW+55yGrJPW5dCKc+UNruDf5Lwu882sjw3O5Y8nrgsJ6UIIIYQQ4qrpHt6dKZ2nVDhP+oS2E2rU9Gt6jR4PowceeFyybCOvRjRq26hK++0a2pWtQ7ZW3JpfWkikV6StbIBTAI9GPVpx+C8ttLvPv8hcZPvdolrIL80nv7TqTeJz4z9kbvyHaBUtj7d4nCdbWFuBM4symbFvBt4e3kQ4euNt9Mb77E8PB49yX6qoqkphqflsuDeTV3Qu6FtD/dmQX3Qu9OeVmM4L/2byiq2hP6/YRInJAkCJyUKGqYSM/JIqn1NlNGdb+Z0dLgj353fxN5YFfa1dK//5od/FYA3+un/Ryu/Ypg2G8DC7dQWxsZgSEyssrwsKtAv06TNmgtlkC/D6wEB0vr4oukqinEZrHQnepwFE3XPeQTPsQ3vyXkg5aL3X/dTf1sVGAa+6F3SXj7LeP19LbnGoThLShRBCCCHEVdU9vDtdQruwI2UHqQWp+Dr52rq41waKothauS8lwj2CZ1s/W6X9tglow65hu8oF+h3JO3hv63uX3N5Z70x+aT5m1YyTzsm2PiEvgRn/zKhwG42i4YkWT9gCfUZRhjXQlwV5R2+8nbxp4O2Np4PPFb3HpWbLeS3554L8+a38+cUmcm2/m+3Wn9vOTP7ZVn6LCrlntyHn0nW4FIezrfznd9Wvk3GSh6uwre+ECThHNbVbFzR5MqUJCZQmJWJKTKQ0MYnSxERKExPRBwbZlc344YfygV6rRefnh2Pz5oR8+oltdcG2bShOTuiDgtB6eNj3JnDygjqdrEsZcymkHyk/wnxeMmQctS77l54rb/S4YE73KPBtDPoqtvxfZWaLmdjkWHaX7MYv2Y+2QW1vir8zEtKFEEIIIcRVp9VoaRPQprqrcdPRarS4GFxs09MBNPBowHf7vrPruXChAKcAVg1chQULGYUZdrcPuBvcGdZkGOmF6dalyPozszgTi2qxD/S5Ccz8Z2aFx7gw0KcXplsDvaM3Po4+dsHe08HTFqb0Wg0eTgY8nCqfA76qLBZrK//54d0W4KsQ+vPsypgpMVtb+YtNFopNJaSf18qfnpVVpZA+8vttGBrnE+zpSLCHI0EeRoL96hMUGUWAm9GulV5VVdTiYrvt3fv3o/R0wtkwn0hpcjKYTJgSEzEF2k+rl/D8C5iSkgBQjEb0AQHoAgPQBwZhbNQQr4ceOvdalZSgMRisA8z5NQbOjcFAXqp9aE/aB2mHrPO6n9hoXcooZ1vuz+8uHxAFLv7XtNV97Ym1dj125q+bj7+TPxPbTqxRPXauhIR0IYQQQgghbmDnjwUAXHQsAC1a/J3tRxsPdQvlhTYvlNuvyWIisygTg/ZcePZw8OChJg+RVphmC/MZRRlkFlUQ6PMS+H7/9xXWWUHhyegn7QL9d/u+s4b5C7rcexo9qzxNnkaj2Lqs+1Vpi4srMVns788vOhf6d8Y6UvKnDoOl8nvySzQ6jhTrSD2cWnF9FQhwMxLk4UiwpyNBHtYl5OzPYE9H/MaMsdtGNZsxpaVjSkq0DgxQtl5V0fv7o5pMmNPSUIuKKImPpyQ+3lqXVq3sQvrRO3piKSy0dqEPCEAfFIju7P3xhohwHJt1hXpdzx3YVAyph+y7yyftg8IMSD1oXfYtOFfeyee8Fvezc7v7RILu338Zs/bEWsatH1dugMqUghTGrR/HlM5TbuigLiFdCCGEEEKIG9y1GAtAp9GVm1Yv1C2U59s8X65sWaB30DnY1nk6eDK8yXDSitLsW+iLMlFRcdGf6w2QkJfAD/t/qLAeCgpPRT/FEy2eACCtMO1coD8vzHs7euNl9Lqq894bdBoMOgOezuWDpZezgZG7JuBWkg9Y0BrPoGjzUc3OmIuCAA05BmdGDWqPu6OehKwiEjILOZNVyJls689Ss8qZ7CLOZBcReyKz3DEA3Iw6a3A/G+KDPcrCfBghno44WFQ0GgVFUYiYNxewtpKbkpLOdqM/gykpCa23t22fqsmEKSUFLBaKs7MpPnjQ7piOrVsT8eO5AQ1PPfU0isFwLswHdkHf6kH0gQFo9cUoyf/Yt7ynH4GCNDi23rqU0ejBt5F9d3n/ZuDsTVWZLWYm//VOhTNIqKgowPt/v0OX0C43bNd3CelCCCGEEELcBMrGAth6ZitrtqyhR/se1+0e3coC/XNtnitX1mQxkVWcZddC7+ngycNNH7a20FfQ5f78QH869zSz9s+qsB4KCk9HP83jLaxT4KUVpvHt3m/tW+fLfjd6o9fqr/ic29bxQhcYyAlLLA7+y+1G2LeUulOc3BdfTX0e7VgXraZ8t2+LRSUtr5jTWWeDe1YhCZmFJGQVWX/PKiS7sJScIhM5SbkcTMqtsB56rUKgu7Ub/fmt8EEejgTXbUJQy9Z4GOyvAUWnI/LvvyhNTLQP84lJlCYlYWzc2FZWNZnIW7/eOld7BZzatiX8h+8h8g4A0qZPR9vAEb2xBJ0mA73lNNqsQ6jJ/5BmyqUkfT8lGQco2b+AUkWhRFEocfbG1bMeTQNjbC3vizP3UWguptRSSom5xDpVormEUxmHMCWnUqewwuoAkOOYyo5jq2hT/67KC9VgEtKFEEIIIYS4SWg1WmL8Y0gxpBDjH1MjWxJ1Gh0+jj5260LdQhkfM75cWbPFTGZxJg7acy30XkYvHm76sF2YTy+ydru3qBa7+/VP556+6BR3o6NH2wJ9akEq3+37rlx3+7KfFwZ6rUbhno4ZfH+0/P4VXTbG4NncU6/igA7Wrvl+bkb83Iy0CvOssExesckW2MtCvDXQF5GQVUhSThGlZpWTGQWczMgHzKAxoygmVFULFuvYA17OGny80vF21eDlosHDWYOHk4Kro4KLt0KThvVp5X8fYJ1C8Nu931KyfQql5lJKi4vwe6IdDum5GNPzCCkwEpRvwJSYhCk1lb9KDzFmSX9KLaWYSouZMiUBzQWN3BoXF/SB0cz3OsrsrufuwY88rZLlBBnO0C7vIF9u3GB7bnJ4CAUVzN/una3y6VdmDOYKXzIASrSQ1PAfkJAuhBBCCCGEEFePVqMtF+jD3MIqDfQXttB7Gb0Y0XSEXZgvu4/erJrtA31e1QN9SkEK3+z9huWnllc4NlrZul+TvubRwm5sT9lubQ02l1BqKT3XOmwuobV/a2ICYgBIyk/i852fU2IpwWQx2cqUWEooNZfSp14fXmj0AACnck8xZMUQis0llJhLMan2U9c5FXUmL+Eu8kvMZBZnUeryPokqkHt2Of+1y25DQMlDBHk44ueusqbgK/sC7meXutArohcf3P4BAKbiIobPjKEw+ygADiUqa6IVfHLBO0clIE+HscCEJS+P4rg4fKJ0GLVG9Fo9RlXPm7NTbIG+0MWR456NrS3w2ixGZBUT18CCATCoKnqLih4VspwuGtABDGbwKb5xo+6NW3MhhBBCCCGEOEur0eLtaH9vc5hbGONixpUra1Et1kCvORfovY3ePBL1iH0L/dlAb1JNuBpcbWVP555mzsE5l6xTUkESa06s4e2/3660zJMtnrSF9LySPJYeXVpp2ZZ+Lc+dr6Ils7ji+9gB+rbw5+XHepJTaOJQajLPbfYHVYdq0WK2aCk1KZSYNJSUajAV+XEsI59jafmACQf/9qBqUVUdqFpQdTgbjHg4OpJwKpR3Vx6w3Rs/pv1HBLq54OHoiIPWAf0gPQaNAYPWgLPeGVeTjtKzXeofdHfj0WbNADBlZHDi+wcpTUpCLS7GMc9EUV42RQA40Df0doK73AlJ+1AT93Lovd3oHExo9CUUc+nB5xq5hl+yTE0lIV0IIYQQQghRq2gUDV5GL7t1YW5hjG09tlxZi2ohpzjHrru7j6MPnUM6s/70+kseq8hcRCu/Vui1evSacwHWoDWg1+hp7HXu/m9fJ1/GtBpTroxBa8CgMRDudi54+jr6sujuRbbn9Npz5fQave1WB3cnPW3DQ/gzfG2F9SsxWUjKtnafT7DdH1/n3OPsQopKLZQAmcBxYDPHLthLFs6GXLsR6oM9HAn2UK3rvIPwj6hjN92czsuLeqtXoaoq5szMc/fHn0mkNCkRY+Mm0OQuaNIP05kzqG91o9RU9fiqUcp3lb9RSEgXQgghhBBCiEpoFA0eRg+7dWFuYTzU9KEqhfQm3k0Y3nR4lY7l7uDOyGYjq1RWr9XTwLNBlcpejEGnIczbiTBvpwqfV1WVjPySs/fBF5wb2C7TGuATMgtJzy8hv8TM4eQ8DifnVbgfrUY5O92c8bwR6h3PzR9fvyGuTZtWuK3O35/6v62jNCmJ/LVLSfvuf//6vGsyCelCCCGEEEIIcZla+bXC38mflIKUCqcDU1Dwd/KnlV+raqjd1aMoCt4uDni7ONAsxL3CMkWl5nID3J0/Sn1itnW6ubLW+W1U3E3f3VF/Xiu8/fzxIR5e+EQHouSckJAuhBBCCCGEEMKeVqNlYtuJjFs/DgXFLqgrWEeOm9B2Qo0cYf9qM+q11PV1oa6vS4XPXzjdXNko9QlnR6k/c3a6ubLlQGJOhfvRaxUGFf/DQ1Wok0Ut/8XJjUJCuhBCCCGEEEJcge7h3ZnSeQqTt04muSDZtt7fyZ8JbSfQPbx7Ndau5rjc6ebOTTVX1jpfZJtu7nhe1ea2P5St4UbtwyAhXQghhBBCCCGuUPfw7nQJ7cKOlB2kFqTi6+RLK79WtaIF/WpycdAR6e9KpL9rhc+bzBaSc4tZttqDkj9nYbBUPg9biUZLokvYtarqNSchXQghhBBCCCH+Ba1GS5uANtVdjZuaTqsh2MOR6JhGjOw+EbeS/ErL5hic+ayOTMEmhBBCCCGEEEJcU23reKELDORYdlEFw/WBAgS4G2lbx6uCZ28MN+7kcUIIIYQQQgghahWtRmFS3yYAZ4fnO6fs8aS+TdBqLnz2xiEhXQghhBBCCCHEDaNXVCDThrYiwN1otz7A3ci0oa3oFRVYTTW7OqS7uxBCCCGEEEKIG0qvqEB6NAlgy5EUft3wN3d0akf7+n43dAt6GQnpQgghhBBCCCFuOFqNQrs6XqQfUGlXx+umCOgg3d2FEEIIIYQQQogaQ0K6EEIIIYQQQghRQ0hIF0IIIYQQQgghaggJ6UIIIYQQQgghRA0hIV0IIYQQQgghhKghJKQLIYQQQgghhBA1hIR0IYQQQgghhBCihpCQLoQQQgghhBBC1BAS0oUQQgghhBBCiBpCQroQQgghhBBCCFFDSEgXQgghhBBCCCFqCAnpQgghhBBCCCFEDSEhXQghhBBCCCGEqCEkpAshhBBCCCGEEDWEhHQhhBBCCCGEEKKGkJAuhBBCCCGEEELUEBLShRBCCCGEEEKIGkJCuhBCCCGEEEIIUUNISBdCCCGEEEIIIWoICelCCCGEEEIIIUQNoavuClxvqqoCkJOTU801ETVRaWkpBQUF5OTkoNfrq7s6QlxTcr2L2kSud1GbyPUuapMb5Xovy59lefRial1Iz83NBSA0NLSaayKEEEIIIYQQojbJzc3F3d39omUUtSpR/iZisVg4c+YMrq6uKIpS3dURNUxOTg6hoaGcOnUKNze36q6OENeUXO+iNpHrXdQmcr2L2uRGud5VVSU3N5egoCA0movfdV7rWtI1Gg0hISHVXQ1Rw7m5udXoD7kQV5Nc76I2ketd1CZyvYva5Ea43i/Vgl5GBo4TQgghhBBCCCFqCAnpQgghhBBCCCFEDSEhXYjzODg4MGnSJBwcHKq7KkJcc3K9i9pErndRm8j1LmqTm/F6r3UDxwkhhBBCCCGEEDWVtKQLIYQQQgghhBA1hIR0IYQQQgghhBCihpCQLoQQQgghhBBC1BAS0oUQQgghhBBCiBpCQrqodaZOnUpERARGo5F27dqxdevWSstOnz6dTp064enpiaenJ927d79oeSFqmsu53s83d+5cFEWhf//+17aCQlxFl3u9Z2Vl8fTTTxMYGIiDgwORkZGsXLnyOtVWiH/ncq/3Tz75hIYNG+Lo6EhoaChjx46lqKjoOtVWiCv3559/0rdvX4KCglAUhSVLllxym/Xr19OqVSscHByoX78+M2fOvOb1vJokpItaZd68eYwbN45JkyaxY8cOWrRoQc+ePUlJSamw/Pr163nggQf4/fff2bJlC6Ghodxxxx0kJCRc55oLcfku93ovEx8fz3PPPUenTp2uU02F+Pcu93ovKSmhR48exMfHs2DBAg4dOsT06dMJDg6+zjUX4vJd7vX+008/MXHiRCZNmsSBAwf49ttvmTdvHi+99NJ1rrkQly8/P58WLVowderUKpU/fvw4d911F126dGHXrl08++yzjBw5ktWrV1/jml49MgWbqFXatWtHmzZt+PzzzwGwWCyEhobyn//8h4kTJ15ye7PZjKenJ59//jkPPfTQta6uEP/KlVzvZrOZ2267jUceeYQNGzaQlZVVpW+shahul3u9f/nll3zwwQccPHgQvV5/vasrxL9yudf76NGjOXDgAOvWrbOtGz9+PH///TcbN268bvUW4t9SFIXFixdftKffhAkTWLFiBfv27bOtu//++8nKymLVqlXXoZb/nrSki1qjpKSE7du30717d9s6jUZD9+7d2bJlS5X2UVBQQGlpKV5eXteqmkJcFVd6vb/55pv4+fnx6KOPXo9qCnFVXMn1vmzZMtq3b8/TTz+Nv78/UVFRvPvuu5jN5utVbSGuyJVc7x06dGD79u22LvHHjh1j5cqV9O7d+7rUWYjracuWLXafD4CePXtW+f/9mkBX3RUQ4npJS0vDbDbj7+9vt97f35+DBw9WaR8TJkwgKCio3AdfiJrmSq73jRs38u2337Jr167rUEMhrp4rud6PHTvGb7/9xpAhQ1i5ciVHjhzhqaeeorS0lEmTJl2PagtxRa7ken/wwQdJS0ujY8eOqKqKyWTiiSeekO7u4qaUlJRU4ecjJyeHwsJCHB0dq6lmVSct6UJU0eTJk5k7dy6LFy/GaDRWd3WEuKpyc3MZNmwY06dPx8fHp7qrI8Q1Z7FY8PPz4+uvv6Z169YMHjyYl19+mS+//LK6qybEVbd+/XreffddvvjiC3bs2MGiRYtYsWIFb731VnVXTQhRAWlJF7WGj48PWq2W5ORku/XJyckEBARcdNsPP/yQyZMns3btWpo3b34tqynEVXG51/vRo0eJj4+nb9++tnUWiwUAnU7HoUOHqFev3rWttBBX6Er+vgcGBqLX69FqtbZ1jRs3JikpiZKSEgwGwzWtsxBX6kqu91dffZVhw4YxcuRIAJo1a0Z+fj6PPfYYL7/8MhqNtNuJm0dAQECFnw83N7cbohUdpCVd1CIGg4HWrVvbDZpisVhYt24d7du3r3S7//73v7z11lusWrWKmJiY61FVIf61y73eGzVqxN69e9m1a5dtufvuu20jo4aGhl7P6gtxWa7k7/utt97KkSNHbF9GARw+fJjAwEAJ6KJGu5LrvaCgoFwQL/uCSsaQFjeb9u3b230+ANasWXPR//drHFWIWmTu3Lmqg4ODOnPmTHX//v3qY489pnp4eKhJSUmqqqrqsGHD1IkTJ9rKT548WTUYDOqCBQvUxMRE25Kbm1tdpyBElV3u9X6h4cOHq/369btOtRXi37nc6/3kyZOqq6urOnr0aPXQoUPqzz//rPr5+alvv/12dZ2CEFV2udf7pEmTVFdXV3XOnDnqsWPH1F9//VWtV6+eet9991XXKQhRZbm5uerOnTvVnTt3qoA6ZcoUdefOneqJEydUVVXViRMnqsOGDbOVP3bsmOrk5KQ+//zz6oEDB9SpU6eqWq1WXbVqVXWdwmWT7u6iVhk8eDCpqam89tprJCUlER0dzapVq2yDS5w8edLum+Zp06ZRUlLCoEGD7PYzadIkXn/99etZdSEu2+Ve70LcyC73eg8NDWX16tWMHTuW5s2bExwczJgxY5gwYUJ1nYIQVXa51/srr7yCoii88sorJCQk4OvrS9++fXnnnXeq6xSEqLLY2Fi6dOliezxu3DgAhg8fzsyZM0lMTOTkyZO25+vUqcOKFSsYO3Ysn376KSEhIXzzzTf07Nnzutf9Ssk86UIIIYQQQgghRA0hTShCCCGEEEIIIUQNISFdCCGEEEIIIYSoISSkCyGEEEIIIYQQNYSEdCGEEEIIIYQQooaQkC6EEEIIIYQQQtQQEtKFEEIIIYQQQogaQkK6EEIIIYQQQghRQ0hIF0IIIYQQQgghaggJ6UIIIa66hx9+mP79+/+rfcTHx6MoCrt27aq0zPr161EUhaysLABmzpyJh4eH7fnXX3+d6Ojof1WPK5WUlESPHj1wdna2q9OViIiI4JNPPrkq9RKVUxSFJUuWVHc1apz09HT8/PyIj4+v8jarVq0iOjoai8Vy7SomhBA3KQnpQghRiz388MMoioKiKBgMBurXr8+bb76JyWSq7qpVSYcOHUhMTMTd3b3C55977jnWrVtne3w1vjyoqo8//pjExER27drF4cOHKy2Xk5PDyy+/TKNGjTAajQQEBNC9e3cWLVqEqqrXpa7/xrX+IqTsi5iyxdfXl969e7N3795rdsza4HI+C++88w79+vUjIiKiyvvv1asXer2eH3/88coqKIQQtZiEdCGEqOV69epFYmIicXFxjB8/ntdff50PPvigwrIlJSXXuXYXZzAYCAgIQFGUCp93cXHB29v7OtfK6ujRo7Ru3ZoGDRrg5+dXYZmsrCw6dOjADz/8wIsvvsiOHTv4888/GTx4MC+88ALZ2dnXrH417b28VH0OHTpEYmIiq1evpri4mLvuuqvGncPNqKCggG+//ZZHH330srd9+OGH+eyzz65BrYQQ4uYmIV0IIWo5BwcHAgICCA8P58knn6R79+4sW7YMONfa9s477xAUFETDhg0B2Lt3L127dsXR0RFvb28ee+wx8vLyyu37jTfewNfXFzc3N5544gm7ULVq1So6duyIh4cH3t7e9OnTh6NHj5bbx8GDB+nQoQNGo5GoqCj++OMP23MXdne/0PmtvK+//jrff/89S5cutbXKrl+/nq5duzJ69Gi77VJTUzEYDHat8BeaNm0a9erVw2Aw0LBhQ2bNmmV7LiIigoULF/LDDz+gKAoPP/xwhft46aWXiI+P5++//2b48OE0adKEyMhIRo0axa5du3BxcbGVLSgo4JFHHsHV1ZWwsDC+/vpru31NmDCByMhInJycqFu3Lq+++iqlpaXlXotvvvmGOnXqYDQagaq9D6dPn+aBBx7Ay8sLZ2dnYmJi+Pvvv5k5cyZvvPEGu3fvtr2mM2fOBKxfQIwcOdL2/nft2pXdu3dfsj6V8fPzIyAggFatWvHss89y6tQpDh48aHt+48aNdOrUCUdHR0JDQ3nmmWfIz8+3e0/eeustHnjgAZydnQkODmbq1KkXPealXlOA5cuX06ZNG4xGIz4+PgwYMMD2XHFxMc899xzBwcE4OzvTrl071q9fb3u+7PaMn3/+mYYNG+Lk5MSgQYMoKCjg+++/JyIiAk9PT5555hnMZvNl73f16tU0btwYFxcX25dxZa99RZ+FiqxcuRIHBwduueUW27qyz92KFSto3rw5RqORW265hX379tlt27dvX2JjYyv8XAshhKichHQhhBB2HB0d7cL0unXrOHToEGvWrOHnn38mPz+fnj174unpybZt25g/fz5r164tF3TXrVvHgQMHWL9+PXPmzGHRokW88cYbtufz8/MZN24csbGxrFu3Do1Gw4ABA8rdw/r8888zfvx4du7cSfv27enbty/p6emXfV7PPfcc9913ny2sJCYm0qFDB0aOHMlPP/1EcXGxrezs2bMJDg6ma9euFe5r8eLFjBkzhvHjx7Nv3z4ef/xxRowYwe+//w7Atm3b6NWrF/fddx+JiYl8+umn5fZhsViYO3cuQ4YMISgoqNzzLi4u6HQ62+OPPvqImJgYdu7cyVNPPcWTTz7JoUOHbM+7uroyc+ZM9u/fz6effsr06dP5+OOP7fZ55MgRFi5cyKJFi2z3+l/qfcjLy+P2228nISGBZcuWsXv3bl544QUsFguDBw9m/PjxNG3a1PaaDh48GIB7772XlJQUfvnlF7Zv306rVq3o1q0bGRkZF63PpWRnZzN37lzA2pMCrL0WevXqxcCBA9mzZw/z5s1j48aN5a7JDz74gBYtWrBz504mTpzImDFjWLNmTaXHutRrumLFCgYMGEDv3r3ZuXMn69ato23btrbnR48ezZYtW5g7dy579uzh3nvvpVevXsTFxdnKFBQU8NlnnzF37lxWrVrF+vXrGTBgACtXrmTlypXMmjWLr776igULFlz2fj/88ENmzZrFn3/+ycmTJ3nuueeAyj8LFdmwYQOtW7eu8Lnnn3+ejz76iG3btuHr60vfvn3tvsQICwvD39+fDRs2VPoaCyGEqIAqhBCi1ho+fLjar18/VVVV1WKxqGvWrFEdHBzU5557zva8v7+/WlxcbNvm66+/Vj09PdW8vDzbuhUrVqgajUZNSkqybefl5aXm5+fbykybNk11cXFRzWZzhXVJTU1VAXXv3r2qqqrq8ePHVUCdPHmyrUxpaakaEhKivv/++6qqqurvv/+uAmpmZqaqqqo6Y8YM1d3d3VZ+0qRJaosWLSo83zKFhYWqp6enOm/ePNu65s2bq6+//nqlr1uHDh3UUaNG2a2799571d69e9se9+vXTx0+fHil+0hOTlYBdcqUKZWWKRMeHq4OHTrU9thisah+fn7qtGnTKt3mgw8+UFu3bm17PGnSJFWv16spKSkXPdaF78NXX32lurq6qunp6RWWv/A1VlVV3bBhg+rm5qYWFRXZra9Xr5761VdfXVZ9yt5jZ2dn1dnZWQVUQL377rttZR599FH1scceK1cHjUajFhYWqqpqfQ179eplV2bw4MHqnXfeaXsMqIsXL660Lhe+pu3bt1eHDBlSYdkTJ06oWq1WTUhIsFvfrVs39cUXX1RV1Xq9AuqRI0dszz/++OOqk5OTmpuba1vXs2dP9fHHH/9X+506darq7+9ve1zRZ6Ei/fr1Ux955BG7dWXvydy5c23r0tPTVUdHR7vPkaqqasuWLS/6WRJCCFGeruLoLoQQorb4+eefcXFxobS0FIvFwoMPPsjrr79ue75Zs2a2FkuAAwcO0KJFC5ydnW3rbr31ViwWC4cOHcLf3x+AFi1a4OTkZCvTvn178vLyOHXqFOHh4cTFxfHaa6/x999/k5aWZmu5PXnyJFFRUXbbldHpdMTExHDgwIGrdv5Go5Fhw4bx3Xffcd9997Fjxw727dtn6/JfkQMHDvDYY4/Zrbv11lsrbDGvjHqZg8I1b97c9ruiKAQEBJCSkmJbN2/ePD777DOOHj1KXl4eJpMJNzc3u32Eh4fj6+trt+5S78OuXbto2bIlXl5eVa7r7t27ycvLKzceQGFhoV3X54rqU5kNGzbg5OTEX3/9xbvvvsuXX35pd7w9e/bYDVKmqioWi4Xjx4/TuHFjwP5aKnt8sVHzL/Wa7tq1i1GjRlW47d69ezGbzURGRtqtLy4utntdnJycqFevnu2xv78/ERERdrc6+Pv7297rK91vYGCg3fVSVYWFhZXeinD+6+nl5UXDhg3LfTYdHR0pKCi47OMKIURtJiFdCCFquS5dujBt2jQMBgNBQUF2XawBuzB+NfXt25fw8HCmT59OUFAQFouFqKioahkMbOTIkURHR3P69GlmzJhB165dCQ8Pv6bH9PX1xcPDw+6+6ovR6/V2jxVFsQXqLVu2MGTIEN544w169uyJu7s7c+fO5aOPPrLbpqL38lLvg6Oj42WfW15eHoGBgRXe53z+dHSXc23VqVMHDw8PGjZsSEpKCoMHD+bPP/+0He/xxx/nmWeeKbddWFjYZdcfqvaaXuy1ycvLQ6vVsn37drRard1z5wfwit7Xi73X/2a/l/vFEICPjw+ZmZmXvV2ZjIyMKn8RI4QQwkruSRdCiFrO2dmZ+vXrExYWVi6gV6Rx48bs3r3bblCuTZs2odFobAPLgbV1s7Cw0Pb4r7/+wsXFhdDQUNLT0zl06BCvvPIK3bp1o3HjxpUGgb/++sv2u8lkYvv27baW0ctlMBjsBuAq06xZM2JiYpg+fTo//fQTjzzyyEX307hxYzZt2mS3btOmTTRp0qTKddFoNNx///38+OOPnDlzptzzZS23VbF582bCw8N5+eWXiYmJoUGDBpw4ceKS21XlfWjevDm7du2yu5f8fBW9pq1atSIpKQmdTkf9+vXtFh8fnyqd08U8/fTT7Nu3j8WLF9uOt3///nLHql+/vl0vkPOvpbLHlV1LVXlNmzdvXunggi1btsRsNpOSklKuTgEBAVd87ldrv5V9Fio63v79+yt87vzXMzMzk8OHD9u9nkVFRRw9epSWLVtWuV5CCCEkpAshhLhMQ4YMwWg0Mnz4cPbt28fvv//Of/7zH4YNG2br6g7WKbUeffRR9u/fz8qVK5k0aRKjR49Go9Hg6emJt7c3X3/9NUeOHOG3335j3LhxFR5v6tSpLF68mIMHD/L000+TmZl5yRBdmYiICPbs2cOhQ4dIS0uzG+Rq5MiRTJ48GVVV7Uborsjzzz/PzJkzmTZtGnFxcUyZMoVFixbZBuaqqnfeeYfQ0FDatWvHDz/8wP79+4mLi+O7776jZcuWFY6YX5EGDRpw8uRJ5s6dy9GjR/nss89sAfZiqvI+PPDAAwQEBNC/f382bdrEsWPHWLhwIVu2bAGsr+nx48fZtWsXaWlpFBcX0717d9q3b0///v359ddfiY+PZ/Pmzbz88svExsZe1mtUEScnJ0aNGsWkSZNQVZUJEyawefNmRo8eza5du4iLi2Pp0qXlBo7btGkT//3vfzl8+DBTp05l/vz5jBkzpsJjVOU1nTRpEnPmzGHSpEkcOHCAvXv38v777wMQGRnJkCFDeOihh1i0aBHHjx9n69atvPfee6xYseKKz/1q7fdin4Xz9ezZk3/++afCL9HefPNN1q1bx759+3j44Yfx8fGxm3v9r7/+wsHBodxtBkIIIS5OQroQQojL4uTkxOrVq8nIyKBNmzYMGjSIbt268fnnn9uV69atGw0aNOC2225j8ODB3H333bZ73TUaDXPnzmX79u1ERUUxduzYSudmnzx5MpMnT6ZFixZs3LiRZcuWXXFr7KhRo2jYsCExMTH4+vratYY/8MAD6HQ6HnjggUtOB9a/f38+/fRTPvzwQ5o2bcpXX33FjBkz6Ny582XVx8vLi7/++ouhQ4fy9ttv07JlSzp16sScOXP44IMPcHd3r9J+7r77bsaOHcvo0aOJjo5m8+bNvPrqq5fcrirvg8Fg4Ndff8XPz4/evXvTrFkzJk+ebOtqPXDgQHr16kWXLl3w9fVlzpw5KIrCypUrue222xgxYgSRkZHcf//9nDhxwu6LnH9j9OjRHDhwgPnz59O8eXP++OMPDh8+TKdOnWjZsiWvvfZauVHzx48fT2xsLC1btuTtt99mypQp9OzZs8L9V+U17dy5M/Pnz2fZsmVER0fTtWtXtm7dant+xowZPPTQQ4wfP56GDRvSv39/tm3bdsVd8K/mfi/2WThfs2bNaNWqFf/73//KPTd58mTGjBlD69atSUpKYvny5XY9F+bMmcOQIUPsxqYQQghxaYp6JTcoCSGEEDeZ+Ph46tWrx7Zt22jVqlV1V0dcZRERETz77LM8++yz1V2VG86KFSt4/vnn2bdvHxqNhvXr19OlSxcyMzPtxhg4X1paGg0bNiQ2NpY6depc3woLIcQNTgaOE0IIUauVlpaSnp7OK6+8wi233CIBXYgL3HXXXcTFxZGQkEBoaGiVtomPj+eLL76QgC6EEFdAQroQQohabdOmTXTp0oXIyEgWLFhQ3dURoka63B4IMTExxMTEXJvKCCHETU66uwshhBBCCCGEEDWEDBwnhBBCCCGEEELUEBLShRBCCCGEEEKIGkJCuhBCCCGEEEIIUUNISBdCCCGEEEIIIWoICelCCCGEEEIIIUQNISFdCCGEEEIIIYSoISSkCyGEEEIIIYQQNYSEdCGEEEIIIYQQoob4f9aReIhNcoT3AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot for extra_scuffed = False\n",
    "df_not_scuffed = df_results[df_results['Extra Scuffed'] == False]\n",
    "plt.plot(df_not_scuffed['p Value'], df_not_scuffed['Word Model Accuracy'],\n",
    "         marker='o', label='Word Model (Not Scuffed)')\n",
    "plt.plot(df_not_scuffed['p Value'], df_not_scuffed['Char Model Accuracy'],\n",
    "         marker='s', label='Char Model (Not Scuffed)')\n",
    "\n",
    "# Plot for extra_scuffed = True\n",
    "df_scuffed = df_results[df_results['Extra Scuffed'] == True]\n",
    "plt.plot(df_scuffed['p Value'], df_scuffed['Word Model Accuracy'],\n",
    "         marker='o', linestyle='--', label='Word Model (Scuffed)')\n",
    "plt.plot(df_scuffed['p Value'], df_scuffed['Char Model Accuracy'],\n",
    "         marker='s', linestyle='--', label='Char Model (Scuffed)')\n",
    "\n",
    "plt.xlabel('Probability of Character Replacement (p)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Performance with Varying Noise Levels')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Custom text classification\n",
    "\n",
    "**1. Finally, to show the robustness of fasttext (and for fun), you are to make your own text and try to let fasttext classify this as one of the four models. Rememeber that the original dataset used texts of around 240 words, so you can either experiment with texts shorter or longer than this and see whether the accuracy is significantly different.**\n",
    "\n",
    "**As an extra challenge, you can try to create a text which is as close to the model's decision boundary as possible, IE. one that is as close as possible to being classified as either two or more of the classes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate 20 different texts with varying topics using ChatGPT's o1-preview model, the first 5 is below 240 words, the next 5 is exactly 240 words (cut off, if there was generated more than 240), the next 5 having above 240 words, and for the extra challenge, the last 5 having exactly 240 words but each with two mixed topics. For the prediction of mixed topics, we just check if it has either one correct. Of course, it is expected that this accuracy is equivalent to that of exactly 240 words, since we expect either one to be correct at the same rate as \"exactly 240 words\".\n",
    "\n",
    "We used the following prompts:\n",
    "\n",
    "\"Generate 15 different texts with one of the four possible categories: World, Sports, Business, Sci/Tec. 5 of the texts should be below 240 words, 5 of the texts should be exactly 240 words and the last 5 should be above.\"\n",
    "\n",
    "and\n",
    "\n",
    "\"Now generate 5 more texts with 240 words that each have 2 different topics in one text. E.g. first text has World and Sports, the second text has Sci/Tec and Business, etc.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified as: Sci/Tec with certainty: 0.7169191241264343\n",
      "Amount of words:  138\n",
      "\n",
      "Classified as: Sports with certainty: 0.9806429743766785\n",
      "Amount of words:  136\n",
      "\n",
      "Classified as: Sci/Tec with certainty: 0.5127098560333252\n",
      "Amount of words:  131\n",
      "\n",
      "Classified as: Sci/Tec with certainty: 0.9160479307174683\n",
      "Amount of words:  127\n",
      "\n",
      "Classified as: World with certainty: 0.7361973524093628\n",
      "Amount of words:  112\n",
      "\n",
      "Classified as: Sports with certainty: 0.6938124299049377\n",
      "Amount of words:  240\n",
      "\n",
      "Classified as: Business with certainty: 0.6210265159606934\n",
      "Amount of words:  240\n",
      "\n",
      "Classified as: Sci/Tec with certainty: 0.9381464719772339\n",
      "Amount of words:  240\n",
      "\n",
      "Classified as: Business with certainty: 0.7805176973342896\n",
      "Amount of words:  240\n",
      "\n",
      "Classified as: Sports with certainty: 0.8408596515655518\n",
      "Amount of words:  240\n",
      "\n",
      "Classified as: Sci/Tec with certainty: 0.9252381920814514\n",
      "Amount of words:  343\n",
      "\n",
      "Classified as: Sci/Tec with certainty: 0.7221215963363647\n",
      "Amount of words:  381\n",
      "\n",
      "Classified as: Sci/Tec with certainty: 0.5739774703979492\n",
      "Amount of words:  435\n",
      "\n",
      "Classified as: Sci/Tec with certainty: 0.6271042823791504\n",
      "Amount of words:  454\n",
      "\n",
      "Classified as: Sci/Tec with certainty: 0.47291505336761475\n",
      "Amount of words:  456\n",
      "\n",
      "Classified as: World with certainty: 0.4267936050891876\n",
      "Amount of words:  240\n",
      "\n",
      "Classified as: Sci/Tec with certainty: 0.8308634757995605\n",
      "Amount of words:  240\n",
      "\n",
      "Classified as: Sci/Tec with certainty: 0.7515397071838379\n",
      "Amount of words:  240\n",
      "\n",
      "Classified as: Sci/Tec with certainty: 0.8589121103286743\n",
      "Amount of words:  240\n",
      "\n",
      "Classified as: Sci/Tec with certainty: 0.7306228876113892\n",
      "Amount of words:  240\n",
      "\n",
      "Accuracy for texts below 240 words: 0.6\n",
      "Accuracy for texts with 240 words: 0.8\n",
      "Accuracy for texts above 240 words: 0.4\n",
      "Accuracy for mixed texts: 0.8\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "\"In a historic gathering, world leaders assembled today for the annual Climate Summit to address the escalating environmental crisis. Representatives from over 100 countries discussed strategies to reduce greenhouse gas emissions and transition to renewable energy sources. Key topics included implementing carbon pricing, investing in sustainable infrastructure, and supporting developing nations affected by climate change. Several nations pledged to achieve net-zero emissions by 2050, with some aiming for even earlier targets. The summit emphasized the importance of international cooperation and technological innovation in combating climate change. Activists and experts stressed that immediate action is necessary to prevent irreversible damage to the planet. While the commitments were praised, critics argued that the measures are insufficient and lack enforceability. The summit concluded with a call to action, urging all countries to accelerate their efforts in addressing the global environmental challenge.\",\n",
    "\n",
    "\"In a stunning upset, the underdog Riverside Tigers clinched the National Basketball Championship last night, defeating the heavily favored Metro City Eagles. The game kept fans on the edge of their seats as the Tigers overcame a significant halftime deficit. Star player Alex Ramirez led the charge with 30 points and 12 rebounds, earning the Most Valuable Player award. Coach Sandra Lee credited the victory to the team's relentless spirit and hard work throughout the season. We believed in ourselves when no one else did, she remarked during the post-game interview. The Tigers' win marks their first national title in school history. The victory parade is scheduled for next week, with the entire community expected to celebrate the team's remarkable achievement. Analysts are already calling this game one of the most memorable championships in recent years.\",\n",
    "\n",
    "\"In a move that has shaken the tech industry, GlobalTech Corporation announced its acquisition of startup InnovateX for $2 billion. InnovateX, known for its cutting-edge artificial intelligence solutions, will bolster GlobalTech's portfolio in the rapidly growing AI market. The deal is expected to close by the end of the fiscal quarter, pending regulatory approval. GlobalTech's CEO, Maria Thompson, stated that the acquisition aligns with the company's strategic vision to lead in AI development. Combining our resources with InnovateX's innovative technology will accelerate our ability to deliver transformative products to our customers, she said. Investors reacted positively to the news, with GlobalTech's stock price rising by 5% in after-hours trading. Industry experts believe this acquisition could spark a wave of consolidation in the tech sector as companies vie for dominance in AI.\",\n",
    "\n",
    "\"Scientists at the National Research Laboratory have announced a significant breakthrough in quantum computing. The research team successfully demonstrated a stable quantum processor capable of performing complex calculations at unprecedented speeds. This development could revolutionize fields such as cryptography, materials science, and drug discovery. Dr. Elena Martinez, the lead researcher, explained that the new processor overcomes previous limitations related to quantum decoherence. Our approach maintains quantum states longer, allowing for more reliable computation, she said. The findings were published in the Journal of Advanced Computing. Experts are hailing this as a major step forward, though practical applications may still be years away. Further research is needed to scale the technology for commercial use. Nevertheless, the breakthrough represents a promising advancement in the quest for powerful quantum computers.\",\n",
    "\n",
    "\"After decades of conflict, the governments of Landia and Riverton have signed a historic peace agreement aimed at ending hostilities and fostering cooperation. The treaty, brokered by international mediators, includes provisions for border demarcation, resource sharing, and the return of displaced persons. World leaders praised the agreement as a significant step toward stability in the region. United Nations Secretary-General António Guterres commended both sides for their willingness to negotiate and compromise. This is a beacon of hope for conflict resolution worldwide, he stated. The agreement faces challenges ahead, including implementation and addressing deep-seated mistrust between the populations. However, optimism remains high as both nations prepare to open embassies and establish diplomatic relations.\",\n",
    "\n",
    "\"In an electrifying performance at the International Swimming Championships, 23-year-old phenom Michael Anders shattered the world record in the men's 100-meter freestyle. Clocking in at an astonishing 46.80 seconds, Anders surpassed the previous record of 46.91 seconds set by rival swimmer James Collins two years ago. The stadium erupted as Anders touched the wall, realizing he had made history. It's a dream come true, he exclaimed during the post-race interview. I've been training for this moment my entire life. Anders' victory is the culmination of years of dedication and rigorous training under coach Sarah Thompson. Known for her innovative techniques, Thompson has been instrumental in refining Anders' speed and endurance. Michael's work ethic is unparalleled, she noted. He deserves every bit of this success. The race was highly anticipated, featuring a lineup of the world's top swimmers. Anders took an early lead, maintaining a flawless stroke and incredible pace throughout the race. Collins finished a close second, congratulating Anders on his achievement. Records are meant to be broken, Collins remarked graciously. Analysts predict that Anders' record may stand for years, given the margin by which he surpassed the previous time. The swimming community is abuzz with speculation about his potential at the upcoming Olympic Games. Fans worldwide have taken to social media to celebrate the historic moment. Anders' hometown is planning a parade in his honor, recognizing the local hero's remarkable accomplishment. As the sport of swimming reaches new heights\",\n",
    "\n",
    "\"In a significant blow to the traditional retail sector, long-standing department store chain GrandMart has filed for Chapter 11 bankruptcy protection. The company cited declining sales, mounting debt, and the relentless rise of e-commerce as primary factors contributing to its financial woes. Founded over 80 years ago, GrandMart was once a staple in shopping malls across the nation, offering a wide array of products from clothing to home goods. However, shifting consumer preferences toward online shopping have eroded its customer base. The COVID-19 pandemic exacerbated the situation, with prolonged store closures and reduced foot traffic. CEO Linda Roberts announced the decision in a press release. This was an incredibly difficult choice, but necessary to restructure our operations and emerge stronger, she stated. The company plans to close 150 underperforming stores while seeking buyers for remaining assets. Industry experts view GrandMart's bankruptcy as indicative of broader challenges facing brick-and-mortar retailers. The retail landscape is evolving rapidly, commented analyst Mark Stevens. Companies must adapt or risk obsolescence. Employees and suppliers are bracing for the impact. The company employs over 20,000 workers, many of whom face uncertain futures. Unions are advocating for fair severance packages and job placement assistance. Meanwhile, competitors in the e-commerce space continue to thrive. Online giants report record profits, capitalizing on the digital shopping trend. Some suggest that GrandMart's failure to invest adequately in online platforms contributed to its downfall. The bankruptcy proceedings will unfold over the coming months\",\n",
    "\n",
    "\"Researchers at the University of GreenTech have unveiled a groundbreaking method to accelerate plastic degradation, potentially revolutionizing waste management and environmental conservation. The team engineered a strain of bacteria capable of breaking down polyethylene terephthalate (PET), a common plastic, within weeks rather than centuries. Led by Dr. Emily Hart, the scientists modified the enzyme PETase, enhancing its ability to digest plastic molecules more efficiently. Our enhanced enzyme can reduce PET plastics to their basic components in a fraction of the time, Dr. Hart explained. This could be a game-changer in addressing plastic pollution. Laboratory tests demonstrated that the engineered bacteria decomposed PET samples by 90% within 60 days. Traditional plastics can persist in the environment for hundreds of years, accumulating in landfills and oceans. Environmentalists are cautiously optimistic. If scalable, this technology could significantly mitigate plastic waste, noted Lisa Perez of the Environmental Protection Agency. However, she emphasized the importance of assessing ecological impacts before widespread application. The team is exploring ways to implement the technology on an industrial scale. Potential applications include treating plastic waste at recycling facilities or contaminated sites. Partnerships with waste management companies are being considered to pilot large-scale operations. Critics urge careful consideration of releasing genetically modified organisms into the environment. We must ensure that such interventions do not create unforeseen ecological problems, warned bioethicist Dr. Alan Monroe. Funding for the research was provided by government grants and private environmental foundations. The findings have been\",\n",
    "\n",
    "\"Leaders from ten nations signed a landmark trade agreement today, establishing the Pacific Regional Economic Partnership (PREP), aimed at enhancing economic integration and reducing trade barriers among member countries. The pact is expected to increase trade flows, promote investment, and foster economic growth across the region. The signing ceremony took place in Singapore, with heads of state and trade ministers in attendance. This agreement represents a new era of cooperation and shared prosperity, declared Singapore's Prime Minister Lee Tan. By working together, we can achieve greater economic resilience and opportunity for our peoples. Key provisions of the agreement include the elimination of tariffs on 90% of goods, the harmonization of regulations, and the facilitation of services trade. The deal also encompasses commitments to environmental standards and labor rights. Economists predict that the PREP could boost the collective GDP of member nations by $500 billion over the next decade. The reduction of trade barriers will enhance competitiveness and innovation, commented economist Dr. Maya Patel. Businesses will have access to larger markets, benefiting consumers through lower prices and greater choice. However, the agreement faces criticism from some quarters. Labor unions express concerns about potential job losses in certain sectors due to increased competition. We must ensure that workers are protected and that the benefits of trade are broadly shared, stated union leader Carlos Mendes. Environmental groups caution that increased industrial activity could exacerbate ecological challenges unless properly managed. The agreement includes clauses\",\n",
    "\n",
    "\"In a dramatic conclusion to the Open Championship, 19-year-old tennis prodigy Sofia Martinez clinched her first Grand Slam title, defeating world number one Serena Williams in a three-set thriller. The match, lasting over two hours, showcased Martinez's exceptional skill and composure under pressure. Martinez, unseeded in the tournament, defied expectations throughout, eliminating several top-ranked players en route to the final. Her victory over Williams, a seasoned champion with 23 Grand Slam titles, marks one of the most significant upsets in tennis history. I'm overwhelmed with joy, Martinez expressed during the trophy presentation. Facing my idol and winning is beyond anything I imagined. The first set saw Williams dominate with powerful serves and forehands, securing it 6-3. Undeterred, Martinez adjusted her strategy, employing tactical placements and agile movements to take the second set 7-5. The decisive third set was a nail-biter, with Martinez saving match points before sealing the win at 7-6 in a tiebreak. Commentators praised Martinez's performance. Her maturity and tactical intelligence are remarkable for her age, noted former champion Anna Kournikova. Williams graciously acknowledged her opponent. Sofia played exceptionally well. She has a bright future ahead, she said. Martinez's triumph propels her into the global spotlight and significantly boosts her ranking. Sponsors and media outlets are eager to engage with the new star, heralding a potential shift in the sport's landscape. Back home, celebrations erupted as fans gathered to watch the historic match. The government announced plans to\",\n",
    "\n",
    "\"Astronomers have announced the discovery of an Earth-sized exoplanet located within the habitable zone of a nearby star system, sparking excitement about the possibility of finding extraterrestrial life. The planet, designated Kepler-1649c, orbits a red dwarf star approximately 300 light-years from Earth. Using data from the Kepler Space Telescope, the research team identified the planet through transit observations, noting that it receives about 75% of the light Earth gets from the Sun. This positions Kepler-1649c within the so-called Goldilocks Zone, where conditions could allow for liquid water on its surface—a key ingredient for life as we know it. Dr. Laura Simmons, the lead astronomer, emphasized the significance of the find. This is one of the most promising exoplanets we've discovered in terms of potential habitability, she said. Its size, estimated to be similar to Earth's, and its temperate orbit make it an exciting target for further study. The discovery has reinvigorated discussions about the prevalence of potentially life-supporting planets in our galaxy. Scientists estimate that there could be billions of such planets orbiting red dwarf stars, which are the most common type of star in the Milky Way. However, challenges remain in determining the planet's actual conditions. Red dwarf stars can emit intense solar flares that might strip away a planet's atmosphere or make the surface inhospitable. Additional observations are needed to assess the planet's atmosphere, composition, and potential magnetic field. Future missions, such as the James Webb Space Telescope and the planned LUVOIR mission, could provide the necessary tools to study exoplanets like Kepler-1649c in greater detail. Spectroscopic analysis may reveal atmospheric components such as oxygen, methane, and other biomarkers indicative of life. The discovery also raises philosophical and ethical questions about humanity's place in the universe and the implications of finding life elsewhere. If life is detected, it could profoundly impact science, religion, and society at large. As technology advances, the search for extraterrestrial life continues to be a unifying endeavor that transcends national boundaries. International collaboration will be essential in exploring these distant worlds and unraveling the mysteries they hold.\",\n",
    "\n",
    "\"The global retail industry is undergoing a significant transformation as e-commerce continues to surge, reshaping consumer behavior and market dynamics in the aftermath of the COVID-19 pandemic. The shift toward online shopping, accelerated by lockdowns and social distancing measures, shows no signs of slowing down even as economies reopen. Major e-commerce platforms report record revenues, with some experiencing growth rates exceeding 50% year-over-year. This trend is not limited to established markets; emerging economies are also witnessing rapid adoption of digital commerce, facilitated by increasing internet penetration and mobile device usage. Retail analysts attribute this sustained growth to several factors. Consumers have become accustomed to the convenience of online shopping, which offers a broader selection of products, competitive pricing, and home delivery. Additionally, advancements in logistics and supply chain management have reduced delivery times and improved customer satisfaction. Brick-and-mortar retailers are adapting by integrating online channels into their business models, a strategy known as omnichannel retailing. This approach aims to provide a seamless shopping experience across physical and digital platforms. Companies investing in technology and data analytics are better positioned to understand customer preferences and tailor their offerings accordingly. However, the e-commerce boom presents challenges. Small and medium-sized enterprises (SMEs) may struggle to compete with larger players due to limited resources and technological capabilities. Governments and industry organizations are encouraging SMEs to adopt digital tools, offering training programs and financial incentives. Cybersecurity and data privacy concerns are also at the forefront. The increase in online transactions has led to a rise in cyberattacks and fraud. Businesses must invest in robust security measures to protect consumer data and maintain trust. Moreover, the environmental impact of increased packaging and delivery logistics is under scrutiny. Sustainability initiatives, such as using recyclable materials and optimizing delivery routes to reduce emissions, are becoming essential components of corporate responsibility strategies. Looking ahead, experts predict that technologies like artificial intelligence, augmented reality, and blockchain will further revolutionize e-commerce. Personalized shopping experiences, virtual try-ons, and secure transactions are set to enhance customer engagement. The pandemic has undeniably accelerated the digital transformation of retail. Companies that adapt to these changes stand to thrive in the new landscape, while those resistant may face obsolescence. The ongoing evolution of e-commerce will continue to redefine how consumers interact with brands and make purchasing decisions.\",\n",
    "\n",
    "\"In a landmark shift towards sustainable energy, countries around the globe are rapidly adopting renewable energy sources to meet ambitious carbon neutrality goals set for the coming decades. The transition from fossil fuels to renewables like solar, wind, hydroelectric, and geothermal energy is being driven by international agreements, technological advancements, and growing public demand for action on climate change. The Paris Agreement, signed by nearly 200 nations, has been a catalyst for this transformation, with countries committing to limit global warming to well below 2 degrees Celsius above pre-industrial levels. To achieve these targets, governments are implementing policies and incentives that encourage investment in renewable energy infrastructure. China, the world's largest emitter of greenhouse gases, has pledged to reach peak carbon emissions by 2030 and achieve carbon neutrality by 2060. The country is investing heavily in solar and wind power, already leading in installed capacity. Similarly, the European Union has set an ambitious goal to become the first climate-neutral continent by 2050, with member states ramping up renewable energy production and phasing out coal. The United States has re-entered the Paris Agreement and is focusing on modernizing its energy grid, promoting electric vehicles, and supporting clean energy research. The Biden administration's infrastructure plan includes substantial funding for renewable energy projects and aims to decarbonize the power sector by 2035. Developing nations are also participating in the renewable revolution. India plans to install 450 gigawatts of renewable energy capacity by 2030, while African countries are exploring solar and wind projects to provide electricity to remote regions. Technological advancements have made renewables more cost-competitive with traditional energy sources. The cost of solar photovoltaic modules and wind turbines has decreased significantly, making them attractive options for new power generation. Energy storage solutions, like advanced batteries, are addressing the intermittency issues of renewables, enhancing grid stability. Despite progress, challenges remain. Transitioning to renewable energy requires substantial investment, grid modernization, and overcoming regulatory and market barriers. Energy-intensive industries and regions dependent on fossil fuels face economic and social hurdles. Ensuring a just transition for workers and communities affected by the shift is a critical concern. Climate activists stress that time is of the essence. While the acceleration of renewable energy adoption is promising, experts warn that current efforts may not be sufficient to prevent the most severe impacts of climate change. Calls for increased ambition and faster action are growing louder. The global commitment to renewable energy marks a significant step towards a sustainable future. As nations collaborate and innovate, the hope is that collective efforts will mitigate climate risks, promote economic growth, and improve the quality of life worldwide.\",\n",
    "\n",
    "\"The rapid advancement of artificial intelligence (AI) and autonomous systems is intensifying global debates over ethical considerations, regulation, and the societal impact of these technologies. As AI becomes increasingly integrated into various sectors—ranging from healthcare and finance to transportation and defense—concerns about privacy, bias, accountability, and job displacement are taking center stage. One of the primary ethical dilemmas revolves around decision-making processes in AI systems, particularly those that affect human lives. For instance, autonomous vehicles must be programmed to make split-second decisions in life-or-death scenarios, raising questions about moral responsibility and the programming of ethical frameworks into machines. In the healthcare sector, AI algorithms assist in diagnostics and treatment planning. While these tools offer enhanced efficiency and accuracy, they also pose risks if the underlying data sets are biased or unrepresentative, potentially leading to disparities in care. Data privacy is another significant concern. AI systems often require vast amounts of personal data to function effectively. High-profile data breaches and misuse scandals have eroded public trust, prompting calls for stricter regulations to protect individuals' information. Employment disruption due to automation is also at the forefront of the debate. While AI has the potential to create new job categories, it simultaneously threatens to displace workers in sectors like manufacturing, customer service, and transportation. Policymakers are grappling with how to manage this transition, considering solutions like retraining programs and social safety nets. International organizations and governments are beginning to address these challenges. The European Union has proposed comprehensive AI regulations focusing on transparency, accountability, and human oversight. The guidelines aim to balance innovation with fundamental rights, imposing stricter rules on high-risk applications. Industry leaders are also participating in shaping ethical standards. Tech companies have established internal ethics boards and are collaborating on initiatives like the Partnership on AI, which brings together academia, industry, and civil society to address AI's societal implications. However, critics argue that self-regulation is insufficient and that more robust, enforceable policies are needed. They emphasize the importance of inclusive dialogue involving diverse stakeholders, including marginalized communities often disproportionately affected by technological changes. Educational institutions are responding by incorporating ethics into computer science and engineering curricula, preparing future professionals to consider the broader impact of their work. The debate extends to AI in military applications, such as autonomous weapons systems, which some warn could lower the threshold for conflict and raise profound ethical questions about delegating life-and-death decisions to machines. As AI continues to evolve, the urgency to establish ethical guidelines and regulatory frameworks grows. Balancing innovation with societal values is a complex challenge that requires international cooperation, multidisciplinary approaches, and ongoing public engagement. The outcome of these debates will shape the trajectory of AI development and its role in society for years to come.\",\n",
    "\n",
    "\"The COVID-19 pandemic has precipitated an unprecedented global education crisis, with school closures and remote learning exposing and amplifying existing inequities in access to quality education. As nations grapple with the aftermath, experts warn of a lost generation unless urgent measures are taken to address learning gaps and invest in resilient education systems. According to UNESCO, over 1.6 billion students were affected by school closures at the height of the pandemic. While some countries managed to pivot to online learning, disparities in technology access left millions without formal education for extended periods. In low-income regions, lack of internet connectivity and devices hindered remote learning initiatives. The long-term consequences are profound. Studies indicate significant declines in literacy and numeracy skills, particularly among marginalized communities. The World Bank estimates that learning poverty—defined as the inability of a 10-year-old to read and understand a simple text—could increase from 53% to 63% in low- and middle-income countries. Girls are disproportionately affected, with heightened risks of dropout due to economic pressures, early marriage, and caregiving responsibilities. The Malala Fund projects that 20 million secondary school-aged girls may never return to classrooms. Teachers face challenges as well, adapting to new technologies without adequate training or support. The strain has led to concerns about teacher burnout and attrition, further destabilizing education systems. Governments and international organizations are mobilizing resources to mitigate the crisis. Initiatives include deploying low-tech solutions like radio and television lessons, distributing printed materials, and implementing community-based education programs. Financial constraints pose significant hurdles. The economic downturn has strained public budgets, leading to cuts in education spending at a time when investment is most needed. The United Nations is advocating for increased funding and debt relief measures to enable countries to prioritize education. Innovations in EdTech offer potential solutions. Partnerships between governments, NGOs, and tech companies are developing platforms tailored to diverse contexts. However, ensuring equitable access remains a challenge. Reopening schools safely is a priority, with protocols for hygiene, social distancing, and mental health support. Vaccine distribution inequities complicate efforts, as unvaccinated populations face higher risks of outbreaks, leading to potential reclosures. The crisis underscores the necessity of reimagining education systems to be more inclusive, flexible, and resilient. Emphasizing foundational skills, socio-emotional learning, and digital literacy is critical. Engaging parents and communities in the educational process enhances support structures for students. Global cooperation is essential. Sharing best practices, resources, and expertise can accelerate recovery and build stronger systems. The Sustainable Development Goal of ensuring inclusive and equitable quality education by 2030 hangs in the balance. Without concerted action, the educational setbacks could have lasting impacts on economic development, social cohesion, and global stability. Investing in education is not only a moral imperative but a strategic necessity for a sustainable future.\",\n",
    "\n",
    "\"The International Olympic Committee announced today that the upcoming Olympic Games will be held jointly in a historic collaboration between Greece and Turkey, marking a significant step towards improving relations between the two neighboring countries. The decision comes after years of diplomatic efforts to ease tensions over territorial disputes in the Aegean Sea. Both nations will share hosting duties, with events spread across cities in both countries, including Athens and Istanbul. Athletes from around the world have expressed excitement over the unique opportunity to compete in venues that bridge both European and Asian continents. This is more than just a sporting event; it's a symbol of unity and peace, stated IOC President Thomas Bach. The co-hosting arrangement is expected to boost tourism and economic activity in the region, with projections estimating an influx of over one million visitors. Security measures are being heightened to ensure the safety of participants and spectators, involving coordinated efforts between Greek and Turkish authorities. Human rights organizations are keeping a close watch to ensure that preparations respect local communities and environmental standards. The United Nations has praised the initiative, with Secretary-General António Guterres calling it a monumental step towards regional cooperation and harmony. However, some critics question the feasibility of managing logistics across two countries with complex political histories. There are concerns about potential bureaucratic hurdles and infrastructural challenges. In response, both governments have formed a joint committee to oversee planning and execution, emphasizing transparency\",\n",
    "\n",
    "\"Tech conglomerate NeuroTech Industries unveiled today its latest breakthrough in biotechnology: a neural interface device that allows seamless communication between the human brain and computers. Named SynapseLink, the device has the potential to revolutionize industries ranging from medicine to finance by enabling direct thought-to-action capabilities. Investors are buzzing, and the company's stock surged by 20% following the announcement. SynapseLink represents a quantum leap in human-computer interaction, stated CEO Dr. Elena Rodriguez during the product launch. The device operates by decoding neural signals and translating them into digital commands, effectively allowing users to control software and hardware with their minds. Potential applications include assisting individuals with disabilities, enhancing virtual reality experiences, and increasing productivity in professional settings. The business implications are vast. Companies are already exploring how SynapseLink can be integrated into their operations to streamline workflows and reduce reliance on traditional input devices like keyboards and mice. In healthcare, the technology could aid in neurorehabilitation, helping patients recover motor functions after strokes or injuries. The gaming industry is particularly excited, seeing opportunities to create more immersive experiences. However, the development raises ethical and regulatory concerns. Data privacy advocates warn about the potential misuse of sensitive neurological data. We're entering uncharted territory where thoughts could be recorded and possibly exploited, cautioned cybersecurity expert Laura Chen. NeuroTech Industries has pledged to implement robust security measures and comply with all regulatory standards. Government agencies are also taking note. Discussions are underway about establishing\",\n",
    "\n",
    "\"Global sports apparel giant AthletiCorp announced a landmark merger with innovative wearable tech company FitPulse in a deal valued at $5 billion. The strategic alliance aims to revolutionize the sports industry by integrating advanced technology into athletic wear, offering real-time performance analytics to both professional athletes and everyday fitness enthusiasts. This merger is a game-changer, proclaimed AthletiCorp CEO Marcus Lee. By combining our expertise in sports apparel with FitPulse's cutting-edge technology, we're poised to redefine how individuals interact with their fitness routines. The new line of smart clothing will feature embedded sensors that monitor biometrics such as heart rate, muscle activity, and hydration levels. Data collected will sync with a mobile app, providing personalized feedback and training recommendations. The business implications are significant. Analysts predict that the market for smart athletic wear could exceed $50 billion within the next five years. Investors reacted positively, with AthletiCorp's stock price increasing by 12% following the announcement. The merger positions the company to compete aggressively against rivals in both the sportswear and tech industries. Professional sports teams are already expressing interest. Contracts are being negotiated to supply entire leagues with the smart apparel, potentially enhancing player performance and reducing injuries through better monitoring. This technology could extend athletes' careers by preventing overexertion and optimizing training, noted sports scientist Dr. Karen Simmons. However, the integration of technology raises privacy concerns. Data security experts warn about the potential risks of sensitive health information being hacked\",\n",
    "\n",
    "\"In an unprecedented global initiative, scientists and policymakers from over 100 countries convened at the United Nations headquarters to launch the International Climate Technology Alliance. The alliance aims to combat climate change by fostering innovation in renewable energy, carbon capture, and sustainable agriculture. This is a critical moment for humanity, declared UN Secretary-General António Guterres. Through collaboration and technology, we can address the most pressing environmental challenges of our time. The alliance will function as a platform for sharing knowledge, resources, and technological advancements. Developed nations have pledged $50 billion to fund research and development projects in emerging economies, focusing on scalable solutions that can be implemented worldwide. Key initiatives include advancing solar and wind energy technologies, developing efficient energy storage systems, and exploring geoengineering possibilities. Scientists are particularly excited about the potential for collaborative research. Dr. Aisha Mbaye, a leading climatologist from Senegal, emphasized the importance of diverse perspectives. Climate change is a global issue requiring global input. By uniting, we can accelerate breakthroughs that might have taken decades individually. Technological innovation is at the heart of the alliance's strategy. Plans are underway to launch satellites equipped with advanced sensors to monitor environmental changes in real-time. This data will be accessible to all member countries, aiding in disaster preparedness and policy formulation. However, the initiative is not without challenges. Critics argue that technology alone cannot solve the climate crisis without significant policy changes and reductions in greenhouse gas emissions.\",\n",
    "\n",
    "\"The National Basketball Association is set to revolutionize the game by integrating artificial intelligence and virtual reality into its upcoming season. Partnering with tech firm VisionSports, the NBA plans to enhance both player performance and fan engagement through cutting-edge technology. We're entering a new era of sports entertainment, announced NBA Commissioner Adam Silver. This initiative will redefine how fans experience basketball and how players train and compete. Players will have access to AI-driven analytics that provide real-time feedback on their performance during games and practices. Wearable sensors will collect data on metrics such as speed, acceleration, and shot accuracy, allowing coaches to make instantaneous strategic adjustments. It's like having a personal analyst with you at all times, said star player LeBron James. This technology could extend careers and elevate the level of competition. For fans, the introduction of virtual reality promises an immersive experience like never before. VisionSports has developed VR headsets that allow viewers to watch games from the perspective of any player on the court or from exclusive courtside seats, all from the comfort of their homes. Interactive features enable fans to access player stats, switch viewing angles, and even participate in virtual halftime shows. The business implications are significant. The NBA expects to increase its global viewership and tap into new revenue streams through subscriptions to the enhanced VR experience. VisionSports stands to gain a substantial market share in the sports technology sector. Advertisers are also keen\"\n",
    "]\n",
    "\n",
    "# World, Sports, Business, Sci/Tec\n",
    "true_labels = [\"World\", \"Sports\", \"Business\", \"Sci/Tec\", \"World\", \"Sports\", \"Business\", \"Sci/Tec\", \"World\", \"Sports\", \"Sci/Tec\", \"Business\", \"World\", \"Sci/Tec\", \"World\", (\"World\", \"Sports\"), (\"Sci/Tec\", \"Business\"), (\"Business\", \"Sports\"), (\"World\", \"Sci/Tec\"), (\"Sports\", \"Sci/Tec\")]\n",
    "\n",
    "below = []\n",
    "exact = []\n",
    "above = []\n",
    "\n",
    "mixed = []\n",
    "\n",
    "for text, label in zip(texts, true_labels):\n",
    "    assert text != \"\", \"Come on, be creative\"\n",
    "\n",
    "    classif = fasttext_char_model.predict(text)\n",
    "    print(\"Classified as:\", classif[0][0][9:], \"with certainty:\", classif[1][0])\n",
    "    text_len = len(text.split())\n",
    "    print(\"Amount of words: \", text_len)\n",
    "    if text_len < 240:\n",
    "        if type(label) == tuple:\n",
    "            mixed.append(classif[0][0][9:] == label[0] or classif[0][0][9:] == label[1])\n",
    "        else:\n",
    "            below.append(classif[0][0][9:] == label)\n",
    "    elif text_len == 240:\n",
    "        if type(label) == tuple:\n",
    "            mixed.append(classif[0][0][9:] == label[0] or classif[0][0][9:] == label[1])\n",
    "        else:\n",
    "            exact.append(classif[0][0][9:] == label)\n",
    "    else:\n",
    "        if type(label) == tuple:\n",
    "            mixed.append(classif[0][0][9:] == label[0] or classif[0][0][9:] == label[1])\n",
    "        else:\n",
    "            above.append(classif[0][0][9:] == label)\n",
    "    print()\n",
    "\n",
    "print(\"Accuracy for texts below 240 words:\", sum(below)/len(below))\n",
    "print(\"Accuracy for texts with 240 words:\", sum(exact)/len(exact))\n",
    "print(\"Accuracy for texts above 240 words:\", sum(above)/len(above))\n",
    "print(\"Accuracy for mixed texts:\", sum(mixed)/len(mixed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below 240: [False, True, False, True, True]\n",
      "Exactly 240: [True, True, True, False, True]\n",
      "Above 240: [True, False, False, True, False]\n",
      "Mixed topics (exactly 240): [True, True, False, True, True]\n"
     ]
    }
   ],
   "source": [
    "print(\"Below 240:\", below)\n",
    "print(\"Exactly 240:\", exact)\n",
    "print(\"Above 240:\", above)\n",
    "print(\"Mixed topics (exactly 240):\", mixed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy for texts with 240 words definitely has the best accuracy, and while texts below and above vary in their distance from 240, it is clear that their performance is worse, with below having the best of the two. The difference in accuracy between below and above could be explained by above having on average a distance of $173.8$ from $240$, and below having an average distance of $111.2$.\n",
    "\n",
    "Our null hypothesis will be that the accuracies for the different types of tests, are statistically indifferent. We cannot use any test with normality assumption due to our small sample size, and we will therefore use Fisher's Exact Test, which is appropriate for comparing proportions in small samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison between below and exact:\n",
      "  Odds Ratio: 0.375\n",
      "  P-Value: 1.0\n",
      "  Corrected P-Value: 1.0\n",
      "  Significant Difference: No\n",
      "\n",
      "Comparison between below and above:\n",
      "  Odds Ratio: 2.25\n",
      "  P-Value: 1.0\n",
      "  Corrected P-Value: 1.0\n",
      "  Significant Difference: No\n",
      "\n",
      "Comparison between below and mixed:\n",
      "  Odds Ratio: 0.375\n",
      "  P-Value: 1.0\n",
      "  Corrected P-Value: 1.0\n",
      "  Significant Difference: No\n",
      "\n",
      "Comparison between exact and above:\n",
      "  Odds Ratio: 6.0\n",
      "  P-Value: 0.5238095238095238\n",
      "  Corrected P-Value: 1.0\n",
      "  Significant Difference: No\n",
      "\n",
      "Comparison between exact and mixed:\n",
      "  Odds Ratio: 1.0\n",
      "  P-Value: 1.0\n",
      "  Corrected P-Value: 1.0\n",
      "  Significant Difference: No\n",
      "\n",
      "Comparison between above and mixed:\n",
      "  Odds Ratio: 0.16666666666666666\n",
      "  P-Value: 0.5238095238095238\n",
      "  Corrected P-Value: 1.0\n",
      "  Significant Difference: No\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from scipy.stats import fisher_exact\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# Function to perform Fisher's Exact Test between two groups\n",
    "def perform_fishers_exact(group1, group2, name1, name2):\n",
    "    # Contingency table\n",
    "    table = [\n",
    "        [sum(group1), len(group1) - sum(group1)],\n",
    "        [sum(group2), len(group2) - sum(group2)]\n",
    "    ]\n",
    "    # Perform Fisher's Exact Test\n",
    "    odds_ratio, p_value = fisher_exact(table, alternative='two-sided')\n",
    "    return {\n",
    "        'groups': (name1, name2),\n",
    "        'odds_ratio': odds_ratio,\n",
    "        'p_value': p_value\n",
    "    }\n",
    "\n",
    "# Prepare data for pairwise comparisons\n",
    "groups = {\n",
    "    'below': below,\n",
    "    'exact': exact,\n",
    "    'above': above,\n",
    "    'mixed': mixed\n",
    "}\n",
    "\n",
    "# Perform all pairwise comparisons\n",
    "results = []\n",
    "for (name1, group1), (name2, group2) in itertools.combinations(groups.items(), 2):\n",
    "    result = perform_fishers_exact(group1, group2, name1, name2)\n",
    "    results.append(result)\n",
    "\n",
    "# Extract p-values for multiple testing correction\n",
    "p_values = [res['p_value'] for res in results]\n",
    "\n",
    "# Apply Bonferroni correction\n",
    "reject, corrected_p_values, _, _ = multipletests(p_values, method='bonferroni')\n",
    "\n",
    "# Update results with corrected p-values\n",
    "for res, p_val, rej in zip(results, corrected_p_values, reject):\n",
    "    res['corrected_p_value'] = p_val\n",
    "    res['significant'] = rej\n",
    "\n",
    "# Print the results\n",
    "for res in results:\n",
    "    print(f\"Comparison between {res['groups'][0]} and {res['groups'][1]}:\")\n",
    "    print(f\"  Odds Ratio: {res['odds_ratio']}\")\n",
    "    print(f\"  P-Value: {res['p_value']}\")\n",
    "    print(f\"  Corrected P-Value: {res['corrected_p_value']}\")\n",
    "    print(f\"  Significant Difference: {'Yes' if res['significant'] else 'No'}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fisher's Exact Test p-value: 0.5238095238095238\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import fisher_exact\n",
    "\n",
    "# Example contingency table for two groups\n",
    "# Group1: successes and failures\n",
    "# Group2: successes and failures\n",
    "table = [\n",
    "    [sum(group1), len(group1) - sum(group1)],\n",
    "    [sum(group2), len(group2) - sum(group2)]\n",
    "]\n",
    "\n",
    "odds_ratio, p_value = fisher_exact(table, alternative='two-sided')\n",
    "print(f\"Fisher's Exact Test p-value: {p_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, we cannot reject our null hypothesis, although this is probably due to our small sample size. Also, we should have balanced the tests with an equal amount of topics. If we were to generate more samples, we could assume normality and use a more popular test, such as Two-Proportion Z-Test, which can compare correct classifications between two independent groups. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-Squared Statistic: 2.417582417582418\n",
      "Degrees of Freedom: 3\n",
      "P-Value: 0.49037005360727715\n",
      "\n",
      "Expected Frequencies:\n",
      "[[3.25 1.75]\n",
      " [3.25 1.75]\n",
      " [3.25 1.75]\n",
      " [3.25 1.75]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Observed frequencies\n",
    "observed = np.array([\n",
    "    [3, 2],  # Below\n",
    "    [4, 1],  # Exact\n",
    "    [2, 3],  # Above\n",
    "    [4, 1]   # Mixed\n",
    "])\n",
    "\n",
    "# Perform Chi-Squared Test\n",
    "chi2_stat, p_value, dof, expected = chi2_contingency(observed)\n",
    "\n",
    "# Print the results\n",
    "print(\"Chi-Squared Statistic:\", chi2_stat)\n",
    "print(\"Degrees of Freedom:\", dof)\n",
    "print(\"P-Value:\", p_value)\n",
    "print(\"\\nExpected Frequencies:\")\n",
    "print(expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  $\\star$ $\\star$ $\\star$ Exercise 6 Extremely optional task\n",
    "\n",
    "**1. It's quite a waste to have all those juicy principle components of the embedding matrices without using them in a classifier of some sort, right?**\n",
    "\n",
    "**Create a classifier to classify texts as one of the four labels, based on the projections of their words unto a number of the principle components of the embedding matrices. Compare this classifier to the fasttext classifier and reflect on their performance.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise NotImplementedError(\"Asking for a whole classifier is a bit much, no?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
